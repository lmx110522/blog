<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[深入学习JVM调优(二)]]></title>
    <url>%2F2019%2F04%2F24%2F%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0JVM%E8%B0%83%E4%BC%98-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[深入学习JVM调优(二)BtraceBtrace可以动态地向目标应用程序的字节码注入追踪代码 安装Btrace首先我们去github下载，然我去下载！ 开始安装1.解压到指定的目录2.新建环境变量BTRACE_HOME,设置成项目的地址3.添加Path: %BTRACE_HOME%\bin 运行Btrace第一种： 在JVisualVM中添加Btrace插件，添加classpath 第二种: 使用命令行 btrace &lt; pid&gt; &lt; trace_script&gt; 引入依赖123456789101112131415161718192021222324&lt;dependency&gt; &lt;groupId&gt;com.sun.btrace&lt;/groupId&gt; &lt;artifactId&gt;btrace-agent&lt;/artifactId&gt; &lt;version&gt;1.3.11&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;F:/JaveWeb/btrace/build/btrace-agent.jar&lt;/systemPath&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun.btrace&lt;/groupId&gt; &lt;artifactId&gt;btrace-boot&lt;/artifactId&gt; &lt;version&gt;1.3.11&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;F:/JaveWeb/btrace/build/btrace-boot.jar&lt;/systemPath&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun.btrace&lt;/groupId&gt; &lt;artifactId&gt;btrace-client&lt;/artifactId&gt; &lt;version&gt;1.3.11&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;F:/JaveWeb/btrace/build/btrace-client.jar&lt;/systemPath&gt; &lt;/dependency&gt; 编写脚本123456789101112131415161718192021222324252627282930313233343536package com.nyist.controller;import com.sun.btrace.AnyType;import com.sun.btrace.BTraceUtils;import com.sun.btrace.annotations.BTrace;import com.sun.btrace.annotations.Kind;import com.sun.btrace.annotations.Location;import com.sun.btrace.annotations.OnMethod;import com.sun.btrace.annotations.ProbeClassName;import com.sun.btrace.annotations.ProbeMethodName;@BTracepublic class PrintArgSimple &#123; @OnMethod( clazz = "com.nyist.controller.BTraceController", method = "arg1", location = @Location(Kind.ENTRY) ) public static void anyRead(@ProbeClassName String pcn, @ProbeMethodName String pmn, AnyType[] args ) &#123; BTraceUtils.printArray(args); BTraceUtils.println("className: " + pcn); BTraceUtils.println("MethodName: " + pmn); BTraceUtils.println(); &#125;&#125; 然后我们启动我们的项目12345678910111213141516package com.nyist.controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping("/btrace")public class BTraceController &#123; @RequestMapping("/arg1") public String arg1(@RequestParam("name") String name) &#123; return "hello: " + name; &#125;&#125; 结果是：]]></content>
      <tags>
        <tag>JVM性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[复习查漏补缺（二）]]></title>
    <url>%2F2019%2F04%2F20%2F%E5%A4%8D%E4%B9%A0%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[复习查漏补缺（二）Spring中自动装配的4种方式byName通过byName方式自动装配属性的时候，在定义bean的属性时，property标签中设置autowired属性为byName,那么spring会自动查找一个与该属性名字相同或id相同的Bean,注入进来 byType通过byType方式自动注入属性时，是在定义Bean的时候，在property标签中设置autowire属性为byType，那么Spring会自动寻找一个与该属性类型相同的Bean，注入进来。 constructor通过构造器自动注入。在定义Bean时，在bean标签中，设置autowire属性为constructor，那么，Spring会寻找与该Bean的构造函数各个参数类型相匹配的Bean，通过构造函数注入进来。 autodetect自动装配。如果想进行自动装配，但不知道使用哪种类型的自动装配，那么就可以使用autodetect，让容器自己决定。这是通过在定义Bean时，设置bean标签的autowire属性为autodetect来实现的。设置为autodetect时，Spring容器会首先尝试构造器注入，然后尝试按类型注入。 默认情况下，Spring是不进行自动装配的 Spring支持的事务管理类型有什么Spring支持两种类型的事务管理 编程式事务意味着你通过编程的方式管理事务，给你带来极大的灵活性，但是很难维护！ 声明式事务意味着你可以将业务代码和事务管理分离，只需要通过注解或者xml的方式来管理事务 编程式事务可以分为三种类型 基于AOP的声明式事务管理 基于AspectJ的声明式事务管理（Aspectj是一个AOP框架） 基于注解的声明式书事务管理 解释一下MyBatis中命名空间（namespace）的作用解释: 在大型项目中，可能存在大量的sql语句，但是每个sql语句必须有一个唯一的标识(ID),所以很不容易保证唯一性，因此，在mybatis中，每个映射文件都有一个唯一的命名空间，这样定义后，只需要保证当前的映射文件中的sql语句的id不重复就可以避免冲突。 assert断言的场景一般使用断言在开发或者测试的时候使用，为了保证程序的执行效率，断言在程序发布后是关闭的。断言包含一个布尔表达式，如果为false,会抛出一个AssertionError异常1assert(m &gt; 0); // throws an AssertionError if m &lt;= 0 Redis为什么是单线程的因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈有可能是机器内存大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，加之多线程数据同步是个问题，所以使用单线程很合适 数据库的拆分数据库拆分就是通过某种特定的条件，按照某个维度，将我们存放在同一个数据库中的数据分散在多个数据库主机上以达到分散主库负载的效果 什么时候才要拆分当我们使用读写分离、缓存后，数据库的压力还是很大的时候，这个时候就需要数据库拆分了 切分模式垂直拆分(专库专用)一个数据库有很多表组成，每个表对应着不同的业务，垂直切分是指按照业务将表进行切分，分不到不同的数据库上面，这样就可以通过把数据分散到不同的数据库进而减轻单库的压力。 优点 数据维护简单 拆分后业务清晰，拆分规则明确 系统之间整合或者扩展容易 缺点 部分业务无法Join,只能通过接口的方式解决，从而提高了系统复杂度 受每种业务不同的限制存在单库性能瓶颈，不易数据扩展跟性能提高 事务处理复杂 水平切分垂直切分之后，但是单机仍有瓶颈，那么可以使用水平切分。 水平切分和垂直切分的区别水平切分是把一个数据库中的不同表拆到不同的数据库中，垂直切分是把一个数据库中的同一张表拆分到不同的数据库中。 理解按照数据行的切分，就是将表中 的某些行切分到一个数据库，而另外的某些行又切分到其他的数据库中 优点： 不存在单库大数据，高并发的性能瓶颈。 对应用透明，应用端改造较少。 按照合理拆分规则拆分，join操作基本避免跨库。 提高了系统的稳定性跟负载能力。 缺点： 拆分规则难以抽象。 分片事务一致性难以解决。 数据多次扩展难度跟维护量极大。 跨库join性能较差 关于水平切分学习，这个博客很好，强烈推荐]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>数据库分库</tag>
        <tag>spring基础知识点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker容器——深度解读]]></title>
    <url>%2F2019%2F04%2F16%2FDocker%E5%AE%B9%E5%99%A8%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[Docker容器——深度解读深入一个技术最好的方式，看文档，点我去官网！ Docker容器不是虚拟机 为什么要用dockerDocker 是开源的应用容器引擎。Docker 可以让你将所有应用软件以及它的依赖打包成软件开发的标准化单元。Docker 容器将软件以及它运行安装所需的一切文件（代码、运行时、系统工具、系统库）打包到一起，这就保证了不管是在什么样的运行环境，总是能以相同的方式运行。就好像 Java 虚拟机一样，“一次编写，到处运行（Write once, run anywhere）”，而 Docker 是“一次构建，到处运行（Build once，run anywhere）”。 Docker 的优点 轻量级：所有容器在一台机器上共享同一个操作系统内核，这样他们立即开始，并更有效地利用内存。Image 是从分层文件系统的构建，这样他们能够共享公共文件，使得磁盘使用率和 Image 的下载更加高效。 开放：Docker 容器是基于开发的标准，允许容器运行在主流的 Linux 发布版和 Microsoft 操作系统作为所有的基础设施。 安全：容器使得应用程序彼此隔离，而基础架构同时为应用程序提供了额外的保护层。 开发更加敏捷：Docker 让开发人员可以自由定义环境，创建和部署的应用程序更快、更容易，IT 运维人员快速应对变化也更加灵活性。 更加可控：Docker 使得开发人员保存从基础设施到应用的代码，帮助 IT 运维人管理拥有标准的、安全的、可扩展的操作环境。 高可移植性：Docker 允许自由选择，可以是从笔记本电脑到一个团队，从私人基础设施到公共云提供商。 Docker底层实现Docker 的容器利用了 LXC(Linux Container 虚拟机容器技术)，管理利用了 namespaces 来做权限的控制和隔离，cgroups 来进行资源的配置，并且还通过 aufs 来进一步提高文件系统的资源利用率，而这些技术都不是 Docker 独创。 Docker存储驱动之AUFSAUFS曾是Docker默认的首选存储驱动。它非常稳定、有很多真实场景的部署、很强的社区支持。它有以下主要优点： 极短的容器启动时间 有效的存储利用率 有效的内存利用率 DockfileDockfile是一个用于编写docker镜像生成过程的文件，其有特定的语法。在一个文件夹中，如果有一个Dockfile的文件，其内容满足语法要求，在这个文件夹路径下执行命令: docker build --tag name:tag .,就可以构建一个镜像了。name是镜像的名称，tag是镜像的版本或者是标签号，不写默认是latest,千万不可以忘记命令中后面有一个空格和一个. Dockfile语法Dockerfile的基本指令有十三个，分别是：FROM、MAINTAINER、RUN、CMD、EXPOSE、ENV、ADD、COPY、ENTRYPOINT、VOLUME、USER、WORKDIR、ONBUILD。 FROM用法： FROM 说明：第一个指令必须是FROM，其指定了一个构建镜像的基础源镜像，如果本地没有就会从公共库中拉取，没有指定镜像标签就会使用默认的latest标签，可以出现多次，如果需要在一个Dockfile中构建多个镜像。 MAINTAINER用法： MAINTAINER &lt; name&gt; &lt; email&gt;说明: 描述镜像的创建者，包括名称和邮箱 RUN用法： RUN “command” “param1””param2”说明： RUN命令是一个常用的命令，执行完成之后会成为一个新的镜像，这里也是指镜像的分层构建。一句RUN就是一层，也相当于一个版本。这就是之前说的缓存的原理。我们知道docker是镜像层是只读的，所以你如果第一句安装了软件，用完在后面一句删除是不可能的。所以这种情况要在一句RUN命令中完成，可以通过&amp;符号连接多个RUN语句。RUN后面的必须是双引号不能是单引号（没引号貌似也不要紧），command是不会调用shell的，所以也不会继承相应变量，要查看输入RUN “sh” “-c” “echo” “$HOME”，而不是RUN “echo” “$HOME”。 CMD用法：CMD command param1 param2说明：CMD在Dockerfile中只能出现一次，假如有多个，那么只有最后一个会有效。其作用是在启动容器的时候提供一个默认的命令项。如果用户执行docker run的时候提供了命令项，就会覆盖掉这个命令。没提供就会使用构建时的命令。 EXPOSE用法：EXPOSE &lt; port&gt; [&lt; port&gt;…]说明：告诉Docker服务器容器对外映射的容器端口号，在docker run -p的时候生效。 ENV用法：EVN 只能设置一个 ； EVN =允许一次设置多个说明：设置容器的环境变量，可以让其后面的RUN命令使用，容器运行的时候这个变量也会保留 ADD用法：ADD &lt; src&gt; &lt; dest&gt;说明：复制本机文件或目录或远程文件，添加到指定的容器目录，支持GO的正则模糊匹配。路径是绝对路径，不存在会自动创建。如果源是一个目录，只会复制目录下的内容，目录本身不会复制。ADD命令会将复制的压缩文件夹自动解压，这也是与COPY命令最大的不同 COPY用法：COPY &lt; src&gt; &lt; dest&gt;说明：COPY除了不能自动解压，也不能复制网络文件。其它功能和ADD相同。 ENTRYPOINT用法：ENTRYPOINT “command” “param1” “param2”说明：这个命令和CMD命令一样，唯一的区别是不能被docker run命令的执行命令覆盖，如果要覆盖需要带上选项–entrypoint，如果有多个选项，只有最后一个会生效。 VOLUME用法：VOLUME [“path”]说明：在主机上创建一个挂载，挂载到容器的指定路径。docker run -v命令也能完成这个操作，而且更强大。这个命令不能指定主机的需要挂载到容器的文件夹路径。但docker run -v可以，而且其还可以挂载数据容器。 USER用法：USER daemon说明：指定运行容器时的用户名或UID，后续的RUN、CMD、ENTRYPOINT也会使用指定的用户运行命令。 WORKDIR用法:WORKDIR path说明：为RUN、CMD、ENTRYPOINT指令配置工作目录。可以使用多个WORKDIR指令，后续参数如果是相对路径，则会基于之前的命令指定的路径。如：WORKDIR /home WORKDIR test 。最终的路径就是/home/test。path路径也可以是环境变量，比如有环境变量HOME=/home，WORKDIR $HOME/test也就是/home/test。 ONBUILD用法：ONBUILD [INSTRUCTION]说明：配置当前所创建的镜像作为其它新创建镜像的基础镜像时，所执行的操作指令。意思就是，这个镜像创建后，如果其它镜像以这个镜像为基础，会先执行这个镜像的ONBUILD命令。 特别注: 上面关于Dockfile知识摘抄此文章，点我去看，仅用于参考，不盈利。 综合上面语法举个栗子1234567891011FROM centosMAINTAINER nobody &quot;xx@qq.com&quot;RUN mkdir -p /opt/jdk/RUN mkdir -p /opt/tomcat/ADD jdk1.7.0_79 /opt/jdk/ADD tomcat /opt/tomcat/ENV CATALINA_HOME /opt/tomcatENV JAVA_HOME /opt/jdkEXPOSE 8080ENV PATH $PATH:$JAVA_HOME/binCMD [&quot;/opt/tomcat/bin/catalina.sh&quot;,&quot;run&quot;] 下一篇继续深入学习Docker容器化构建]]></content>
  </entry>
  <entry>
    <title><![CDATA[蚂蚁金服HR面——重新审视自己]]></title>
    <url>%2F2019%2F04%2F15%2F%E8%9A%82%E8%9A%81%E9%87%91%E6%9C%8DHR%E9%9D%A2%E2%80%94%E2%80%94%E9%87%8D%E6%96%B0%E5%AE%A1%E8%A7%86%E8%87%AA%E5%B7%B1%2F</url>
    <content type="text"><![CDATA[蚂蚁金服HR面——重新审视自己关于和面试官的疑惑面试差不多有半个小时左右，然后整个过程差不多面试官都在问我的优点缺点以及如果面试没有面过或者面过种种问题，我还是想说，我是个有理想的小男生。 面试官问我，工作室老师对我的评价，我说，老师说我有跳跃性思维，其实，从不同的角度看，结果是不同的，我从百度百科中摘抄了这个词汇的理解 1跳跃式思维（Jump Thinking）是指一种不依逻辑步骤，直接从命题跳到答案，并再一步推而广之到其他相关的可能的一种思考模式。这种思考模式在部分资优学童很常见，而随著因特网的普及，这种思考模式更慢慢成为了主流。因此，现时对这种称呼有另一种叫法，叫作选单式思考。简单地说，跳跃性思维就是一种杂乱的思维方式。通常对一种事物的想象突然跳到与此事物不相干的另一事物上了，而且连续这样跳跃想象，想象力非常丰富。逻辑不严密，组织杂乱无序。它与逻辑思维是相对立的。通常的表现是说话或者写文章太乱，组织不严密，立意太分散。 面试官说和我的专注度是矛盾的在面对多个处境的时候，可能我会跳跃性的去选择我认为正确的路，然后去专注的做好它。并不是说，学习的时候不够深入，这是不矛盾的。当初我在接触到c++的时候，我没有去学习它，不是我不专注，是因为我觉着我不喜欢所以才会不去做这件事，然后接触java之后，我觉着这就是我喜欢的语言。但是由刚开始的再表面上学习使用，觉着很好用，甚至没有了c++中复杂的指针，不用自己进行垃圾回收。这只是我刚开始用的时候的直观感受，其实在后来的学习中不然。 我是一个要强的人我一定要做到比别人好，这是我的态度，也是我在做一件事情的时候，会去做的比别人好。可能从小家庭的缘故，我见不到别人比我要好，所以我会花更多的事情去做好这件事情，这是一种态度，也是我精神的食量。在我们学习的技术中，全国很多程序员都会做，都不是傻子，谁不会做呢，但是真正深入的那部分人就是他们中优秀的那部分人，这就话是我常常告诉我自己的，要做好就要做更多的努力，持之以恒。我虽然没有科比每天早晨凌晨的四点钟的洛杉矶的太阳，但作为我的偶像，我要做我这周围人中最优秀的。我经历过大学几乎大部分时间的早晨6点钟的南阳理工的清晨，多少个日日夜夜在屏幕前看着一行行字母，还有一份份pdf文档,还有一个个视频的播放，那是我的经历，是我人生的积累！我认为我是个专注的人，这不矛盾！ 我是一个有计划的人马云说过，我们和富人们的一样的是一天我们都是有24个小时！我喜欢有计划的做好这个24个小时大约在初中的时候，语文老师告诉我们，做任何事情都要有计划，即使计划赶不上变化，大部分时间会让你很自信面对生活。 这个计划在我脑子里面一直履行，已经享受了这种计划带来的幸福感！每一天的学习计划都会在前一天晚上做好，提前一天准备好我的学习资料和视频，第二天大部分时间就会做到！除非有其他的生活琐事占满！我的幸福感的大部分来源于有个规划的明天 关于面试官问我的问题1.如果面试不上，你觉着你比别人差在哪2.如果你面试上，你觉着你比别人优秀在哪3.你的优点以及缺点4.身边的人对你的评价5.你为什么想来阿里巴巴6. 你除了蚂蚁金服，你还喜欢阿里巴巴的哪个公司7. 你从前面的一个个面试官哪个学到了东西8. 面试官给你的建议你后来是怎么来学习的成功不是偶然，机会是给有准备的人学业上的成就不是用时间来衡量的，是你比别人多思考了多少。 校园里的一名小学生，上述仅个人观点！]]></content>
      <categories>
        <category>自我认知</category>
      </categories>
      <tags>
        <tag>蚂蚁金服HR面</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入学习JVM调优(一)]]></title>
    <url>%2F2019%2F04%2F14%2F%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0JVM%E8%B0%83%E4%BC%98-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[深入学习JDK调优非标准化参数X类型参数-Xint: 解释执行-Xcomp: 第一次使用就编译成本地代码-Xmixed: 混合模式,JVM自己决定是否编译成本地代码 扩展解释执行：将编译好的字节码一行一行地翻译为机器码执行。编译执行：以方法为单位，将字节码一次性翻译为机器码后执行。 在编译示时期，我们通过将源代码编译成.class ，配合JVM这种跨平台的抽象，屏蔽了底层计算机操作系统和硬件的区别，实现了“一次编译，到处运行” 。 而在运行时期，目前主流的JVM 都是混合模式（-Xmixed），即解释运行 和编译运行配合使用。以 Oracle JDK提供的HotSpot虚拟机为例，在HotSpot虚拟机中，提供了两种编译模式：解释执行 和 即时编译（JIT，Just-In-Time）。解释执行即逐条翻译字节码为可运行的机器码，而即时编译则以方法为单位将字节码翻译成机器码（上述提到的“编译执行”）。前者的优势在于不用等待，后者则在实际运行当中效率更高。 XX类型参数主要用途:jvm调优 Boolean类型格式： -XX:[+-]&lt; name&gt;表示启用或者禁用name属性，其中+表示启用，-表示禁用例如： -XX:+UseConcMarkSweepGC 启用CMS垃圾收集器；-XX：+UseG1GC 启用G1垃圾收集器 非Boolean类型格式： -XX:&lt; name&gt;=&lt; value&gt;表示name属性的值是value比如： -XX:MaxGCPauseMillis=500表示GC垃圾收集最大停顿时间是500毫秒 -Xms: jvm的初始内存大小，也可以成为最小内存大小-Xmx: jvm的最大内存大大小-Xss: 设置线程堆栈的大小 JVM运行时参数-XX:+PrintFlagsInitial 查看初始值 -XX:+PrintFlagsFinal 查看最终值 -XX:+UnlockExperimentalVMOptions 解锁实验参数 -XX:+UnlockDiagnosticVMOptions 解锁诊断参数 -XX:+PrintCommandLineFlags 打印命令行参数 详解-XX：+PrintFlagsFinal 查看最终值然后执行java -XX:PrintFlagsFinal -version结果得到有 := 和 =的键值对，其中 := 表示 被用户或者JVM修改后的值，= 表示默认值 此时运行的结果表示是当前命令执行的所在线程的参数值 jps专门用来查询java进程的命令，类似于linux中的ps命令其中 jps -l 能够查看到具体的进程中的全类名 刚刚我们通过jps查到对用的进程号，然后我们通过jinfo -flags 进程号 打印出所有的参数变量 jstat用来查看JVM的统计信息 类加载 2. 垃圾收集 3. JIT编译我们首先使用jps找到对应的进程id，然后我们使用 jstat -class id 毫秒数 数量 打印出对应的统计信息 123456789101112131415F:\jvm&gt;jstat -class 16108Loaded Bytes Unloaded Bytes Time 677 1339.9 0 0.0 0.54F:\jvm&gt;jstat -compiler 16108Compiled Failed Invalid Time FailedType FailedMethod 114 0 0 0.08 0//其中S0C S1C S0U S1U表示survior区的总量和使用量// EC EU OC OU 分别表示 Eden区和old区的总量和使用量//GCT 总的垃圾回收时间// YGC YGCT FGC FGCT 分别表示minor gc的次数和时间 Full gc的次数和时间F:\jvm&gt;jstat -gc 16108 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT512.0 512.0 504.0 0.0 2048.0 587.3 129536.0 638.1 4864.0 3810.5 512.0 427.0 4 0.005 0 0.000 0.005 其中 Loaded 加载的个数 jmap + MAT 定位内存溢出出现内存泄露，需要我们导出内存映像文件，有两种方式1 内存溢出自动导出-XX:+HeapDumpOnOutOfMemoryError-XX:HeapDumpPath=./ 在系统运行的时候配置上面两个参数，控制台打印出12345java.lang.OutOfMemoryError: GC overhead limit exceededDumping heap to ./\java_pid18408.hprof ...Heap dump file created [48277884 bytes in 0.389 secs]Exception in thread "http-nio-80-exec-3" java.lang.OutOfMemoryError: GC overhead limit exceededException in thread "http-nio-80-exec-1" java.lang.OutOfMemoryError: GC overhead limit exceeded 然后我们会在项目所在目录找到 java_pid18408.hprof 文件 2 使用jmap命令手动导出首先我们使用jps -l 得到对应进程的进程号123F:\jvm&gt;jmap -dump:format=b,file=heap.hprof 18408Dumping heap to F:\jvm\heap.hprof ...Heap dump file created 我们使用jmap -heap 进程号，可以得到对应堆内存数据配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647F:\jvm&gt;jmap -heap 18408Attaching to process ID 18408, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.11-b03using thread-local object allocation.Parallel GC with 8 thread(s)Heap Configuration: MinHeapFreeRatio = 40 MaxHeapFreeRatio = 70 MaxHeapSize = 33554432 (32.0MB) NewSize = 11010048 (10.5MB) MaxNewSize = 11010048 (10.5MB) OldSize = 22544384 (21.5MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 21807104 (20.796875MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB)Heap Usage:PS Young GenerationEden Space: capacity = 4718592 (4.5MB) used = 4718592 (4.5MB) free = 0 (0.0MB) 100.0% usedFrom Space: capacity = 3145728 (3.0MB) used = 0 (0.0MB) free = 3145728 (3.0MB) 0.0% usedTo Space: capacity = 3145728 (3.0MB) used = 0 (0.0MB) free = 3145728 (3.0MB) 0.0% usedPS Old Generation capacity = 22544384 (21.5MB) used = 22106680 (21.08257293701172MB) free = 437704 (0.41742706298828125MB) 98.0584787767987% used13365 interned Strings occupying 1920632 bytes. 根据上面我们导出的内存映像文件，我们这时候下载一个mat软件，然后在此软件内打开我们的内存映像文件点我去下载MAT软件 下一篇继续学习jvm调优的其他方式]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>JVM性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梳理Java线程的状态以及切换]]></title>
    <url>%2F2019%2F04%2F13%2F%E6%A2%B3%E7%90%86Java%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81%E4%BB%A5%E5%8F%8A%E5%88%87%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[梳理Java线程的状态以及切换Java的线程状态 NEW 2.RUNNABLE 3. WAITING 4. TIMED_WAITING 5. BLOCKED 6. TERMINATED 锁池和等待池锁池假设线程A已经拥有了某个对象(注意:不是类)的锁，而其它的线程想要调用这个对象的某个synchronized方法(或者synchronized块)，由于这些线程在进入对象的synchronized方法之前必须先获得该对象的锁的拥有权，但是该对象的锁目前正被线程A拥有，所以这些线程就进入了该对象的锁池中。 等待池假设一个线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁(因为wait()方法必须出现在synchronized中，这样自然在执行wait()方法之前线程A就已经拥有了该对象的锁)，同时线程A就进入到了该对象的等待池中。如果另外的一个线程调用了相同对象的notifyAll()方法，那么处于该对象的等待池中的线程就会全部进入该对象的锁池中，准备争夺锁的拥有权。如果另外的一个线程调用了相同对象的notify()方法，那么仅仅有一个处于该对象的等待池中的线程(随机)会进入该对象的锁池. 个人汇总: 锁池是线程得到运行的前提，只有进入锁池的线程才有机会得到运行，然后抢夺后再拿到对应的锁，接着进入到对应的就绪状态，最后获得cpu的时间片才可以得到运行。然而在等待池的线程，在被notify或者notifyAll之后，会有一个或者全部在线程池的线程进入到锁池中，进而来竞争得到锁，于是进入到就绪状态，等待获取时间片 Java线程的转化(重点)拿到对象的锁标记，即为获得了对该对象(临界区)的使用权限。即该线程获得了运行所需的资源，进入“就绪状态”，只需获得CPU，就可以运行。因为当调用wait()后，线程会释放掉它所占有的“锁标志”，所以线程只有在此获取资源才能进入就绪状态。 过程详解sleep join当线程调用了自身的sleep()方法或其他线程的join()方法，进程让出CPU，然后就会进入阻塞状态（该状态既停止当前线程，但并不释放所占有的资源即调用sleep ()函数后，线程不会释放它的“锁标志”。）。当sleep()结束或join()结束后，该线程进入可运行状态，继续等待OS分配CPU时间片。典型地，sleep() 被用在等待某个资源就绪的情形：测试发现条件不满足后，让线程阻塞一段时间后重新测试，直到条件满足为止。 yield线程调用了yield()方法，意思是放弃当前获得的CPU时间片，回到就绪状态，这时与其他进程处于同等竞争状态，OS有可能会接着又让这个进程进入运行状态； 调用 yield() 的效果等价于调度程序认为该线程已执行了足够的时间片从而需要转到另一个线程。yield()只是使当前线程重新回到可执行状态，所以执行yield()的线程有可能在进入到可执行状态后马上又被执行。当线程刚进入可运行状态（注意，还没运行），发现将要调用的资源被synchronized（同步），获取不到锁标记，将会立即进入锁池状态，等待获取锁标记（这时的锁池里也许已经有了其他线程在等待获取锁标记，这时它们处于队列状态，既先到先得），一旦线程获得锁标记后，就转入就绪状态，等待OS分配CPU时间片； suspend resumesuspend() 和 resume() 方法：两个方法配套使用，suspend()使得线程进入阻塞状态，并且不会自动恢复，必须其对应的resume() 被调用，才能使得线程重新进入可执行状态。典型地，suspend() 和 resume() 被用在等待另一个线程产生的结果的情形：测试发现结果还没有产生后，让线程阻塞，另一个线程产生了结果后，调用 resume() 使其恢复。 4.6、wait() 和 notify() 方法：当线程调用wait()方法后会进入等待队列（进入这个状态会释放所占有的所有资源，与阻塞状态不同），进入这个状态后，是不能自动唤醒的，必须依靠其他线程调用notify()或notifyAll()方法才能被唤醒（由于notify()只是唤醒一个线程，但我们由不能确定具体唤醒的是哪一个线程，也许我们需要唤醒的线程不能够被唤醒，因此在实际使用时，一般都用notifyAll()方法，唤醒有所线程），线程被唤醒后会进入锁池，等待获取锁标记。 waitwait() 使得线程进入阻塞状态，它有两种形式： 一种允许指定以毫秒为单位的一段时间作为参数；另一种没有参数。前者当对应的 notify() 被调用或者超出指定时间时线程重新进入可执行状态即就绪状态，后者则必须对应的 notify()被调用。当调用wait()后，线程会释放掉它所占有的“锁标志”，从而使线程所在对象中的其它synchronized数据可被别的线程使用。waite()和notify()因为会对对象的“锁标志”进行操作，所以它们必须在synchronized函数或synchronizedblock中进行调用。如果在non-synchronized函数或non-synchronizedblock中进行调用，虽然能编译通过，但在运行时会发生IllegalMonitorStateException的异常。 注意区别：初看起来wait() 和 notify() 方法与suspend() 和 resume() 方法对没有什么分别，但是事实上它们是截然不同的。区别的核心在于，前面叙述的suspend()及其它所有方法在线程阻塞时都不会释放占用的锁（如果占用了的话），而wait() 和 notify() 这一对方法则相反。 wait notify 详解以及注意点首先，前面叙述的所有方法都隶属于 Thread 类，但是wait() 和 notify() 方法这一对却直接隶属于 Object 类，也就是说，所有对象都拥有这一对方法。初看起来这十分不可思议，但是实际上却是很自然的，因为这一对方法阻塞时要释放占用的锁，而锁是任何对象都具有的，调用任意对象的 wait() 方法导致线程阻塞，并且该对象上的锁被释放。而调用任意对象的notify()方法则导致因调用该对象的 wait() 方法而阻塞的线程中随机选择的一个解除阻塞（但要等到获得锁后才真正可执行）。 其次，前面叙述的所有方法都可在任何位置调用，但是wait() 和 notify() 方法这一对方法却必须在 synchronized 方法或块中调用，理由也很简单，只有在synchronized 方法或块中当前线程才占有锁，才有锁可以释放。同样的道理，调用这一对方法的对象上的锁必须为当前线程所拥有，这样才有锁可以释放。因此，这一对方法调用必须放置在这样的 synchronized 方法或块中，该方法或块的上锁对象就是调用这一对方法的对象。若不满足这一条件，则程序虽然仍能编译，但在运行时会出现IllegalMonitorStateException 异常。 wait() 和 notify() 方法的上述特性决定了它们经常和synchronized 方法或块一起使用，将它们和操作系统的进程间通信机制作一个比较就会发现它们的相似性：synchronized方法或块提供了类似于操作系统原语的功能，它们的执行不会受到多线程机制的干扰，而这一对方法则相当于 block 和wake up 原语（这一对方法均声明为 synchronized）。它们的结合使得我们可以实现操作系统上一系列精妙的进程间通信的算法（如信号量算法），并用于解决各种复杂的线程间通信问题。 上述内容借鉴于zolalad的博客，谢谢！]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见算法题型(三)——Java实现]]></title>
    <url>%2F2019%2F04%2F10%2F%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95%E9%A2%98%E5%9E%8B-%E4%B8%89-%E2%80%94%E2%80%94Java%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[1. 打印从1到最大n位数输入数字n,按顺序打印出从1到最大n位十进制数。比如输入3，则依次打印出 1 2 3 .. 999解题思路：首先考虑问题的时候要足够全面，数字整型会存在越界问题，所以对于此类型的问题，使用字符串拼接或者数组解决起来比较容易 12345678910111213141516171819202122232425package com.nyist.offer;import java.util.Scanner;public class PrintCountNums &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); System.out.print("请输入数字n:"); if(scanner.hasNextInt())&#123; int n = scanner.nextInt(); for(int i = 0; i &lt; Math.pow(10,n-1);i++)&#123; for(int j = 0;j &lt; 10;j++)&#123; if(i != 0)&#123; System.out.println(i+""+j); &#125; else&#123; System.out.println(j); &#125; &#125; &#125; &#125; &#125;&#125; 这个方法实现起来比较简单，效率较高 2.创建链表并删除链表中重复的元素输入链表的长度，以及元素内容创建链表，找到重复的元素，删除。例如：输入链表长度为6，对应元素分别为 1,2,2,3,4,4，那么删除重复元素后链表的内容是:1,2,3,4解题思路：首先我们创建元素时候，遍历根节点知道为null的时候再创建当前节点，如果头节点为空的时候，直接创建的节点为根节点。找重复元素的时候，应该保留当前元素的前一个节点，然后发现当前节点和前一个节点的元素相同，则把前一个节点的下一个节点指向当前节点的下一个节点。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798package com.nyist.offer;import java.util.Scanner;public class DeleteLink &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); System.out.print("请输入链表的长度:"); LinkNode1 linkNode = null; if(!scanner.hasNextInt() || scanner.nextInt() &lt;= 0)&#123; System.out.println("输入不合法！"); &#125; else&#123; int len = scanner.nextInt(); for(int i = 0; i &lt; len;i++)&#123; System.out.print("请输入第"+(i+1)+"个数:"); if(scanner.hasNextInt())&#123; int num = scanner.nextInt(); if(linkNode == null)&#123; linkNode = new LinkNode1(num); &#125; else&#123; LinkNode1 linkNode1 = linkNode; while (linkNode1.getNextNode1() != null)&#123; linkNode1 = linkNode1.getNextNode1(); &#125; linkNode1.setNextNode1(new LinkNode1(num)); &#125; &#125; else&#123; System.out.println("输入不合法"); &#125; &#125; &#125; scanner.close(); deleteRepateNode(linkNode); &#125; private static void deleteRepateNode(LinkNode1 linkNode) &#123; Integer temp = null; if(linkNode != null)&#123; LinkNode1 linkNode1 = linkNode; LinkNode1 linkNode12 = linkNode1; while (linkNode1 != null)&#123; if(temp == null)&#123; temp = linkNode1.getData(); linkNode12 = linkNode1; linkNode1 = linkNode1.getNextNode1(); &#125; else&#123; if(linkNode1.getData() == temp)&#123; linkNode12.setNextNode1(linkNode1.getNextNode1()); linkNode1 = linkNode12.getNextNode1(); &#125; else&#123; linkNode12 = linkNode1; temp = linkNode12.getData(); linkNode1 = linkNode1.getNextNode1(); &#125; &#125; &#125; System.out.println(linkNode); &#125; &#125;&#125;class LinkNode1&#123; private LinkNode1 nextNode; private Integer data; public LinkNode1(Integer data) &#123; this.data = data; &#125; public LinkNode1() &#123; &#125; public LinkNode1 getNextNode1() &#123; return nextNode; &#125; public void setNextNode1(LinkNode1 nextNode) &#123; this.nextNode = nextNode; &#125; public Integer getData() &#123; return data; &#125; public void setData(Integer data) &#123; this.data = data; &#125;&#125; 3. 割绳子给你一根长度为n的绳子，请把绳子剪成m段(m、n都是整数，n&gt;1并且m&gt;1),每段绳子的长度记为k[0],k[1], ,k[m]。请问k[0]xk[1]x…xk[m]可能的最大乘积是多少?例如，当绳子的长度是8时，我们把它剪成长度分别为2、3、3的三段，此时得到的最大乘积是18。解题思路：使用动态规划。使用动态规划是从上往下分析，然后解决的时候是从下往上的解决，即从最小的问题入手，然后逐渐解决大问题的过程。我们把最大乘积设置为f(n)，n表示绳子的长度。首先我们分析绳子的长度为1的时候，没办法剪(m、n都是整数)，所以为0,即f(1) = 0；绳子的长度为2的时候，只有一个剪的办法,分半剪，分别为1,乘积为1,即f(2)=1;绳子长度为3的时候，可以分割成1,2或者1,1,1，那么最大的是1,2乘积为2,则f(3)=2;依次类推。12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.nyist.offer;import java.util.Arrays;import java.util.List;import java.util.Scanner;public class CutStir &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); System.out.print("请输入绳子的长度:"); int len = scanner.nextInt(); int maxMulti = cutResult(len); System.out.println(maxMulti); &#125; //动态规划 private static int cutResult(int len) &#123; if(len == 1) return 0; else if(len == 2) return 1; else if(len == 3) return 2; int[] results = new int[len+1]; results[0] = 0; results[1] = 1; results[2] = 2; results[3] = 3; results[4] = 4; int max = 0; for(int i = 5;i &lt;= len;i++)&#123; max = 0; for(int j = 1;j &lt;= i/2;j++)&#123; int result = results[j] * results[i-j]; if(result &gt; max)&#123; max = result; &#125; &#125; results[i] = max; &#125; max = results[len]; return max; &#125;&#125; 总结: 为了重复计算，我们自下向上的计算，然后把计算的结果存放在数组中.其中results数组中下标0,1,2,3,4对应的值为1,2,3,4,其实是当n大于4的时候，对应的1,2,3,4是可以不分割的。这时候最大。 4. 用13的瓷砖密铺320的地板有几种方式用13的瓷砖密铺320的地板有几种方式解题思路：动态规划。3*n的问题，最后我们只需要把n设置成20即可解决问题。当n=1的时候，只有一种铺法，f(1)=1;当n=2的时候，两个都要竖着铺，则只有一个方法，即f(2)=1;当n=3的时候，竖着或者横着铺3个，有2种方法，即f(3)=2，那么如果n = n,那么首先如果我们使用横着铺，那么面积还剩余3(n-1)，如果竖着铺，则下面长度为2,和上面选择同样的方式，则右面的部分可以有其他的选择，选择面积3（n-3）,那么f(n) = (n-1)+(n-3)1234567891011121314151617181920212223242526272829303132package com.nyist.offer;import java.util.Scanner;/** * 关于铺瓷砖的问题 * 用1*3的瓷砖密铺3*20的地板有几种方式 */public class TilingProgram &#123; public static void main(String[] args) &#123; int n = 20; int way = tiling(n); System.out.println("共有"+way+"种方法！"); &#125; private static int tiling(int n) &#123; int[] ways = new int[n+1]; if(n == 0) return 1; if(n == 1) return 1; if(n == 2) return 1; if(n == 3) return 2; ways[0] = 1; ways[1] = 1; ways[2] = 1; ways[3] = 2; for(int i = 4; i &lt;= n;i++)&#123; ways[i] = ways[i-1]+ways[i-3]; &#125; return ways[20]; &#125;&#125; 5.调整数组的顺序使奇树位于偶数前面输入一个数组，实现一个函数来调整该数组的顺序，使得所有的奇数位于数组的前部，数组的偶数位于数组的后半部分**解题思路：我们解决这个问题可以使用辅助数组，那么空间复杂度为O(n),但是不是我们想要的结果，那么我们可以使用两个指向，一个指向数组的头部，一个指向数组的尾部，然后分别靠近，知道相遇再结束，靠近的过程中，如果左边的指向是奇数，那么++,右边的指向为偶数同样++,当两边相反的时候交换1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.nyist.offer;public class ChangeArr &#123; public static void main(String[] args) &#123; int[] arr = new int[]&#123;1,2,3,3,4,0,5,5,6,6,7&#125;; arr = doChange(arr); showResult(arr); &#125; private static void showResult(int[] arr) &#123; System.out.println("改变后的数组:"); for (int i : arr) &#123; System.out.print(i+" "); &#125; &#125; private static int[] doChange(int[] arr) &#123; int l = 0; int r = arr.length-1; while (true)&#123; if(l &gt;= r)&#123; break; &#125; if(isOk(arr[l]) &amp;&amp; isOk(arr[r]))&#123; l++; &#125; if(!isOk(arr[l]) &amp;&amp; isOk(arr[r]))&#123; int temp = arr[l]; arr[l] = arr[r]; arr[r] = temp; l++; r--; &#125; if(isOk(arr[l]) &amp;&amp; !isOk(arr[r]))&#123; l++; r--; &#125; if(!isOk(arr[l]) &amp;&amp; !isOk(arr[r]))&#123; r--; &#125; &#125; return arr; &#125; private static boolean isOk(int num) &#123; if(num % 2 != 0)&#123; return true; &#125; return false; &#125;&#125; 注: 考虑时间复杂度和空间复杂度，以及我们函数的相似部分的抽离，上述的问题是根据奇偶数把数组分成前后两部分，然后我们遇到下一个类型的题目，例如，根据是都是2的幂次方分成前后两部分，这时候我们只需要改写isOK函数的部分。 算法很有意思，渐渐修炼中…贵在坚持]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>常见算法题型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见算法题型(二)——Java实现]]></title>
    <url>%2F2019%2F04%2F04%2F%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95%E9%A2%98%E5%9E%8B(%E4%BA%8C)%E2%80%94%E2%80%94Java%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[常见算法题型(二)——Java实现1. 构建二叉排序树，并广度遍历解决方案：根据二叉排序树的定义，树的度最多为2,而且左子树小于根节点的值，右子树的值大于根节点的值。广度遍历的方式是利用队列的方式，把节点自上到下的方式把节点放入队列中，然后取出，把自身的值打印出来，把自身左右节点不为空的放入队列中，一直执行下去，直到二叉树节点不存在了并且队列中不存在元素的情况下，广度遍历结束。特别注意的是，定义树节点的时候有个属性len表示该节点的数据在二叉树中存在几个，即重复元素的处理方式。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134package com.nyist.offer;import java.util.ArrayDeque;import java.util.Queue;import java.util.Scanner;/** * 树的广度遍历 * 顺便构建二叉排序树 */public class TreeWideTraverse &#123; public static void main(String[] args) &#123; TreeNode node = new TreeNode(); TreeNode treeNode = createTreeNode(node); wideTraverse(treeNode); &#125; private static void wideTraverse(TreeNode node) &#123; Queue&lt;TreeNode&gt; queue = new ArrayDeque&lt;&gt;(); TreeNode qNode = null; if(node != null)&#123; queue.offer(node); qNode = queue.poll(); while (qNode != null)&#123; if(qNode.getLeftNode() != null)&#123; queue.offer(qNode.getLeftNode()); &#125; if(qNode.getRightNode() != null)&#123; queue.offer(qNode.getRightNode()); &#125; int i = 0; while(i &lt; qNode.getLen())&#123; System.out.print(qNode.getData()+" "); i++; &#125; qNode = queue.poll(); &#125; &#125; &#125; private static TreeNode createTreeNode(TreeNode node) &#123; System.out.println("请输入你需要创建树节点的个数："); Scanner scanner = new Scanner(System.in); int len = scanner.nextInt(); for(int i = 0;i &lt; len;i++)&#123; System.out.println("请输入你需要创建的第"+(i+1)+"个节点的数据："); int num = scanner.nextInt(); if(node.getData() == null)&#123; node = new TreeNode(num,1); &#125; else&#123; TreeNode inNode = node; while (inNode != null &amp;&amp; inNode.getData() != null)&#123; if(num &gt; inNode.getData())&#123; TreeNode bNode = inNode; inNode = inNode.getRightNode(); if(inNode == null)&#123; bNode.setRightNode(new TreeNode(num,1)); &#125; &#125; else if(num &lt; inNode.getData())&#123; TreeNode bNode = inNode; inNode = inNode.getLeftNode(); if(inNode == null)&#123; bNode.setLeftNode(new TreeNode(num,1)); &#125; &#125; else&#123; inNode.setLen(inNode.getLen()+1); break; &#125; &#125; &#125; &#125; return node; &#125;&#125;class TreeNode&#123; private Integer data; private TreeNode leftNode; private TreeNode rightNode; //标记重复的元素 private Integer len = 0; public TreeNode(Integer data, Integer len) &#123; this.data = data; this.len = len; &#125; public TreeNode() &#123; &#125; public Integer getData() &#123; return data; &#125; public void setData(Integer data) &#123; this.data = data; &#125; public TreeNode getLeftNode() &#123; return leftNode; &#125; public Integer getLen() &#123; return len; &#125; public void setLen(Integer len) &#123; this.len = len; &#125; public void setLeftNode(TreeNode leftNode) &#123; this.leftNode = leftNode; &#125; public TreeNode getRightNode() &#123; return rightNode; &#125; public void setRightNode(TreeNode rightNode) &#123; this.rightNode = rightNode; &#125;&#125; 2.重构二叉树2.1 根据先序遍历结果和中序遍历结果进行重构二叉树解题思路：首先知道先序遍历A集合，那么A的第一个元素就是树的根节点，接着根据根节点去中序遍历集合B中找根节点位置，得到index，然后在集合B中，index的左侧是根节点的左子树部分，index的右侧是右子树部分，然后采用递归的部分，进而分别将左右子树部分再细分为左右子树，最后得到整个树的结构12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package com.nyist.offer;import java.util.Arrays;public class RebuildBinaryTree &#123; public static void main(String[] args) &#123; int[] preTraverse = &#123;1,2,4,7,3,5,6,8&#125;; int[] inTraverse = &#123;4,7,2,1,5,3,8,6&#125;; TreeNode node = reBuildTree(preTraverse, inTraverse); System.out.println(node); &#125; private static TreeNode reBuildTree(int[] preTraverse, int[] inTraverse) &#123; if(preTraverse.length == 0 || inTraverse.length == 0)&#123; return null; &#125; TreeNode node = new TreeNode(preTraverse[0]); int index = -1; for(int i = 0;i &lt; inTraverse.length;i++)&#123; if(inTraverse[i] == node.getData())&#123; index = i; break; &#125; &#125; int[] leftPre = Arrays.copyOfRange(preTraverse,1,index+1); int[] leftIn = Arrays.copyOfRange(inTraverse,0,index); int[] rightPre = Arrays.copyOfRange(preTraverse,index+1,preTraverse.length); int[] rightIn = Arrays.copyOfRange(inTraverse,index+1, inTraverse.length); node.setLeftNode(reBuildTree(leftPre,leftIn)); node.setRightNode(reBuildTree(rightPre,rightIn)); return node; &#125;&#125;class TreeNode&#123; private Integer data; private TreeNode leftNode; private TreeNode rightNode; public TreeNode(Integer data) &#123; this.data = data; &#125; public TreeNode() &#123; &#125; public Integer getData() &#123; return data; &#125; public void setData(Integer data) &#123; this.data = data; &#125; public TreeNode getLeftNode() &#123; return leftNode; &#125; public void setLeftNode(TreeNode leftNode) &#123; this.leftNode = leftNode; &#125; public TreeNode getRightNode() &#123; return rightNode; &#125; public void setRightNode(TreeNode rightNode) &#123; this.rightNode = rightNode; &#125;&#125; 2.2 根据后序遍历结果和中序遍历结果进行重构二叉树12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package com.nyist.offer;import java.util.Arrays;public class RebuildBinaryTree &#123; public static void main(String[] args) &#123; int[] preTraverse = &#123;1,2,4,7,3,5,6,8&#125;; int[] inTraverse = &#123;4,7,2,1,5,3,8,6&#125;; int[] postTraverse = &#123;7,4,2,5,8,6,3,1&#125;; TreeNode node = reBuildTree(inTraverse, postTraverse); System.out.println(node); &#125; private static TreeNode reBuildTree(int[] inTraverse, int[] postTraverse) &#123; if(inTraverse.length == 0|| postTraverse.length == 0)&#123; return null; &#125; TreeNode node = new TreeNode(postTraverse[postTraverse.length-1]); int index = -1; for(int i = 0;i &lt; inTraverse.length;i++)&#123; if(node.getData() == inTraverse[i])&#123; index = i; break; &#125; &#125; int[] leftPost = Arrays.copyOfRange(postTraverse,0,index); int[] rigthPost = Arrays.copyOfRange(postTraverse,index,postTraverse.length-1); int[] leftIn = Arrays.copyOfRange(inTraverse,0,index); int[] rightIn = Arrays.copyOfRange(inTraverse,index+1,inTraverse.length); node.setLeftNode(reBuildTree(leftIn,leftPost)); node.setRightNode(reBuildTree(rightIn,rigthPost)); return node; &#125;&#125;class TreeNode&#123; private Integer data; private TreeNode leftNode; private TreeNode rightNode; public TreeNode(Integer data) &#123; this.data = data; &#125; public TreeNode() &#123; &#125; public Integer getData() &#123; return data; &#125; public void setData(Integer data) &#123; this.data = data; &#125; public TreeNode getLeftNode() &#123; return leftNode; &#125; public void setLeftNode(TreeNode leftNode) &#123; this.leftNode = leftNode; &#125; public TreeNode getRightNode() &#123; return rightNode; &#125; public void setRightNode(TreeNode rightNode) &#123; this.rightNode = rightNode; &#125;&#125; 3.用两个栈实现队列题目：用两个栈实现一个队列，在函数的appendTail和deleteHead方法内部完成队列尾部插入数据和队列首部删除节点的功能 解题思路：自定义栈，里面有实现扩容的部分，定义了栈的先进后出的规定，两个栈结合起来，stack1负责存储，stack2负责模拟队列在首部取出数据的方式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111package com.nyist.offer;import java.util.Arrays;import java.util.Scanner;public class StackOperate &#123; public static void main(String[] args) &#123; MyQueue queue = new MyQueue(); Scanner scanner = new Scanner(System.in); System.out.println("请输入队列的长度:"); int len = scanner.nextInt(); for(int i = 0;i &lt; len;i++)&#123; System.out.print("请输入队列第"+(i+1)+"个数据:"); Integer numData = scanner.nextInt(); queue.appendTail(numData); &#125; for(int i = 0;i &lt; len;i++)&#123; Integer num = queue.deleteHead(); System.out.println("取出队列第"+(i+1)+"个元素为:"+num); &#125; &#125;&#125;class MyQueue&#123; private MyStack stack1 = new MyStack(); private MyStack stack2 = new MyStack(); public void appendTail(Integer data)&#123; if(stack1.getCount() == 0 &amp;&amp; stack2.getCount() != 0)&#123; int len = stack1.getCount(); for(int i = 0;i &lt; len;i++)&#123; stack1.push(stack2.pop()); &#125; stack2 = new MyStack(); stack2.setCount(0); &#125; stack1.push(data); &#125; public Integer deleteHead()&#123; if(stack2.getCount() == 0 &amp;&amp; stack1.getCount() != 0)&#123; int len = stack1.getCount(); for(int i = 0;i &lt; len;i++)&#123; stack2.push(stack1.pop()); &#125;; stack1 = new MyStack(); stack1.setCount(0); &#125; Integer num = stack2.pop(); return num; &#125; public MyStack getStack1() &#123; return stack1; &#125; public void setStack1(MyStack stack1) &#123; this.stack1 = stack1; &#125; public MyStack getStack2() &#123; return stack2; &#125; public void setStack2(MyStack stack2) &#123; this.stack2 = stack2; &#125;&#125;class MyStack&#123; private int len = 10; private Integer[] arr = new Integer[len]; private int count = 0; public int getCount() &#123; return count; &#125; public void setCount(int count) &#123; this.count = count; &#125; public void push(int num)&#123; if(count &gt;= arr.length)&#123; int newLen = arr.length+(arr.length&gt;&gt;1); Integer[] newArr = new Integer[newLen]; System.arraycopy(arr,0,newArr,0,count); arr = newArr; &#125; arr[count] = num; count++; &#125; public Integer pop()&#123; Integer v = null; if(count &gt;= 0)&#123; v = arr[--count]; return v; &#125; else&#123; return null; &#125; &#125;&#125; 4.求斐波那契问题题目：在不使用递归的条件下，求出输入的Num值的斐波那契值。解题思路： 首先分析斐波那契规律，除了第一二项之外，其他项都等于前两项的和，因此，我们可以反复循环赋值的方式来处理这个问题。12345678910111213141516171819202122232425262728293031323334353637package com.nyist.offer;import java.util.Scanner;public class FibonacciSolution &#123; public static void main(String[] args) &#123; System.out.println("请输入你需要求斐波那契数字："); Scanner scanner = new Scanner(System.in); int num = scanner.nextInt(); int result = getFibonacciResult(num); System.out.println(num+"斐波那契结果是:"+result); &#125; private static int getFibonacciResult(int num) &#123; if(num &gt; 0)&#123; if(num == 1 || num == 2)&#123; return 1; &#125; else&#123; int i = 2; int num1 = 1, num2 = 1; int result = 0; while (i &lt; num)&#123; result = num1 + num2; num1 = num2; num2 = result; i++; &#125; return result; &#125; &#125; return 0; &#125;&#125; 5. 青蛙跳台问题(斐波那契规律)题目：一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共需要多少种跳法。解题思路：首先考虑n等于0、1、2时的特殊情况，f(0) = 0 f(1) = 1 f(2) = 2 其次，当n=3时，青蛙的第一跳有两种情况：跳1级台阶或者跳两级台阶，假如跳一级，那么 剩下的两级台阶就是f(2)；假如跳两级，那么剩下的一级台阶就是f(1)，因此f(3)=f(2)+f(1) 当n = 4时，f(4) = f(3) +f(2),以此类推………..可以联想到Fibonacci数列。采用非递归的方式实现12345678910111213141516171819202122232425262728293031323334353637383940414243package com.nyist.offer;import java.util.Scanner;public class FibonacciSolution &#123; public static void main(String[] args) &#123; System.out.println("青蛙跳台的阶数："); Scanner scanner = new Scanner(System.in); int num = scanner.nextInt(); int result = getFibonacciResult(num); System.out.println(num+"青蛙跳法共有:"+result+"种"); &#125; private static int getFibonacciResult(int num) &#123; if(num &gt; 0)&#123; if(num == 0)&#123; return 0; &#125; else if(num == 1)&#123; return 1; &#125; else if(num == 2)&#123; return 2; &#125; else&#123; int i = 2; int num1 = 1, num2 = 2; int result = 0; while (i &lt; num)&#123; result = num1 + num2; num1 = num2; num2 = result; i++; &#125; return result; &#125; &#125; return 0; &#125;&#125; 算法很有趣，继续攻破更多的算法题，目前已经上瘾…]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>常见算法题型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见算法题型(一)——Java实现]]></title>
    <url>%2F2019%2F04%2F04%2F%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95%E9%A2%98%E5%9E%8B(%E4%B8%80)%E2%80%94%E2%80%94Java%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[常见算法题型(一)——Java实现1. 找出链表中倒数第K个数字解决方案： 我们可以使用两个指向，一个指向链表头部的链表节点A，一个指向第K-1个链表节点B，接着B节点循环直到为null的时候，同时A节点也在循环，B节点为空的时候，A节点所在节点就是倒数第K个节点1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package com.nyist.offer;import java.util.Scanner;import java.util.regex.Matcher;import java.util.regex.Pattern;public class LinkFindK &#123; public static void main(String[] args) &#123; InputData(); &#125; private static void outputData(LinkNode linkNode) &#123; System.out.print("链表中的顺序是: "); while (linkNode != null)&#123; if(linkNode.getData() != null)&#123; System.out.print(linkNode.getData()+" "); &#125; linkNode = linkNode.getNextNode(); &#125; &#125; private static void InputData() &#123; Scanner scanner = new Scanner(System.in); LinkNode linkNode = new LinkNode(); System.out.println("请输入你想创建链表的长度："); Integer len = scanner.nextInt(); if(len &gt; 0)&#123; for(int i = 0;i &lt; len;i++)&#123; System.out.println("请输入"+(i+1)+"个链表的数字:"); Integer num = scanner.nextInt(); LinkNode pNode = new LinkNode(num); LinkNode linkNode1 = linkNode; //找到最后一个节点，然后再追加 while (linkNode1.getNextNode() != null)&#123; linkNode1 = linkNode1.getNextNode(); &#125; pNode.setNextNode(linkNode1.getNextNode()); linkNode1.setNextNode(pNode); &#125; &#125; System.out.println("输入完毕！"); outputData(linkNode); System.out.println("链表的哪个倒数节点?"); Integer rIndex = scanner.nextInt(); findK(rIndex,linkNode); &#125; private static void findK(Integer K,LinkNode linkNode)&#123; LinkNode aNode; int i = 0; LinkNode linkNode1 = linkNode; while (linkNode1 != null &amp;&amp; i &lt; K)&#123; linkNode1 = linkNode1.getNextNode(); i++; &#125; aNode = linkNode1; while (linkNode1 != null)&#123; linkNode1 = linkNode1.getNextNode(); linkNode = linkNode.getNextNode(); &#125; System.out.println(linkNode.getData()); &#125;&#125;class LinkNode&#123; private Integer data; private LinkNode nextNode; public LinkNode(Integer data) &#123; this.data = data; &#125; public LinkNode() &#123; &#125; public Integer getData() &#123; return data; &#125; public void setData(Integer data) &#123; this.data = data; &#125; public LinkNode getNextNode() &#123; return nextNode; &#125; public void setNextNode(LinkNode nextNode) &#123; this.nextNode = nextNode; &#125;&#125; 注：一定注意K的大小是否在链表长度范围之内！ 2.找出数组中重复的数字 在一个长度为n的数组里的所有数字都在0~n-1的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。例如，如果输入长度为7的数组{2,3,1,0,2,5,3},那么对应的输出是重复的数字2或者3。解题思路：我们可以将数组进行排序，然后挨个查找，也可以使用hash表（时间复杂度o(1),空间复杂度o(n)），但时间和空间复杂度都不是很理想，所以我们根据审题就可以知道数字在0~n-1,那么一个下标，要么没有元素，要么重复元素，所以解决思路如下：首先从第一个开始遍历，下标为i,看当前下标的元素是否v和下标i相等，如果相等，就继续遍历下一个元素，如果不等，则找出下标为v的元素，判断下标为v的元素k是否和v值相等，如果相等，则说明值为v元素出现重复，如果不相等，则进行交换元素，接着仍然对下标为i元素重复上面操作。123456789101112131415161718192021222324252627282930313233343536package com.nyist.offer;public class FindRepateNum &#123; public static void main(String[] args) &#123; Integer[] nums = &#123;1,2,3,3,5,6,7,0&#125;; FindRepateNumMethod(nums); &#125; private static void FindRepateNumMethod(Integer[] nums) &#123; for(int i = 0;i &lt; nums.length;i++)&#123; int v = nums[i]; if(v == i)&#123; continue; &#125; else&#123; //针对于数组中的数字不在相应范围内的问题 if(v &gt;= nums.length)&#123; System.out.println("数组中的数字 "+v+" 不在0~"+(nums.length-1)+"之内"); break; &#125; int k = nums[v]; if(k == v)&#123; System.out.println("数字 "+k+" 出现了重复!"); continue; &#125; else&#123; int temp = nums[v]; nums[v] = nums[i]; nums[i] = temp; i--; &#125; &#125; &#125; &#125;&#125; 3.根据输入构建哈夫曼树解题思路：哈夫曼树的构建原理是，每次都取最小的两个数字，然后把它们合并在一起，把合并后的数字放在数组中，然后把对应的两个数从数组中去除，两个数字分别作为新数组数字的左右子树。以此类推，每次都取出最小的两个数字123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145package com.nyist.offer;import java.util.ArrayList;import java.util.Collections;import java.util.Comparator;import java.util.Scanner;public class HafManDemo &#123; public static void main(String[] args) &#123; ArrayList&lt;DataNode&gt; list = new ArrayList&lt;&gt;(); TreeNode node = new TreeNode(); InputData(list); TreeNode node3 = buildHafTree(list, node); &#125; private static TreeNode buildHafTree(ArrayList list,TreeNode node3) &#123; while (list.size() &gt; 0)&#123; Collections.sort(list, new Comparator&lt;DataNode&gt;() &#123; @Override public int compare(DataNode o1, DataNode o2) &#123; if(o1.getData() &gt; o2.getData())&#123; return 1; &#125;else if(o1.getData() &lt; o2.getData())&#123; return -1; &#125;else&#123; return 0; &#125; &#125; &#125;); DataNode dataNode1 = (DataNode) list.get(0); if(list.size() == 1)&#123; if(dataNode1.getNode() == null)&#123; node3 = new TreeNode(dataNode1.getData()); &#125; return node3; &#125; DataNode dataNode2 = (DataNode) list.get(1); TreeNode node1,node2; if(dataNode1.getNode() == null)&#123; node1 = new TreeNode(dataNode1.getData()); &#125;else&#123; node1 = dataNode1.getNode(); &#125; if(dataNode2.getNode() == null)&#123; node2 = new TreeNode(dataNode2.getData()); &#125;else&#123; node2 = dataNode2.getNode(); &#125; node3 = new TreeNode(dataNode1.getData()+dataNode2.getData(),node1,node2); list.remove(dataNode1); list.remove(dataNode2); list.add(new DataNode((dataNode1.getData()+dataNode2.getData()),node3)); &#125; return node3; &#125; private static void InputData(ArrayList list) &#123; System.out.println("请输入你要创建哈夫曼树的节点个数:"); Scanner scanner = new Scanner(System.in); int len = scanner.nextInt(); for(int i = 0;i &lt; len;i++)&#123; System.out.println("请输入第"+(i+1)+"个的节点数据:"); int num = scanner.nextInt(); list.add(new DataNode(num,null)); &#125; &#125;&#125;class TreeNode&#123; private Integer data; private TreeNode lTreeNode; private TreeNode rTreeNode; public TreeNode(Integer data) &#123; this.data = data; &#125; public TreeNode(Integer data, TreeNode lTreeNode, TreeNode rTreeNode) &#123; this.data = data; this.lTreeNode = lTreeNode; this.rTreeNode = rTreeNode; &#125; public TreeNode() &#123; &#125; public Integer getData() &#123; return data; &#125; public void setData(Integer data) &#123; this.data = data; &#125; public TreeNode getlTreeNode() &#123; return lTreeNode; &#125; public void setlTreeNode(TreeNode lTreeNode) &#123; this.lTreeNode = lTreeNode; &#125; public TreeNode getrTreeNode() &#123; return rTreeNode; &#125; public void setrTreeNode(TreeNode rTreeNode) &#123; this.rTreeNode = rTreeNode; &#125;&#125;class DataNode&#123; private Integer data; private TreeNode node; public DataNode(Integer data, TreeNode node) &#123; this.data = data; this.node = node; &#125; public Integer getData() &#123; return data; &#125; public void setData(Integer data) &#123; this.data = data; &#125; public TreeNode getNode() &#123; return node; &#125; public void setNode(TreeNode node) &#123; this.node = node; &#125;&#125; 4. 二维数组的查找在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的个二维数组和一个整数，判断数组中是否含有该整数。解题思路：根据二维数组中数字是行列都是有序的，所以我们可以首先定位到右上角的元素进行逐步定位所查找的元素，假如比右上角的大，那么所在行将被排除，如果比右上角小，那么排除最右面的一列，逐渐，二维数组被排除一部分之后，逐步缩小区域，当二维数组只有最后一个元素也没有找到，那么表示不存在。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package com.nyist.offer;import java.util.Scanner;public class FindNumByTwoArray &#123; public static void main(String[] args) &#123; int[][] arr = &#123;&#123;1,2,8,9&#125;,&#123;2,4,9,12&#125;,&#123;4,7,10,13&#125;,&#123;6,8,11,15&#125;&#125;; Scanner scanner = new Scanner(System.in); System.out.println("请输入你要查询的数字:"); int num = scanner.nextInt(); Node node = findNum(arr, num); if(node == null)&#123; System.out.println("没有找到数字"+num); &#125; else &#123; System.out.println("找到了数字:"+num+",位置在第"+node.getRow()+"行-&gt;第"+node.getCol()+"列！"); &#125; &#125; private static Node findNum(int[][] arr, int num) &#123; int row = arr.length; int col = arr[0].length; int row0 = 0; int col0 = 0; Node node = null; while (true)&#123; if(col &lt;= 0 || row0 &gt;= row)&#123; break; &#125; if(arr[row0][col-1] == num)&#123; node = new Node(row0+1,col,true); break; &#125; else if(arr[row0][col-1] &lt; num)&#123; row0++; &#125; else&#123; col--; &#125; &#125; return node; &#125;&#125;class Node&#123; private int row; private int col; private Boolean isFind; public Node(int row, int col, Boolean isFind) &#123; this.row = row; this.col = col; this.isFind = isFind; &#125; public Boolean getFind() &#123; return isFind; &#125; public void setFind(Boolean find) &#123; isFind = find; &#125; public int getRow() &#123; return row; &#125; public void setRow(int row) &#123; this.row = row; &#125; public int getCol() &#123; return col; &#125; public void setCol(int col) &#123; this.col = col; &#125;&#125; 注：我们可以选取右上角和左下角的元素作为起点开始以缩小二维数组的方式来定位查找的元素。但是不能从左上角和右下角开始，因为加入所找元素不等于第一个，而是大于第一个元素，那么我们将不知道是从此元素的右面或者下面继续定位元素了。 5.从尾到头打印链表输入一个链表的头节点，从尾到头反过来打印出每个节点的值。解题思路：首先我在不修改链表的前提下，我们审题发现要求倒着打印出链表的数据，因此和栈的数据结构很匹配，因此我们可以使用递归(空间复杂度很高，底层是栈)来解决上述问题1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.nyist.offer;import java.util.Scanner;public class PrintLinkNodeReverse &#123; public static void main(String[] args) &#123; PrintNode node = new PrintNode(); PrintNode printNode = createLinkNode(node); reversePrintNode(printNode); &#125; private static void reversePrintNode(PrintNode node) &#123; if(node != null)&#123; if(node.getNextNode() != null)&#123; reversePrintNode(node.getNextNode()); &#125; System.out.print(node.getData()+" "); &#125; &#125; private static PrintNode createLinkNode(PrintNode node) &#123; Scanner scanner = new Scanner(System.in); System.out.println("请输入你要创建链表的长度："); int len = scanner.nextInt(); for(int i = 0;i &lt; len;i++)&#123; System.out.println("请输入链表第"+(i+1)+"个元素:"); int num = scanner.nextInt(); if(node.getData() == null)&#123; node = new PrintNode(num); &#125; else&#123; PrintNode inNode = node; while (inNode.getNextNode() != null)&#123; inNode = inNode.getNextNode(); &#125; PrintNode nNode = new PrintNode(num); nNode.setNextNode(inNode.getNextNode()); inNode.setNextNode(nNode); &#125; &#125; return node; &#125;&#125;class PrintNode&#123; private Integer data; private PrintNode printNode; public PrintNode() &#123; &#125; public PrintNode(Integer data) &#123; this.data = data; &#125; public Integer getData() &#123; return data; &#125; public void setData(Integer data) &#123; this.data = data; &#125; public PrintNode getNextNode() &#123; return printNode; &#125; public void setNextNode(PrintNode printNode) &#123; this.printNode = printNode; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>常见算法题型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[canal实现同步]]></title>
    <url>%2F2019%2F04%2F01%2Fcanal%E5%AE%9E%E7%8E%B0%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[数据同步的问题——Canal常常我们在一个大型分布式系统中会有redis、solr、mysql等各种数据库，往往nosql数据库都是从mysql总获取数据，那在系统运行中如何保证数据的同步呢？我们常常有以下三种 利用业务代码实现同步往往在删除或者修改之后，执行逻辑代码实现同步。 优点：操作简单缺点：1. 业务耦合度太高 2. 执行效率变低 利用定时器来实现同步(SpringTask、Quartz)在数据库添加一个时间戳字段，然后每次定时执行任务，查询最后一个时间之后的数据变化然后同步到各个nosql数据库中。优点：和业务代码实现了解耦缺点： 数据的实时性不高 通过MQ实现同步当执行完删除或者修改操作之后，发送消息到消息中间件，然后消费者接收到消息，执行同步逻辑优点：业务逻辑解耦，可以做到准实时缺点： 还是要在业务代码中加入发送消息的代码，API耦合 通过Canal来实现实时同步(阿里巴巴技术)通过Canal来解析数据库的日志信息，来检测数据库中表结构的数据变化，从而更新Nosql数据库优点：业务逻辑解耦，可以做到准实时，API完全解耦 Canal深入学习介绍canal的github地址点我去下载地址 内部组成其中 server代表一个canal运行实例，对应一个jvm,Instance对应一个数据队列(可能有多个) 接着instance下的三个子模块关系 EventParser: 数据源接入，模拟slave协议和master进行交互,协议解析EventSink: Parser和Store的链接器，进行数据的过滤、加工、分发的工作EventStore: 数据的存储 进行canal搭建canal原理利用mysql binlog技术，所以要开启Binlog写入功能，建议binlog模式为row；1234567mysql&gt; show variables like &apos;binlog_format&apos;;+---------------+-----------+| Variable_name | Value |+---------------+-----------+| binlog_format | STATEMENT |+---------------+-----------+1 row in set (0.00 sec) 通过查询我们可以看出默认是STATEMENT,所以我们需要设置成row 然后接着我们可以进行配置 123456781. 在linux中复制一份conf到/etc下 cp/usr/share/mysql/my-default.cnf /etc/my.cnf2. 修改etc下的 my.cnlog-bin=mysql-bin binlog_format=ROW server_id=1f3.然后重启mysql service mysql restart 由于canal底层和主从相近，所以我们需要创建一个用户 1234561. 创建一个用户root1密码root1CREATE USER root1@&apos;localhost&apos; IDENTIFIED BY &apos;root1&apos;;2. 赋予查询权限(slave只复制读操作)GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO &apos; root1&apos;@&apos;localhost&apos;;3. 刷新权限FLUSH PRIVILEGES; 上传解压 canal.deployer-1.0.24.tar.gz，我解压到了/usr/local/canal下目录下编辑 canal/conf/example/instance.properties : 选项含义:1) canal.instance.mysql.slaveId : mysql 集群配置中的 serverId 概念，需要保证和当前 mysql 集群中 id 唯一;2) canal.instance.master.address: mysql 主库链接地址;3) canal.instance.dbUsername : mysql 数据库帐号4) canal.instance.dbPassword : mysql 数据库密码;5) canal.instance.defaultDatabaseName : mysql 链接时默认数据库;6) canal.instance.connectionCharset : mysql 数据解析编码;7) canal.instance.filter.regex : mysql 数据解析关注的表，Perl 正则表达 接下来我们启动canalcd /usr/local/canal/bin/startup.sh启动之后进入/usr/local/canal/logs/example，然后查询日志tail -f example.log 然后我们根据官方一个的测试工程12345678910111213141516171819202122232425262728293031323334353637383940414243package com.alibaba.otter.canal.example;import java.net.InetSocketAddress;import org.apache.commons.lang.exception.ExceptionUtils;import com.alibaba.otter.canal.client.CanalConnector;import com.alibaba.otter.canal.client.CanalConnectors;import com.alibaba.otter.canal.common.utils.AddressUtils;public class SimpleCanalClientTest extends AbstractCanalClientTest &#123; public SimpleCanalClientTest(String destination)&#123; super(destination); &#125; public static void main(String args[]) &#123; // 根据ip，直接创建链接，无HA的功能 String destination = "example"; CanalConnector connector = CanalConnectors.newSingleConnector(new InetSocketAddress("192.168.13.130", 11111), destination, "", ""); final SimpleCanalClientTest clientTest = new SimpleCanalClientTest(destination); clientTest.setConnector(connector); clientTest.start(); Runtime.getRuntime().addShutdownHook(new Thread() &#123; public void run() &#123; try &#123; logger.info("## stop the canal client"); clientTest.stop(); &#125; catch (Throwable e) &#123; logger.warn("##something goes wrong when stopping canal:\n&#123;&#125;", ExceptionUtils.getFullStackTrace(e)); &#125; finally &#123; logger.info("## canal client is down."); &#125; &#125; &#125;); &#125;&#125; InetSocketAddress修改自己服务器ip然后创建了canaldb表之后 执行插入语句后12INSERT INTO tb_book(NAME , author , publishtime , price , publishgroup) VALUES('白帽子讲安全协议 2','吴瀚请',NOW(),99.00,'电子工业出版社'); 执行之后，控制台打印出对应的日志过程基本上使用上结束 canal实现redis工程已经在gitub上，大家可以download下来运行在idea上，点我去下载]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>canal整合redis实现同步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring底层巩固]]></title>
    <url>%2F2019%2F03%2F31%2FSpring%E5%BA%95%E5%B1%82%E5%B7%A9%E5%9B%BA%2F</url>
    <content type="text"><![CDATA[Spring底层巩固BeanFactory ApplicationContextBeanFactoryBeanFactory实际上是实例化，配置和管理众多bean的容器。这些bean通常会彼此合作，因而他们之间会产生依赖。Spring使用BeanFactory来实例化、配置、管理Bean，是IOC容器的核心接口，定义了IOC的基本功能。 切记BeanFactory只管理单例Bean的生命周期。它不能管理原型(prototype,非单例)Bean 的生命周期。因为原型Bean实例被创建之后便被传给了客户端，容器失去了对它们的引用。 ApplicationContextApplicationContext由BeanFactory派生而来，提供了更多面向实际应用的功能。在BeanFactory中，很多功能需要以编程的方式实现，而在ApplicationContext中则可以通过配置实现。由于ApplicationContext是BeanFactor的派生，则拥有BeanFactory的所有功能，另外增加了更多的扩展 增加了如下的扩展: MessageSource, 提供国际化的消息访问 资源访问，如URL和文件 事件传播特性，即支持aop特性 载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的web层 ApplicationContext：是IOC容器另一个重要接口， 它继承了BeanFactory的基本功能， 同时也继承了容器的高级功能，如：MessageSource（国际化资源接口）、ResourceLoader（资源加载接口）、ApplicationEventPublisher（应用事件发布接口） BeanFactory ApplicationContext区别 BeanFactroy采用的是延迟加载形式来注入Bean的，即只有在使用到某个Bean时(调用getBean())，才对该Bean进行加载实例化，这样，我们就不能发现一些存在的Spring的配置问题。而ApplicationContext则相反，它是在容器启动时，一次性创建了所有的Bean。这样，在容器启动时，我们就可以发现Spring中存在的配置错误。 相对于基本的BeanFactory，ApplicationContext 唯一的不足是占用内存空间。当应用程序配置Bean较多时，程序启动较慢。BeanFacotry延迟加载,如果Bean的某一个属性没有注入，BeanFacotry加载后，直至第一次使用调用getBean方法才会抛出异常；而ApplicationContext则在初始化自身是检验，这样有利于检查所依赖属性是否注入；所以通常情况下我们选择使用 ApplicationContext。应用上下文则会在上下文启动后预载入所有的单实例Bean。通过预载入单实例bean ,确保当你需要的时候，你就不用等待，因为它们已经创建好了。 BeanFactory和ApplicationContext都支持BeanPostProcessor、BeanFactoryPostProcessor的使用，但两者之间的区别是：BeanFactory需要手动注册，而ApplicationContext则是自动注册。 Bean的生命周期关于Bean的初始化和销毁，可以有以下方法 跟源码之后，发现BeanPostProcess源码之后，内部原理 在spring中有很多地方用到了BeanPostProcess原理,例如:1.@Sync注解2.@PostConstruct,@PreDesrory3.@Autowired4.类实现ApplicationContextAware往类中注入ioc容器(ApplicationContext) 这篇博客，关于Bean的生命周期流程图写的很好，借鉴一下,自己跟底层源码证实了正确性！ BeanFactoryAware和BeanNameAware 实现 BeanFactoryAware 接口的 bean 可以直接访问 Spring 容器，被容器创建以后，它会拥有一个指向 Spring 容器的引用。 BeanFactoryAware 接口只有一个方法void setBeanFactory(BeanFactorybeanFactory)。配置和一般的bean一样。 如果某个 bean 需要访问配置文件中本身的 id 属性，则可以使用 BeanNameAware 接口，该接口提供了回调本身的能力。实现该接口的 bean，能访问到本身的 id 属性。该接口提供一个方法:void setBeanName(String name)。 Spring 提供了以下 5 中标准的事件1.上下文更新事件（ContextRefreshedEvent）：该事件会在 ApplicationContext 被初始化或者更新时发布。也可以在调用 ConfigurableApplicationContext 接口中的 refresh()方法时被触发。2.上下文开始事件（ContextStartedEvent）：当容器调用ConfigurableApplicationContext的 Start()方法开始/重新开始容器时触发该事件。3.上下文停止事件（ContextStoppedEvent）：当容器调用ConfigurableApplicationContext的 Stop()方法停止容器时触发该事件。4.上下文关闭事件（ContextClosedEvent）：当 ApplicationContext 被关闭时触发该事件。容器被关闭时，其管理的所有单例 Bean 都被销毁。5.请求处理事件（RequestHandledEvent）：在 Web 应用中，当一个 http 请求（request）结束触发该事件。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring底层原理</tag>
        <tag>spring事件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud Stream]]></title>
    <url>%2F2019%2F03%2F30%2FSpringCloud-Stream%2F</url>
    <content type="text"><![CDATA[SpringCloud StreamSpringCloud Stream（消息驱动微服务的框架）先上官方的一张图从图中我们可以看出，应用程序通过inputs和outputs来与SpringCloud Stream中的binder交互，接着springcloud的binder来和消息中间件实现交互！SpringCloud Stream为供应商的消息中间件产品提供了个性化的自动化配置实现，引用了发布—订阅，消费组，分区的三个核心概念。目前只支持RabbitMQ,Kafka.在我看来，主要为了简化开发，开发者只关注业务即可。 既然有Rabbit、Kafka，为什么还要SpringCloud Stream消息驱动呢? 比方说我们用到了RabbitMQ和Kafka，由于这两个消息中间件的架构上的不同，像RabbitMQ有exchange，kafka有Topic，partitions分区，这些中间件的差异性导致我们实际项目开发给我们造成了一定的困扰，我们如果用了两个消息队列的其中一种，后面的业务需求，假如想往另外一种消息队列进行迁移，这时候无疑就是一个灾难性的，一大堆东西都要重新推倒重新做，因为它跟我们的系统耦合了，这时候springcloud Stream给我们提供了一种解耦合的方式。 如何实现呢，实操来体会 首先在对应的服务的pom.xml中引入依赖(我使用的底层是RabbitMQ) 1234 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt;&lt;/dependency&gt; 然后我们定义一个接口123456789101112131415161718public interface StreamClient &#123; String INPUT = "myMessage"; String INPUT2 = "myMessage2"; @Input(INPUT) SubscribableChannel input(); @Output(INPUT) MessageChannel output(); @Input(INPUT2) SubscribableChannel input2(); @Output(INPUT2) MessageChannel output2();&#125; 接着我们实现消息的接受者 其中的 @SendTo注解表示接收到消息并且返回给消息队列，然后@StreamListener(StreamClient.INPUT2)捕获到12345678910111213141516@Component@EnableBinding(StreamClient.class)public class StreamReceiver &#123; @SendTo(StreamClient.INPUT2) @StreamListener(StreamClient.INPUT) public String process(Object message)&#123; System.out.println("消息是:"+message); return "received"; &#125; @StreamListener(StreamClient.INPUT2) public void getMsg(Object msg)&#123; System.out.println("接受到并返回:"+msg); &#125;&#125; 如何设置发送者呢其中MessageBuilder是org.springframework.messaging.support.MessageBuilder该包下的12345@GetMapping("/sendMessage")public void process()&#123; String msg = "复习springcloud的 stream用法"; streamClient.output().send(MessageBuilder.withPayload(msg).build());&#125; 基本上介绍都差不多了但是我们往往希望在rabbitMQ软件中也可以看出消息具体内容，所以我们可以这样在yml中配置123456spring: cloud: stream: bindings: myMessage: content-type: application/json]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>SpringCloud Stream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[复习查漏补缺（一）]]></title>
    <url>%2F2019%2F03%2F30%2F%E5%A4%8D%E4%B9%A0%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[复习查漏补缺（一）Nginx和Ribbon的比较服务器端负载均衡 Nginxnginx 是客户端所有请求统一交给 nginx，由 nginx 进行实现负载均衡请求转发，属于服务器端负载均衡。 既请求由 nginx 服务器端进行转发 客户端负载均衡 RibbonRibbon 是从 eureka 注册中心服务器端上获取服务注册信息列表，缓存到本地，然后在本地实现轮询负载均衡策略。 既在客户端实现负载均衡。 有关Feign和Ribbonspring-cloud-starter-feign 里面已经包含了 spring-cloud-starter-ribbon（Feign 中也使用了 Ribbon） Spring Cloud Netflix 的微服务都是以 HTTP 接口的形式暴露的，所以可以用 Apache 的 HttpClient 或 Spring 的 RestTemplate 去调用，而 Feign 是一个使用起来更加方便的 HTTP 客戶端，使用起来就像是调用自身工程的方法，而感觉不到是调用远程方法。feign封装了Http调用流程，更适合面向接口化的编程习惯在feign底层，通过基于面向接口的动态代理的方式生成实现类，将请求调用委托到动态代理实现类 git本地执行命令 git status git clone 地址 git add . git commit -m ‘简述’ git push origin master(具体的分支) springcloud中的消息总线bus配置问题我们在开发的时候，微服务中高端配置往往集中配置更简洁，效率更高，运维更容易所以我们独立部署一个config项目(我使用的springcloud版本是 Dalston.SR1,配合springboot 1.5x使用的) 引入pom.xml，切记是spring-cloud-config-server,而不是spring-cloud-starter-config-server 12345678910111213141516171819202122232425262728&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;parent&gt; &lt;artifactId&gt;springclouddemo&lt;/artifactId&gt; &lt;groupId&gt;com.nyist&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;springclouddemo-config&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 然后我们需要配置存放github的地址,yml文件这样配置 12345678910server: port: 9001spring: application: name: springclouddemo-config cloud: config: server: git: uri: https://github.com/lmx110522/springcloud-config.git 配置好，一定记得在启动类加上@EnableConfigServer以开启config服务 1234567891011121314import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.config.server.EnableConfigServer;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;@EnableConfigServer@SpringBootApplication@EnableEurekaClientpublic class SpringCloudDemoConfig9001 &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudDemoConfig9001.class,args); &#125;&#125; 然后我们就可以把我们的各个微服务的工程的配置在git上集中化管理在需要git管理的服务中的pom.xml添加1234 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 接着，我们会出现一个叫做bootstrap.yml的文件(这个bootstrap不是前端的那个框架)bootstrap.yml的优先级高于application.yml，所以我们不需要git管理的放在application.yml中，bootstrap.yml这样配置1234567spring: cloud: config: name: springcloud-provider-8001 # 需要从github上读取的资源名称 没有yml后缀 profile: dev label: master uri: http://localhost:9001 这个时候，启动该服务会从github上拿取配置但是在我们改变github上的配置的时候，在项目中并没有生效，这个时候因为我们没有引入消息总线bus 引入消息总线bus分别在config-server工程和需要config-client(需要git管理配置文件的工程)添加1234 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 同时都要配置rabboitmq信息1234spring: rabbitmq: host: 192.168.13.132 port: 5672 底层利用的是消息队列，会把改变放在消息队列，然后服务从队列中取出接着在git改变配置文件后，要使用/bus/refresh的POST请求来更新操作(从控住台可以看出) 借助Postman发现请求结果为：1234567&#123; "timestamp": 1533892993040, "status": 401, "error": "Unauthorized", "message": "Full authentication is required to access this resource.", "path": "/bus/refresh"&#125; 这是因为actuator安全认证，所以我们在config-server的yml文件中关闭即可123management: security: enabled: false # 不开启actuator安全认证 注：在config-client(需要git管理配置文件的工程)中需要改变的属性所在类添加@RefreshScope,这是重点！ 启动后，查看rabbitmq 然后更改之后git配置之后，我们可以使用postman发起/bus/refresh请求，使配置生效其实更好的办法，我们可以在github上设置webHooks,这样就避免我们每次都要手动发起更新具体的如何设置，请看这个博客，写的很好，点我去阅读！]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>springcloud中的bus</tag>
        <tag>ribbon和nginx区别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper深入学习总结]]></title>
    <url>%2F2019%2F03%2F27%2FZookeeper%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[zookeeper深入学习（观察者设计模式）Zookeeper = 文件系统 + 通知机制Zookeeper是一个分布式的服务框架，主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储。但是，zookeeper并不是专门存储数据的，它主要是维护和监控系统的数据的状态的变化的。通过监控这些数据的变化，从而达到基于数据的集群管理。Zookeeper所提供的服务主要是通过: 数据结构+原句+watcher机制这三个部分来实现的。 初步了解zookeeper的节点初步介绍zookeeper中的数据存储在一个叫做ReplicatedDataSource的数据库中，该数据是一个内存数据库，既然是内存数据库，数据量就不会很大zookeeper的数据存储在内存中，由于内存空间的限制，存储的节点需要根据需求和功能进行选择，都是有ZK节点的性质和该节点所关联的数据实现的。 Zookeeper中每个节点存储的数据都是要进行原子性的操作，也就是读操作将获取与节点相关的所有数据，写操作将替换掉节点所有的数据。每一个节点都拥有自己的ACL(访问控制列表)，这个列表规定了用户的权限，即限定了特定用户对目标节点可以执行的操作。 特点 zookeeper节点类型主要有两种，一种是 临时节点，另一种是 永久节点，节点的类型在创建时即被确定，并且不能改变。 临时节点该节点的生命周期依赖于创建它们的会话。一旦会话(Session)结束，临时节点将被自动删除，当然可以也可以手动删除。虽然每个临时的Znode都会绑定到一个客户端会话，但他们对所有的客户端还是可见的。另外，ZooKeeper的临时节点不允许拥有子节点。 永久节点该节点的生命周期不依赖于会话，并且只有在客户端显示执行删除操作的时候，他们才能被删除。 存储结构是一个树状，每个节点被称为一个ZNode,默认能够存储1MB的数据，并且每个ZNode都是可以通过路径唯一标识 Zookeeper的常用方式统一配置信息把集群的中各个服务器配置存放于每一个ZNode中，节点信息变化，会通知到各个服务器 统一集群模式主要是把各个集群的状态存放于节点中，哪台服务器宕机了，其他节点会立刻被通知到 服务器动态上下线服务节点上下线会把信息返回给客户端，客户端将不再调用此服务 软负载均衡把服务器的访问量存储在ZNode中，然后，客户端去访问的时候，把访问的请求分发给请求少的服务器 Zookeeper监听原理 首先要有一个main（）线程 在main线程中创建zookeeper客户端，这时就会创建两个线程，一个负责网络连接通信(connect),一个负责监听(listener) 通过connect线程将注册的监听事件发给zookeeper 在zookeeper的注册监听列表中将注册的监听事件添加到列表中 zookeeper监听到数据或者路径有变化时，会将这个消息发送给listener线程 listener线程内部调用process()方法。 常见的监听类型 监听节点数据的变化 get [path] watch 监听节点数量的变化 ls [path] watch]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql优化后续总结]]></title>
    <url>%2F2019%2F03%2F23%2Fmysql%E4%BC%98%E5%8C%96%E5%90%8E%E7%BB%AD%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[mysql优化后续总结show status like ‘innodb_row_lock%’ 查看行级锁的状态 show status like ‘table%’ 查看表级锁的状态 explainid select_key table type key possible_key key_len ref rows extra 执行顺序id相同，从上往下执行id不同，从大向小执行type: all-&gt;index-&gt;range-&gt;ref-&gt;eq_ref-&gt;const-&gt;systempossible_key: 可能用到的索引key: 实际用到的索引ref: const,实际引用extra: using index using where using filesort(效率偏差，最左匹配原则断层) using temporty(从上往下) 写sql的时候注意点 不对索引建立操作 != &lt;&gt; 适当选择使用 exists in 索引最左匹配 order by 、group by和where一样，根据最左匹配原则合理创建索引 字符类型一定要加双引号 索引操作创建索引create index 索引名 on 表名(索引列1,..)alter table 表名 add index 索引名(索引列1,..) 删除索引drop index 索引名 on 表名 查找所有的索引show index from 表名 执行过程详细查看接着我们需要详细查看执行情况 show variables like ‘profiling’ 默认关闭 set global profiling = 1;打开然后 使用 show profiles 查看所有的语句执行 然后根据某个语句执行id show profile cpu,block io 或者(all) for query id(上面的id);可以获得哪个执行的秒数情况，用来排查 其实我们还可以使用mysql全局监测 set global general_log = 1;默认关闭，是自带数据库mysql中的select * from mysql.general_log;获得以往执行情况 mysql锁表级索 行级索 inndb表级索 myisam mysql5.5以后默认innodb 以 innodb为例： 首先 设置读锁lock table 表名 read; 不可以对表进行写，但是可以读，只能读当前表其他session可以读，但是呢，写的话会阻塞 unlock tables; 释放所有的锁 设置写锁 lock table 表名 write; 不能写也不能读 unlock tables;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蚂蚁金服面试总结]]></title>
    <url>%2F2019%2F03%2F21%2F%E8%9A%82%E8%9A%81%E9%87%91%E6%9C%8D%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[阿里蚂蚁金服面试总结——查漏补缺内存泄露与内存溢出原理内存溢出out of memory出现的原因是，程序再向系统申请内存的时候，系统没有足够的内存提供给应用程序。 内存泄露经常报错的提示是 memory leak,出现的原因，程序向系统申请内存，系统有内存，但是释放不出来。比如，之前打开一个应用程序，申请了一个内存空间，但是用完之后，没有释放掉。等到了下一个程序用，这份已经闲置的内存就不能用，可能是指针的丢失。 常发性内存泄露发生内存泄露的代码会被多次执行到，每次执行的时候都会导致一块内存的泄露。 偶发性内存泄露发生内存泄露的代码只是在某些特定的环境或操作的过程中才会发生。常发性和偶发性是相对的。对于特定的环境，偶发性也许就会变成常发性。所以测试环境和测试方法对检测内存泄漏至关重要。 一次性内存泄漏发生内存泄漏的代码只会被执行一次，或者由于算法上的缺陷，导致总会有一块仅且一块内存发生泄漏。比如，在类的构造函数中分配内存，在析构函数中却没有释放该内存，所以内存泄漏只会发生一次。 隐式内存泄漏程序在运行过程中不停的分配内存，但是直到结束的时候才释放内存。严格的说这里并没有发生内存泄漏，因为最终程序释放了所有申请的内存。但是对于一个服务器程序，需要运行几天，几周甚至几个月，不及时释放内存也可能导致最终耗尽系统的所有内存。所以，我们称这类内存泄漏为隐式内存泄漏。 内存溢出总结内存溢出中隐式内存泄漏比较难以检测到，所以危害比较大。 总结内存泄露如果不是特别严重，泄露一点半点的，可以容忍，系统的内存空间可能很大，足够分配给新的应用，但是泄露很多，或者一直泄露，这时候会导致，系统闲置的空间越来越小，也就是常讲的，内存泄露最终会导致内存溢出。 内存溢出形成内存溢出的原因有很多种，如下： 内存中加载的数据量过于庞大，如一次从数据库中取出过多数据； 集合类中有对 对象 的引用，使用完后没有清空，是的jvm不能回收； 代码中存在死循环或者循环产生或多重复的对象实体 启动参jvm内存时参数值设定过小和面试官讨论了关于死循环是否会产生内存溢出的问题，所以理由是什么？我后来总结了一下，如果你死循环中大量创建对象，然后就会出现out of memory，由于创建的对象存放在堆区，所以堆区溢出也会造成内存溢出，和递归调用同样的道理。 解决方案 修改虚拟机的参数,直接增加内存 -xmx -xms 检查日志错误，查看“OutOfMemory”错误前是否有其它异常或错误 对代码进行走查和分析，找出可能发生内存溢出的位置 检查对数据库查询中，是否有一次获得全部数据的查询。一般来说，如果一次取十万条记录到内存，就可能引起内存溢出。这个问题比较隐蔽，在上线前，数据库中数据较少，不容易出问题，上线后，数据库中数据多了，一次查询就有可能引起内存溢出。因此对于数据库查询尽量采用分页的方式查询。 检查代码中是否有死循环或递归调用（重复产生新对象实体）。 检查List、MAP等集合对象是否有使用完后，未清除的问题。List、MAP等集合对象会始终存有对对象的引用，使得这些对象不能被GC回收。 socket心跳机制因为防火墙会关闭长时间处于非活跃状态的连接而导致socket连接中断，通过心跳机制可以保持长连接。 原理客户端会每个一段时间向服务器端发送一个心跳包，同时开启定时器。服务器返回一个相同的心跳包给客户端。如果客户端能够接受到心跳包，说明连接正常，删除定时器。如果超时未收到心跳包，则认为连接断开，这个时候进行重连设置。 当客户端和服务器断掉的时候，我们可以重连设置，如何设置直连当与服务器断开连接或网络错误的时候，先不要处理当前socket，应该首先另起一个socket服务，与服务器尝试连接，当连接成功，通知当前socket重新连接，每6秒连接一次，如果30秒内没有连接上，通知掉线，然后继续尝试连接，直到连接上。 快速排序的最坏情况这个其实是会的，但是由于当时紧张脑子有点放空！快速排序的最好情况是，每次恰好能够均分序列，树的深度为log2n+1,仅需要递归log2n次；最坏情况是O(n^2),每次划分序列为一个元素和其他元素部分，退化为冒泡排序，有点像单斜树 mysql的性能优化方面有很多，如：索引优化，查询优化，查询缓存，服务器设置优化，操作系统和硬件优化，应用层面优化(web服务器优化，换缓存) mysql性能的开销指标 执行时间 查询的数据量 返回的结果数量 几种简单的优化查询优化 count的优化计算id大于5的城市 a. select count() from world.city where id &gt; 5; b. select (select count() from world.city) – count() from world.city where id &lt;= 5; a语句当行数超过11行的时候需要扫描的行数比b语句要多， b语句扫描了6行，此种情况下，b语句比a语句更有效率。当没有where语句的时候直接select count() from world.city这样会更快，因为mysql总是知道表的行数 避免使用不兼容的数据类型数据库类型的不兼容可能使优化器无法执行一些本来可以优化的操作 索引字段进行运算会使索引失效（会导致引擎放弃索引进行全表扫描）如： SELECT FROM T1 WHERE F1/2=100 应改为: SELECT FROM T1 WHERE F1=100*2 避免使用!=或＜＞、IS NULL或IS NOT NULL、IN ，NOT IN等这样的操作符 因为这会使系统无法使用索引,而只能直接搜索表中的数据。例如: SELECT id FROM employee WHERE id != “B%” 优化器 将无法通过索引来确定将要命中的行数,因此需要搜索该表的所有行。在in语句中能用exists语句代替的就用exists. 能够用BETWEEN的就不要用IN 能够用DISTINCT的就不用GROUP BY 尽量不要使用SELECT INTO语句。SELECT INTO 语句会导致表被锁定，阻止其他用户访问该表 1234SELECT LastName,Firstname INTO Persons_backup FROM Persons WHERE City='Beijing'将查询后的结果存放在一个新表 Persons_backup中，其中查询的过程表会被锁定 必要的时候强制查询优化器使用某个索引 1SELECT * FROM T1 WHERE nextprocess = 1 AND processid IN (8,32,45) 改成： SELECT * FROM T1 (INDEX = IX_ProcessID) WHERE nextprocess = 1 AND processid IN (8,32,45) 则查询优化器将会强行利用索引IX_ProcessID 执行查询。 Order By语句的Mysql优化 ORDER BY + LIMIT组合的索引优化 索引建立在order by上 Where+ORDER BY + LIMITz组合索引优化 索引建立在where 和 order by 上 WHERE+ORDER BY多个栏位+LIMIT 索引建立在where和多个order by上 不要在选择的栏位上放置索引，应该在条件选择的语句上合理的放置索引，比如order by where 数据类型优化避免使用NULL类型，因为大多数数据库要进行对他特殊处理，最好使用0或者1来标识 先总结那么多，后续再去进行添加总结]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>蚂蚁金服面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程总结(四)]]></title>
    <url>%2F2019%2F03%2F15%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%80%BB%E7%BB%93-%E5%9B%9B%2F</url>
    <content type="text"><![CDATA[线程总结(四)怎么检测一个线程是否拥有锁？ 可以调用wait()方法，如果出现异常，就说明java中的线程没有持有锁。否则将持有锁。(这种方式不推荐) 我们可以使用API，Thread的一个静态方法boolean isHave = Thread.holdsLock(User.class);如果存在则返回true,没有持有User这个对象的锁，则返回false; Jdk中排查多线程问题用什么命令jstack作用： 生成JVM当前时刻线程的快照(threaddump,当前进程中所有线程的信息)目的：帮助快速定位程序问题出现的原因，如长时间停顿、cpu占用率过高。 向线程传递参数的三种基本方法1. 通过构造方法传递数据 1234567891011121314151617181920package com.nyist.thread; public class MyThread extends Thread&#123; private String name; public MyThread(String name) &#123; this.name = name; &#125; public void run() &#123; System.out.println("hello " + name); &#125; public static void main(String[] args) &#123; Thread thread = new MyThread("demo"); thread.start(); &#125;&#125; 2.通过变量和方法传递数据12345678910111213141516171819202122package com.nyist.thread;public class MyThread1 implements Runnable&#123; private String name; public void setName(String name) &#123; this.name = name; &#125; public void run() &#123; System.out.println("hello " + name); &#125; public static void main(String[] args) &#123; MyThread2 myThread = new MyThread2(); myThread.setName("demo"); Thread thread = new Thread(myThread); thread.start(); &#125;&#125; 3.通过回调函数传递数据1234567891011121314151617181920212223242526272829303132333435363738394041package com.nyist.thread; class Data&#123; public int value = 0;&#125;class Work&#123; public void process(Data data, Integer numbers) &#123; for (int n : numbers) &#123; data.value += n; &#125; &#125;&#125;public class MyThread2 extends Thread&#123; private Work work; public MyThread3(Work work) &#123; this.work = work; &#125; public void run() &#123; java.util.Random random = new java.util.Random(); Data data = new Data(); int n1 = random.nextInt(1000); int n2 = random.nextInt(2000); int n3 = random.nextInt(3000); work.process(data, n1, n2, n3); // 使用回调函数 System.out.println(String.valueOf(n1) + "+" + String.valueOf(n2) + "+" + String.valueOf(n3) + "=" + data.value); &#125; public static void main(String[] args) &#123; Thread thread = new MyThread3(new Work()); thread.start(); &#125;&#125; 锁的降级和升级ReadWriteLock是读写锁接口，里面有两个方法123456789101112131415public interface ReadWriteLock &#123; /** * Returns the lock used for reading. * * @return the lock used for reading */ Lock readLock(); /** * Returns the lock used for writing. * * @return the lock used for writing */ Lock writeLock();&#125; 一个是读锁，一个写锁 降级锁： 由写锁到读锁 升级锁： 由读锁到写锁 1234567891011121314package com.nyist.thread;import java.util.concurrent.locks.ReentrantReadWriteLock;public class Test1 &#123; public static void main(String[] args) &#123; ReentrantReadWriteLock rtLock = new ReentrantReadWriteLock(); rtLock.readLock().lock(); System.out.println("获得读锁."); rtLock.writeLock().lock(); System.out.println("阻塞"); &#125;&#125; 结果打印出来是 获得读锁. 这说明ReentrantReadWriteLock不可以锁升级1234567891011121314package com.nyist.thread;import java.util.concurrent.locks.ReentrantReadWriteLock;public class Test2 &#123; public static void main(String[] args) &#123; ReentrantReadWriteLock rtLock = new ReentrantReadWriteLock(); rtLock.writeLock().lock(); System.out.println("写锁"); rtLock.readLock().lock(); System.out.println("获得读锁"); &#125;&#125; 结果打印出来是 写锁 获得读锁 这说明ReentrantReadWriteLock可以锁降级 FutureTask和Future区别Future是一个接口，代表可以取消的任务，并且返回执行的结果。FutureTask是实现了Futrue和Runnable接口]]></content>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程总结(三)以及HashMap底层源码跟读]]></title>
    <url>%2F2019%2F03%2F14%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%80%BB%E7%BB%93-%E4%B8%89%2F</url>
    <content type="text"><![CDATA[多线程的总结(三)Synchronized有哪几种用法方法声明时使用放在声明符之后，返回值之前，即一次只有一个线程进入该方法。，其他线程排队等候，等当前线程执行结束之后才可以进入执行。 对于某一代码块使用synchronized后跟括号,括号里是变量,这样,一次只有一个线程进入该代码块123456789public int synMethod(int a1)&#123; synchronized(a1) &#123; //一次只能有一个线程进入 &#125; &#125; synchronized后面括号里是一对象,此时,线程获得的是对象锁如果线程进入，获得是对象锁，那么别的线程在该类所有对象上都不能进行任何操作，使用对象级锁范围太过于大，所以性能不高，完全可以让其他线程访问该类上的其他同步方法来共享资源。由于每个对象都有锁，所以可以使用虚拟对象锁来上锁。 12345678910111213141516171819202122232425262728293031323334353637class FineGrainLock &#123; MyMemberClass x, y; Object xlock = new Object(), ylock = new Object(); public void foo() &#123; synchronized(xlock) &#123; //access x here &#125; //do something here - but don't use shared resources synchronized(ylock) &#123; //access y here &#125; &#125; public void bar() &#123; synchronized(this) &#123; //access both x and y here &#125; //do something here - but don't use shared resources &#125;&#125; 不推荐这样使用this，范围太大了，导致进入其他对象不能访问其他同步方法，最好使用虚拟变量来上锁 synchronized后面括号里是类如果线程进入,则线程在该类中所有操作不能进行,包括静态变量和静态方法,实际上,对于含有静态方法和静态变量的代码块的同步,我们通常用 类.class 来加锁. 锁的四种声明方式总结 锁是和对象相关联的，每个对象有一把锁，为了执行synchronized语句，线程必须能够获得synchronized语句中表达式指定的对象的锁，一个对象只有一把锁，被一个线程获得之后它就不再拥有这把锁，线程在执行完synchronized语句后，将获得锁交还给对象。 在方法前面加上synchronized修饰符即可以将一个方法声明为同步化方法。同步化方法在执行之前获得一个锁。如果这是一个类方法，那么获得的锁是和声明方法的类相关的Class类对象的锁。如果这是一个实例方法，那么此锁是this对象的锁总之： 同步synchronized(.class)代码块的作用其实和synchronized static方法作用一样。Class锁对类的所有对象实例起作用。synchronized应用在static方法上，那是对当前对应的.Class进行持锁。 synchronized同步方法①对其它的synchronized同步方法或synchronized(this)同步代码块调用是堵塞状态；②同一时间只有一个线程执行synchronized同步方法中的代码。 synchronized(this)同步代码块①对其它的synchronized同步方法或synchronized(this)同步代码块调用是堵塞状态；②同一时间只有一个线程执行synchronized同步方法中的代码 重入锁可重入锁最大的作用就是避免死锁中断响应： 对于synchronized块来说，要么获取到锁执行，要么持续等待。而重入锁的中断响应功能就合理地避免了这样的情况。比如，一个正在等待获取锁的线程被“告知”无须继续等待下去，就可以停止工作了 公平锁：所有的等待锁线程都排在队列中，使用FIFO的方式来获取锁非公平锁：等待线程在无论在不在队列中或者队列末尾都会直接抢夺锁，抢不到进入队列中，下次继续抢夺12345678910ReentrantLock lock = new ReentrantLock();lock.lockInterruptibly(); // 以可以响应中断的方式加锁Thread t1 = new Thread(deadLock1);Thread t2 = new Thread(deadLock2);t1.start();t2.start();Thread.sleep(1000);t2.interrupt();//线程t2响应中断，不会继续等待t1所持有的锁 tryLock 锁申请等待限时1234567891011121314151617181920212223242526import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.ReentrantLock;public class TryLockTest implements Runnable&#123; public static ReentrantLock lock = new ReentrantLock(); @Override public void run() &#123; try &#123; if (lock.tryLock(1, TimeUnit.SECONDS)) &#123; // 等待1秒 Thread.sleep(2000); //休眠2秒 &#125; else &#123; System.err.println(Thread.currentThread().getName() + "获取锁失败！"); &#125; &#125; catch (Exception e) &#123; if (lock.isHeldByCurrentThread()) lock.unlock(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; TryLockTest test = new TryLockTest(); Thread t1 = new Thread(test); t1.setName("线程1"); Thread t2 = new Thread(test); t1.setName("线程2"); t1.start();t2.start(); &#125;&#125; 首先普及一下APIisFair（）：作用是判断ReentrantLock是否是公平锁。返回true为公平锁，false为非公平锁。isHeldByCurrentThread（）查询当前线程是否保持锁isLocked（）：查询锁是否有线程保持。 Fork/Join框架是干什么的(执行任务的框架)是Java7提供的用于执行任务的框架，是把一个大任务分割成若干个小任务，然后把各个小任务执行的结果汇总就是大任务的结果。完成两件事情1. 任务分割：首先Fork/Join框架需要把大的任务分割成多个子任务，如果子任务比较大的话还要继续分割2.执行任务并合并结果：分割的子任务分别放到双端队列里，然后几个启动线程分别从双端队列里获取任务执行。子任务执行完的结果都放在另外一个队列里，启动一个线程从队列里取数据，然后合并这些数据 HashMap和HashTable集合线程不安全: 多个线程操作同一个集合时，需要自己设置同步机制，否则会出现异常 HashMap是线程不安全的，多线程环境下可能会发生死锁。HashTable是线程安全的，因为它的每个方法都加入了synchronized方法。HashMap比HashTable执行效率高。当需要多线程的操作的时候，我们可以使用ConcurrentHashMap,多线程环境下ConcurrentHashMap比HashTable的执行效率高好几倍。因为ConcurrentHashMap使用了分段锁，并不对整个数据进行锁定。 HashTable键值对都不可以为空，否则会抛出空指针异常。，HashMap的键是可以为空的，但是只可以一个键为空。值也可以为null,所以我们不可以使用get()方法来判断是否map中有没有key,因为返回null并不意味着键不存在，有可能有键但是值为null。所以我们可以使用containsKey()方法来判断 继承的父类不同。 HashMap继承AbstractMap,而HashTable继承Dictionary类，由于Dictionary类已经被废弃，所以使用的不多了 初始容量不同和每次扩充容量不同HashTable的初始容量是11,而HashMap的初始容量是16。在创建时，如果给定了容量初始值，那么Hashtable会直接使用给定的大小，而HashMap则会将其扩充为2的幂次方大小。Hashtable会尽量使用素数、奇数。原因在于两种侧重面不同。HashTable更侧重于将结果分布均匀，是哈希冲突减少。HashMap使用位运算(&gt;&gt; &lt;&lt;)能够快速定位位置。但是Hash冲突也增加了。因为得出的hash值的低位相同的概率比较高，为了解决这个冲突，让取到的位置更分散，然后将得到的hashcode再进行了一次位处理。源码： 什么是装载因子？他有什么作用？1234/** * The load factor used when none specified in constructor. */ static final float DEFAULT_LOAD_FACTOR = 0.75f; 作用:就是控制什么时候map需要通过resize方法扩容，然后通过rehash方法把原有的元素复制到新的容器里面是否resize,由装载因子和初始容量决定的。 HashMap源码解读前面我们知道了装载因子(用来衡量HashMap满的程度)，那么HashMap如何计算呢size: 表示HashMap中所有的KV数量，包括链表和树的总和然后capacity表示顺序表的长度然后 size/capacity(初始大小为16，第二次要增加到64,以后每次翻2倍，所以都是2的幂次方)和装载因子比较，大于装载因子就进行resize操作，然后通过rehash方式把原有的元素复制到新的容器里面。threshold = 装载因子(LoadFactor)*capacity，就是说size的数量什么时候超过threshold就执行resize方法。那么什么时候会将链表树化呢？跟源码]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>HashMap底层原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入学习消息中间件 —— RabbitMQ]]></title>
    <url>%2F2019%2F03%2F13%2F%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6-%E2%80%94%E2%80%94-RabbitMQ%2F</url>
    <content type="text"><![CDATA[深入学习消息中间件 —— RabbitMQ消息丢失了怎么办？由于我比较了解RabbitMQ，所以我们以RabbitMQ为例子介绍消息丢失分为三个不同的丢失 生产者丢失问题 消息中间件丢失问题 消费者丢失问题 生产者端丢失（RabbitMQ）生产者生产的消息要发送到RabbitMQ,但是很容易数据在半路上弄丢，或者网络原因。所以如何保证消息可以安全送达到RabbitMQ呢解决方案有两个 1、开启RabbitMQ事务机制(同步)（RabbitMQ）我们可以使用channel.txSelect来开启事务，然后如果消息没有预期到达RabbitMQ,那么会执行事务回退channel.Rollback执行成功的话提交事务channel.txCommit。但是由于事务机制是同步的，会导致吞吐量减少，太耗费性能。 2、开启confirm模式(异步)（RabbitMQ）生产者生产的每一个消息都会有一个唯一的id,自身会在内存中维护这个id的状态信息，然后将消息写入RabbitMQ,如果RabbitMQ接受到消息，会回传一个ack消息,告诉生产者这个消息我已经接受到了，但是如果消息没有被RabbitMQ处理，那么会回传一个nack，如果你收到这个nack回传消息或者很久没有收到任何响应就利用内存维护的对应Id状态信息再次发送。 事务机制和confirm两个不同点（RabbitMQ）由于事务机制是同步的，即你提交一个事务之后会阻塞到那儿，但是confirm机制是异步的，消息发送出去之后，然后继续发送，然后RabbitMQ收到消息之后会异步回调给生产者一个接口来通知你消息收到了 RabbitMQ端丢失（RabbitMQ）我们解决的方案可以开启RabbitMQ持久化，就是将消息写入之后持久化到磁盘，就算某个时候RabbitMQ宕机了，恢复之后也会读取之前存储的数据。但是仍然也会有一种情况，消息存入到RabbitMQ，还没有来得及持久化，RabbitMQ就发生宕机了，从而导致数据丢失，那么如何解决呢？我们可以结合confirm机制，当生产者发送消息给RabbitMQ的时候，我们将数据存入并且持久化到磁盘时再回传ack，这样就可以解决上面的RabbitMQ还没有来得及持久化就宕机了。 消费者端丢失（RabbitMQ）情形：让消费者从RabbitMQ拿到数据之后，还没有来得及消费，自身就宕机了，可是RabbitMQ以为你已经消费了解决办法：使用由于RabbitMQ提供的ack机制。简单来说，就是必须关闭RabbitMQ的自动ack,可以通过一个api来调用就行，每次在代码中确认处理完成之后，自己添加ack，这样如果你没有处理完，就无法返回ack,那么RabbitMQ会认为你没没有处理，会把消息让别的消费者处理。 消息中间件的优缺点（RabbitMQ）优点（RabbitMQ）解耦合（RabbitMQ）加入B系统、C系统、D系统都使用A系统执行的结果，那么如何解决C宕机或者需要添加E系统调用，太麻烦了，耦合度太高，每次修改都需要更改原先的代码，所以我们可以使用消息中间件。把A返回的消息存储在消息中间件中，然后任何系统需要用，就去其中拿，不需要就不拿。 异步（RabbitMQ）加入用户写操作需要往A,B,C三个系统中写数据，但是A需要2ms,B需要200ms,C需要300ms，那么用户写一次数据需要502ms，那么用户可能会崩溃，一次操作需要等待那么久，所以我们可以让A执行操作后，把B、C操作放入到消息中间件中，然后再逐个从其中取出执行，那么用户就会感受到执行速度很快 削锋（RabbitMQ）一般系统的流量访问都是不均衡的，可能夜里访问人数就几十个，但是例如外卖互联网公司，饭点的时候系统的对数据的操作可能就比较繁重，用户请求大到几K，但是MySQL数据库的每秒的访问到达2k已经差不多了，所以超过这个数量之后，MySQL就会扛不住甚至崩溃，那么我们可以使用消息中间件，把数据库最大操作数量交由数据库处理，剩余的放在消息中间件，等待数据库处理完，我们可以继续从消息中间件取数据。从而解决了高并发下对数据库的压力 缺点（RabbitMQ）系统可用性降低（RabbitMQ）系统引入外面依赖越多，越容易挂掉。系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，人 ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整，MQ 一挂，整套系统崩溃的，你不就完了？如何保证消息队列的高可用 系统复杂度提高（RabbitMQ）硬生生加个 MQ 进来，你怎么[保证消息没有重复消费]？怎么[处理消息丢失的情况]？怎么保证消息传递的顺序性？这些问题都要去解决 一致性问题（RabbitMQ）A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了 如何保证消息的一致性（RabbitMQ）RabbitMQ假如我们把对于数据库的操作放进RabbitMQ,那么插入和删除的顺序必须和送入RabbitMQ的顺序一致，否则执行结果就不一样了，所以我们必要要保证一致性我们能不能这样解决，由于队列有序(先进先出)，就是当消费者消费消息，RabbitMQ等待消费者消费结束之后返回给RabbitMQ一个内容，然后再去执行下一个消息，显然这样不符合高并发下的生产条件，效率太低了。即 在MQ中创建多个queue,按照某一规则，有顺序的放进MQ的queue里面，然后消费者只取一个queue里面的数据消费。或者还是只有一个 queue 但是对应一个消费者，然后这个消费者内部用内存队列做排队，然后分发给底层不同的 worker 来处理。 消息中间件的高可用（RabbitMQ）RabbitMQ可以有三种模式 单机模式 普通集群模式 镜像集群模式(高可用) 镜像集群模式你创建的每个queue里面的消息或者元数据都会同步到其他的queue，对于每一个RabbitMQ节点，都有这个queue的一个完整镜像，包含queue的全部数据的意思。缺点： 性能开销太大，因为数据需要同步到各个RabbitMQ节点 不是分布式，没有可扩展性，如果queue负载过重，即使加机器，也是把所有的节点都复制到新的机器上，并没有办法扩展。 知识补记分布式和集群理解 理解 分布式 一个业务拆分为多个子业务，部署到多个服务器上 集群 同一个业务部署在多个服务器上 主从和集群的更新 更新 主从 服务器之间是异步的，从服务器可能和主服务器不一致 集群 更新是同步的，数据节点都是一致的]]></content>
      <categories>
        <category>消息中间件</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[多线程总结（二）]]></title>
    <url>%2F2019%2F03%2F12%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%80%BB%E7%BB%93%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[多线程总结(一)java多线程中的死锁、活锁、饥饿、无锁死锁死锁是多线程中最差的一种情况，多个线程相互占用对方的资源的锁，而又相互等对方释放锁，此时若无外力干预，这些线程则一直处理阻塞的假死状态，形成死锁 活锁活锁这个概念大家应该很少有人听说或理解它的概念，而在多线程中这确实存在。活锁恰恰与死锁相反，死锁是大家都拿不到资源都占用着对方的资源，而活锁是拿到资源却又相互释放不执行。当多线程中出现了相互谦让，都主动将资源释放给别的线程使用，这样这个资源在多个线程之间跳动而又得不到执行，这就是活锁。 饥饿我们知道多线程执行中有线程优先级这个东西，优先级高的线程能够插队并优先执行，这样如果优先级高的线程一直抢占优先级低线程的资源，导致低优先级线程无法得到执行，这就是饥饿。当然还有一种饥饿的情况，一个线程一直占着一个资源不放而导致其他线程得不到执行，与死锁不同的是饥饿在以后一段时间内还是能够得到执行的，如那个占用资源的线程结束了并释放了资源。 无锁无锁，即没有对资源进行锁定，即所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。无锁典型的特点就是一个修改操作在一个循环内进行，线程会不断的尝试修改共享资源，如果没有冲突就修改成功并退出否则就会继续下一次循环尝试。所以，如果有多个线程修改同一个值必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。之前的文章我介绍过JDK的CAS原理及应用即是无锁的实现 并发编程中的三个概念原子性原子性：即一个操作或多个操作要不 不执行且执行过程不会被任何外界因素所打断，要么不执行 可见性可见性指的是当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看到修改的值 有序性有序性指的是程序的执行的顺序按照代码的先后顺序执行。 什么是守护线程（Daemon）通俗的例子就是任何一个守护线程都是JVM中非守护线程的“保姆”只要当前JVM实例存在一个没有结束的非守护线程，那么守护线程就会全部运行。只有当最后一个非守护线程结束的时候，守护线程会随着JVM一起结束工作。 用户线程和线程区别几乎一样，唯一区别是，JVM的离开，如果用户进程全部退出了，那么守护进程和JVM一起结束，因为没有了守护者，守护进程就没有守护的进程的意义，所以没有继续运行的必要性了 典型的守护进程GC线程，只要有用户线程在，垃圾收集线程就不会退出。 注意点 设置setDaemon（true）必须在new Thread().start执行之前执行，普通线程不可以转换成守护线程 守护线程内部产生的新线程也是守护线程 并不是所有的应用都可以分配Daemon来守护，例如读写操作或计算逻辑 void setDaemon(boolean on) 标志着该线程是 守护线程或用户线程 on可以取true或者false 多线程下的异常如何处理异常不同处理的方式不同 非运行时异常(UnCheckedException)多线程中run方法不支持抛出,所以必须捕获处理 运行时异常（Runtime Exception）可以选择打印在控制台，或者设置UncaughtException异常处理器来自定义处理操作]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程总结(一)]]></title>
    <url>%2F2019%2F03%2F12%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%80%BB%E7%BB%93-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[多线程总结（一）多线程实现的五种方法1、使用Synchronized关键字修饰方法，java对象都有一个内置锁，当用此关键字修饰方法时，内置锁会保护整个方法。在调用该方法前，需要获得内置锁，否则就处于阻塞状态。2、 使用Synchronized静态代码块3、 使用局部变量方式ThreadLocal来创建一个static变量，多线程执行时会在自身工作区域创建局部变量副本4、 使用volatile来修饰共享变量，这样每次线程需要操作变量时，从主内存拿，而不是从操作自己的工作内存的那个副本5、 使用重入锁实现线程同步 死锁的产生是必须要满足一些特定条件1.互斥条件：进程对于所分配到的资源具有排它性，即一个资源只能被一个进程占用，直到被该进程释放2.请求和保持条件：一个进程因请求被占用资源而发生阻塞时，对已获得的资源保持不放。3.不剥夺条件：任何一个资源在没被该进程释放之前，任何其他进程都无法对他剥夺占用4.循环等待条件：当发生死锁时，所等待的进程必定会形成一个环路（类似于死循环），造成永久阻塞。 线程池的submit和execute方法区别虽然executor是线程池的顶层接口，但真正实现的接口却是：executorService submit有返回值，而execute没有用到返回值的例子，比如说我有很多个做validation的task，我希望所有的task执行完，然后每个task告诉我它的执行结果，是成功还是失败，如果是失败，原因是什么。然后我就可以把所有失败的原因综合起来发给调用者。个人觉得cancel execution这个用处不大，很少有需要去取消执行的。 ###submit方便Exception处理意思就是如果你在你的task里会抛出checked或者unchecked exception，而你又希望外面的调用者能够感知这些exception并做出及时的处理，那么就需要用到submit，通过捕获Future.get抛出的异常。 代码展示区别12345678910111213141516171819202122232425262728public class RunnableTestMain &#123; public static void main(String[] args) &#123; ExecutorService pool = Executors.newFixedThreadPool(2); /** * execute(Runnable x) 没有返回值。可以执行任务，但无法判断任务是否成功完成。 */ pool.execute(new RunnableTest("Task1")); /** * submit(Runnable x) 返回一个future。可以用这个future来判断任务是否成功完成。请看下面： */ Future future = pool.submit(new RunnableTest("Task2")); try &#123; if(future.get()==null)&#123;//如果Future's get返回null，任务完成 System.out.println("任务完成"); &#125; &#125; catch (InterruptedException e) &#123; &#125; catch (ExecutionException e) &#123; //否则我们可以看看任务失败的原因是什么 System.out.println(e.getCause().getMessage()); &#125; &#125;&#125; 实现一个多线程的类123456789101112131415public class RunnableTest implements Runnable &#123; private String taskName; public RunnableTest(final String taskName) &#123; this.taskName = taskName; &#125; @Override public void run() &#123; System.out.println("Inside "+taskName); throw new RuntimeException("RuntimeException from inside " + taskName); &#125;&#125; Java的CountDownLatch和CyclicBarrier的理解和区别CountDownLatch从字面上可以看CountDown表示减法计数，Latch表示门阀的意思，当什么时候计数变成0的时候，门阀打开表示主线程等其他所有线程执行完毕才开始执行，当计数为0的时候，下一步的动作实施者是main函数12345678910111213141516171819202122232425262728293031323334353637package com.nyist.thread;import java.util.Random;import java.util.concurrent.CountDownLatch;public class CountDownLatchDemo &#123; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch latch = new CountDownLatch(4); for(int i = 0; i &lt; latch.getCount();i++)&#123; new Thread(new MyThread(latch),"玩家"+i).start(); &#125; System.out.println("所有玩家都已经准备好"); latch.await(); System.out.println("开始游戏"); &#125; private static class MyThread implements Runnable&#123; private CountDownLatch latch; public MyThread(CountDownLatch latch) &#123; this.latch = latch; &#125; public void run() &#123; try &#123; int randowNum = new Random().nextInt(10) + 1000; Thread.sleep(randowNum); System.out.println(Thread.currentThread().getName()+"已经准备好，所用时间"+randowNum); latch.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; CyclicBarrier主线程不等待其他线程直接结束，而其他线程必须同时执行完一个任务去执行下一个任务之前等待其他线程执行完毕才可以执行下一个任务12345678910111213141516171819202122232425262728293031323334353637383940414243package com.nyist.thread;import java.util.Random;import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;public class CyclicBarrierDemo &#123; public static void main(String[] args) &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(4); for(int i = 0; i &lt; cyclicBarrier.getParties();i++)&#123; new Thread(new MyThread(cyclicBarrier),"玩家"+i).start(); &#125; System.out.println("游戏结束！"); &#125; private static class MyThread implements Runnable&#123; private CyclicBarrier cyclicBarrier; public MyThread(CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; for(int i = 0; i&lt; 3;i++)&#123; try &#123; int t1 = new Random().nextInt(1000) + 1000; Thread.sleep(t1); System.out.println(Thread.currentThread().getName()+"通过"+(i+1)+"个障碍，耗时"+t1+"毫秒"); cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; CountDownLatch和CyclicBarrier区别两个都有让多个线程等待同步之后再去执行下一步的意思！但是呢，CountDownLatch是主线程等待其他线程，而CyclicBarrier主线程早早结束，然后其他执行完毕的线程来等待还没有执行完成的线程，最后再一起进入下一步的执行过程！]]></content>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式集群下session共享解决方案]]></title>
    <url>%2F2019%2F03%2F12%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E4%B8%8Bsession%E5%85%B1%E4%BA%AB%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[分布式Session共享解决方案Session是服务器用来保存用户操作的一系列会话信息，由Web容器进行管理。单机情况下，不存在Session共享的情况，分布式情况下，如果不进行Session共享会出现请求落到不同机器要重复登录的情况，一般来说解决Session共享有以下几种方案。 session复制session复制是早期的企业级的使用比较多的一种服务器集群session管理机制。应用服务器开启web容器的session复制功能，在集群中的几台服务器之间同步session对象，使得每台服务器上都保存所有的session信息，这样任何一台宕机都不会导致session的数据丢失，服务器使用session时，直接从本地获取。 这种方式在应用集群达到数千台的时候，就会出现瓶颈，每台都需要备份session，出现内存不够用的情况。 session绑定利用hash算法，比如nginx的ip_hash,使得同一个Ip的请求分发到同一台服务器上。 这种方式不符合对系统的高可用要求，因为一旦某台服务器宕机，那么该机器上的session也就不复存在了，用户请求切换到其他机器后么有session，无法完成业务处理。 利用cookie记录sessionsession记录在客户端，每次请求服务器的时候，将session放在请求中发送给服务器，服务器处理完请求后再将修改后的session响应给客户端。这里的客户端就是cookie。 利用cookie记录session的也有缺点，比如受cookie大小的限制，能记录的信息有限；每次请求响应都需要传递cookie，影响性能，如果用户关闭cookie，访问就不正常。但是由于cookie的简单易用，可用性高，支持应用服务器的线性伸缩，而大部分要记录的session信息比较小，因此事实上，许多网站或多或少的在使用cookie记录session。 session服务器session服务器可以解决上面的所有的问题，利用独立部署的session服务器（集群）统一管理session，服务器每次读写session时，都访问session服务器。 这种解决方案事实上是应用服务器的状态分离，分为无状态的应用服务器和有状态的session服务器，然后针对这两种服务器的不同特性分别设计架构。 对于有状态的session服务器，一种比较简单的方法是利用分布式缓存（memcached), 数据库等。在这些产品的基础上进行包装，使其符合session的存储和访问要求。 如果业务场景对session管理有比较高的要求，比如利用session服务基层单点登录（sso),用户服务器等功能，需要开发专门的session服务管理平台。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>session共享解决方案</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四种线程池]]></title>
    <url>%2F2019%2F03%2F10%2F%E5%9B%9B%E7%A7%8D%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[四种线程池总结java的线程池是什么，有哪些类型，作用分别是什么线程池是一种多线程处理形式，处理过程中将任务添加队列，然后在创建线程后自动启动这些任务，每个线程都使用默认的堆栈大小，以默认的优先级运行，并处在多线程单元中，如果某个线程在托管代码中空闲，则线程池将插入另一个辅助线程来使所有处理器保持繁忙。如果所有线程池都始终保持繁忙，但队列中包含挂起的工作，则线程池将在一段时间后辅助线程的数目永远不会超过最大值。超过最大值的线程可以排队，但他们要等到其他线程完成后才能启动。 java里面的线程池的顶级接口是Executor，Executor并不是一个线程池，而只是一个执行线程的工具，而真正的线程池是ExecutorService。 java中的有哪些线程池1.newCachedThreadPool创建一个可缓存线程池 2.newFixedThreadPool 创建一个定长线程池 3.newScheduledThreadPool 创建一个定时或周期线程池 4.newSingleThreadExecutor 创建一个单线程化的线程池 分别解释四种线程池newCachedThreadPoolnewCachedThreadPool,是一种线程数量不定的线程池，并且其最大线程数为Integer.MAX_VALUE，这个数是很大的，一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。但是线程池中的空闲线程都有超时限制，这个超时时长是60秒，超过60秒闲置线程就会被回收。调用execute将重用以前构造的线程(如果线程可用)。这类线程池比较适合执行大量的耗时较少的任务，当整个线程池都处于闲置状态时，线程池中的线程都会超时被停止。12345678910111213141516171819202122232425262728public class PoolExecutorTest &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub ExecutorService mCachelThreadPool = Executors.newCachedThreadPool(); for(int i = 0;i &lt; 7;i++ ) &#123; final int index = i; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; mCachelThreadPool.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println("第" +index +"个线程" +Thread.currentThread().getName()); &#125; &#125;); &#125; &#125; &#125; 从结果可以看到，执行第二个任务的时候第一个任务已经完成，会复用执行第一个任务的线程，不用每次新建线程。 newFixedThreadPoolnewFixedThreadPool 创建一个指定工作线程数量的线程池，每当提交一个任务就创建一个工作线程，当线程 处于空闲状态时，它们并不会被回收，除非线程池被关闭了，如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到池队列（没有大小限制）中。由于newFixedThreadPool只有核心线程并且这些核心线程不会被回收，这样它更加快速的响应外界的请求。12345678910111213141516171819202122232425262728public class PoolExecutorTest &#123; public static void main(String[] args) throws InterruptedException &#123; // TODO Auto-generated method stub //设置最大线程数5个 ExecutorService mFixedThreadPool = Executors.newFixedThreadPool(5); for(int i = 0;i &lt; 7;i++ ) &#123; final int index = i; mFixedThreadPool.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println("时间是:"+System.currentTimeMillis()+"第" +index +"个线程" +Thread.currentThread().getName()); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; &#125; 由于设置最大线程是5，所以当执行完这5个线程后，等待两秒后，在执行后面2个线程 newScheduledThreadPoolnewScheduledThreadPool 创建一个线程池，它的核心线程数量是固定的，而非核心线程数是没有限制的，并且当非核心线程闲置时会被立即回收，它可安排给定延迟后运行命令或者定期地执行。这类线程池主要用于执行定时任务和具有固定周期的重复任务12345678910111213141516171819202122public class PoolExecutorTest &#123; public static void main(String[] args) throws InterruptedException &#123; // TODO Auto-generated method stub //设置池中核心数量是2 ScheduledExecutorService mScheduledThreadPool = Executors.newScheduledThreadPool(2); System.out.println("现在的时间:"+System.currentTimeMillis()); mScheduledThreadPool.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; // TODO Auto-generated method stub System.out.println("现在的时间:"+System.currentTimeMillis()); &#125; &#125;, 2, 3,TimeUnit.SECONDS);//这里设置延迟2秒后每3秒执行一次 &#125; &#125; 可发现确实延迟2秒后每隔3秒后就会执行一次，程序不退出就一直执行下去 newSingleThreadExecutornewSingleThreadExecutor这类线程池内部只有一个核心线程，以无界队列方式来执行该线程，这使得这些任务之间不需要处理线程同步的问题，它确保所有的任务都在同一个线程中按顺序中执行，并且可以在任意给定的时间不会有多个线程是活动的123456789101112131415161718192021222324252627public class PoolExecutorTest &#123; public static void main(String[] args) throws InterruptedException &#123; // TODO Auto-generated method stub ExecutorService mSingleThreadPool = Executors.newSingleThreadExecutor(); for(int i = 0;i &lt; 7;i++) &#123; final int number = i; mSingleThreadPool.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println("现在的时间:"+System.currentTimeMillis()+"第"+number+"个线程"); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; &#125; 可发现是有顺序地去执行上面6个线程 上面的总结来自于csdn,总结的比较好，拿来自己收藏保存，没有抄袭！]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL深入学习 —— 主从分离]]></title>
    <url>%2F2019%2F03%2F07%2FMySQL%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0-%E2%80%94%E2%80%94-%E4%B8%BB%E4%BB%8E%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[MySQL深入学习 —— 主从分离如何实现MySQL的读写分离基于主从复制架构，有一个主库，挂多个从库，然后我们写在主库，读在从库 MySQL主从复制原理主库将变更写入binlog日志中，然后从库连接主库之后，从库有一个IO线程，将主库的binlog日志拷贝到自己本地，然后写入一个叫做relay中继日志中，接着从库有一个SQL线程从中继日志中取出binlog日志内容，然后执行，相当于执行了一遍sql语句，这样就保证了自己和主库的数据是一致的。 注：主库是并行执行的，但是从库是串行化执行的，所以在高并发下，从库数据与主库数据同步会有延迟。 然后会衍生出来一个问题，如果主库执行后还没有来得及给从库，就发生宕机了，那么从库数据就得不到同步。所以有两种比较不错的解决方案1. 半同步复制即 一旦主库变更写入binlog日志中，就会强制此时立即将数据同步到从库，从库日志写入自己的relay中继日志中之后，接着会返回主库一个ack表示，主库收到至少一个ack标识，就认为写操作完成了。2. 并行复制从库开启多个线程，并行读取relay log中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。 延迟比较严重，有以下解决方案 分库： 将一个主库拆分为多个主库，然后这样就可以减少一个主库的并发，从而缓轻从库的主从复制压力 重写代码： 在执行写之后一段时间内，不进行读操作 并行： 打开从库的并行复制 设置直连主库 ，这样分离没有意义 说到这儿了，还没有说为什么要读写分离(主从复制)，接下来说说 什么时候使用读写分离其实就是将数据库分为主库和从库，主库用来读，从库用来读，然后主从进行数据同步。由于互联网的应用大部分都是读多写少，所以我们可以使用读写分离方式来解决数据库的写瓶颈。但是选择读写分离要面对一下几个问题 数据库连接池要进行区分，哪些是读连接池，哪些是写连接池，研发难度很大 要保持主从一致性 为了保证高可用，读连接池要能使用故障自动迁移。 所以我们完全可以使用缓存来解决这些问题的，但是必须实现高可用，否则集群挂掉，所有的访问压力全部集中于数据库，数据库会瘫痪。 数据库的瓶颈以及解决办法数据容量是瓶颈，例如订单表，数据量只增不减，历史数据又必须要留存，非常容易成为性能的瓶颈，而要解决这样的数据库瓶颈问题，“读写分离”和缓存往往都不合适，最适合的是什么呢？答案是数据切分 数据切分切分的目的在于减少数据库的负担，缩短查询时间！数据库分布式的核心就是数据切分，以及切分后对数据的定位、整合数据切分根据其切分类型，可以分为两种方式：垂直（纵向）切分和水平（横向）切分详细学习，比较难理解，后续继续学习！]]></content>
      <categories>
        <category>mysql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[XML初步总结]]></title>
    <url>%2F2019%2F03%2F03%2FXML%E5%88%9D%E6%AD%A5%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[XML可扩展标记语言，是一种标记语言非常灵活，没有固定的标签，所有的标签都是自定义！通常用于信息的记录和传递！ xml格式格式良好的xml文档 必须有xml声明语句 必须有且仅有一个根元素 标签大小写敏感 属性值用双引用 标签成对 元素正确嵌套 有效的XML文档 首先必须有良好的格式 使用DTD和XSD定义语义约束 注释写法1&lt;!--这是注释--&gt; 123456789101112131415&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;books&gt; &lt;book&gt; &lt;name&gt;十月围城&lt;/name&gt; &lt;price&gt;21&lt;/price&gt; &lt;/book&gt; &lt;book&gt; &lt;name&gt;李沫熙&lt;/name&gt; &lt;price&gt;22&lt;/price&gt; &lt;/book&gt; &lt;book&gt; &lt;name&gt;杨宁宁&lt;/name&gt; &lt;price&gt;11&lt;/price&gt; &lt;/book&gt;&lt;/books&gt; xml解析然后我们需要解析到xml标签中的数据我们可以使用以下四种方法来解析1、DOM解析；2、SAX解析；3、JDOM解析；4、DOM4J解析我们着重了解一下 SAX解析方式 我们定义的xml内容 123456789101112131415&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;books&gt; &lt;book&gt; &lt;name&gt;十月围城&lt;/name&gt; &lt;price&gt;21&lt;/price&gt; &lt;/book&gt; &lt;book&gt; &lt;name&gt;李沫熙&lt;/name&gt; &lt;price&gt;22&lt;/price&gt; &lt;/book&gt; &lt;book&gt; &lt;name&gt;杨宁宁&lt;/name&gt; &lt;price&gt;11&lt;/price&gt; &lt;/book&gt;&lt;/books&gt; 然后使用SAX解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package com.nyist.xml;import org.xml.sax.Attributes;import org.xml.sax.SAXException;import org.xml.sax.helpers.DefaultHandler;import javax.xml.parsers.ParserConfigurationException;import javax.xml.parsers.SAXParser;import javax.xml.parsers.SAXParserFactory;import java.io.IOException;import java.util.ArrayList;import java.util.List;/** * SAX解析 */public class Test1 &#123; public static void main(String[] args) throws ParserConfigurationException, SAXException, IOException &#123; //1.获取解析工厂 SAXParserFactory factory =SAXParserFactory.newInstance(); //2. 从解析工厂获取解析器 SAXParser parser = factory.newSAXParser(); //3.编写处理器 BookHandler handler = new BookHandler(); //开始解析 parser.parse(Thread.currentThread().getContextClassLoader().getResourceAsStream("test.xml"),handler); //获得解析的数据 List&lt;Book&gt; books = handler.getBooks(); //使用增强for循环遍历 for (Book book : books) &#123; System.out.println("书名:"+book.getName()+"--&gt;"+"价格:"+book.getPrice()); &#125; &#125;&#125;class BookHandler extends DefaultHandler&#123; private List&lt;Book&gt; books; private Book book; private String tag; @Override public void startDocument() throws SAXException &#123; books = new ArrayList&lt;&gt;(); &#125; @Override public void startElement(String uri, String localName, String qName, Attributes attributes) throws SAXException &#123; if(qName != null)&#123; if(qName.equals("book"))&#123; book = new Book(); &#125; tag = qName; &#125; &#125; @Override public void characters(char[] ch, int start, int length) throws SAXException &#123; String str = new String(ch, start, length).trim(); if(str.length() &gt; 0)&#123; if(tag.equals("name"))&#123; book.setName(str); &#125;else if(tag.equals("price"))&#123; book.setPrice(Integer.valueOf(str)); &#125; &#125; &#125; @Override public void endElement(String uri, String localName, String qName) throws SAXException &#123; if(qName != null)&#123; if(qName.equals("book"))&#123; books.add(book); &#125; &#125; qName = null; &#125; public List&lt;Book&gt; getBooks() &#123; return books; &#125;&#125; 于是我们可以从我们的xml得到数据]]></content>
      <categories>
        <category>XML</category>
      </categories>
      <tags>
        <tag>XML初步总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2F2019%2F03%2F02%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[#正则表达式正则表达式是一个独立的语言，不区别于语言 标准字符表示的意义 自定义符合集合[] 方括号表示匹配方式，能够匹配方括号中的任意一个字符其中[]小数点不用转义，但是呢 - d 等都要转义 贪婪模式 | 不贪婪模式{}符号可以表示匹配前一个字符的次数，例如\d{5}表示匹配5位，同样的也有\d{2,6}表示最少匹配2位，最多匹配6位，但是会默认贪婪模式，默认匹配6位！我们可以在对应的后面添加?表示开启不贪婪模式，默认匹配最少的！我们也可以使用\d{3,}匹配最少3位，最多没有限制！ 其他使用方法 \b表示前面的字符和后面的字符不全是\w，用于匹配一个单词边界！ 选择符和分组我们可以使用反向引用的方式实现对分组已经捕获的字符串进行引用。具体操作： 每一对()都分配一个编号，具体顺序以左侧符号出现顺序为准，从1开始编号！ 预搜索只对子表达式进行匹配，匹配后的内容不计入最终的结果！是对位置的匹配！ 常用正则表达式亲测有效]]></content>
      <categories>
        <category>正则表达式</category>
      </categories>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式漏洞]]></title>
    <url>%2F2019%2F03%2F02%2F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E6%BC%8F%E6%B4%9E%2F</url>
    <content type="text"><![CDATA[单例模式的漏洞我们实现单例模式可以有5种实现方式，分别是 懒汉式、饿汉式、双重锁模式、枚举模式、静态内部类模式，但是呢，由于双重锁和JMM结构不一致吗，一般不推荐使用，但是其他的除了枚举模式以外，其他的都可被攻破！ 反射攻击模式1234567//1.通过反射攻破单例模式 Class&lt;SingletonDemo2&gt; clazz = (Class&lt;SingletonDemo2&gt;) Class.forName("com.nyist.singleton.SingletonDemo2"); Constructor constructor = clazz.getDeclaredConstructor(null); constructor.setAccessible(true); SingletonDemo2 singletonDemo21 = clazz.newInstance(); SingletonDemo2 singletonDemo22 = clazz.newInstance(); System.out.println(singletonDemo21 == singletonDemo22); 最后打印出的结果是false。也就是创建了不同的对象，即打破了单例模式。那么如何补救呢，可以这样，构建方法内判断对象存在后再决定是否创建 1234567891011121314public class SingletonDemo1 &#123; private static SingletonDemo1 demo1 = new SingletonDemo1(); //类初始化的时候，立刻加载对象 private SingletonDemo1() &#123; if(demo1 == null)&#123; demo1 = new SingletonDemo1(); &#125; &#125; public static SingletonDemo1 getInstance()&#123; return demo1; &#125;&#125; 序列化反序列化方式我们可以结合对象字节流的操作，将字节流先存储在文件中，然后读取，会创建一个不一样的对象12345678910111213141516171819202122232425262728//2.通过序列化攻破单例模式 FileOutputStream fileOutputStream = null; ObjectOutputStream objectOutputStream = null; ObjectInputStream objectInputStream = null; FileInputStream fileInputStream = null; try &#123; SingletonDemo2 singletonDemo2 = SingletonDemo2.getInstance(); System.out.println("开始"); System.out.println(singletonDemo2); fileOutputStream = new FileOutputStream("D:/test.txt"); objectOutputStream = new ObjectOutputStream(fileOutputStream); objectOutputStream.writeObject(singletonDemo2); fileInputStream = new FileInputStream("D:/test.txt"); objectInputStream = new ObjectInputStream(fileInputStream); SingletonDemo2 demo2 = (SingletonDemo2) objectInputStream.readObject(); System.out.println("结束"); System.out.println(demo2); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; fileInputStream.close(); objectInputStream.close(); objectOutputStream.close(); fileOutputStream.close(); &#125; 结果demo2和singletonDemo2的地址不相同，表示没有遵守单例模式我们如何避免呢在相应的类中加上此方法即可以后学习中，继续总结，走起…]]></content>
      <categories>
        <category>面试总结</category>
      </categories>
      <tags>
        <tag>单例漏洞和补修</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试总结(One)]]></title>
    <url>%2F2019%2F03%2F02%2F%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93-One%2F</url>
    <content type="text"><![CDATA[笔试总结(One)面向对象的五大基本原则 单一职责原则（SRP）一个类，最好只做一件事，只有一个引起它的变化。单一职责原则可以看做是低耦合、高内聚在面向对象原则上的引申，将职责定义为引起变化的原因，以提高内聚性来减少引起变化的原因。 开放封闭原则（OCP）软件实体应该是可扩展的，而不可修改的。也就是，对扩展开放，对修改封闭的 里氏替换原则（LSP）子类必须能够替换其基类。这一思想体现为对继承机制的约束规范，只有子类能够替换基类时，才能保证系统在运行期内识别子类，这是保证继承复用的基础。 依赖倒置原则（DIP）依赖于抽象。具体而言就是高层模块不依赖于底层模块，二者都同依赖于抽象；抽象不依赖于具体，具体依赖于抽象。 接口隔离原则（ISP）使用多个小的专门的接口，而不要使用一个大的总接口 单例模式饿汉式加载12345678910111213141516171819package com.nyist.singleton;/** * 饿汉式单例模式 * 线程安全 */public class SingletonDemo1 &#123; private static SingletonDemo1 demo1 = new SingletonDemo1(); //类初始化的时候，立刻加载对象 private SingletonDemo1() &#123; &#125; public static SingletonDemo1 getInstance()&#123; return demo1; &#125;&#125; 懒汉式什么时候需要什么时候加载1234567891011121314151617181920package com.nyist.singleton;/** * 懒汉式 */public class SingletonDemo2 &#123; private static SingletonDemo2 s; private SingletonDemo2()&#123; &#125; public static synchronized SingletonDemo2 getInstance()&#123; if(s == null)&#123; s = new SingletonDemo2(); &#125; return s; &#125;&#125; 静态内部类实现方式1234567891011121314151617package com.nyist.singleton;//静态内部类实现方式(也是一种懒加载的方式)public class SingletonDemo3 &#123; private static class SingletonClassInstance&#123; private static final SingletonDemo3 singletonDemo3 = new SingletonDemo3(); &#125; private SingletonDemo3() &#123; &#125; public SingletonDemo3 getInstance()&#123; return SingletonClassInstance.singletonDemo3; &#125;&#125; 枚举方式(没有懒加载的功能)12345678910111213141516package com.nyist.singleton;public enum SingletonDemo4 &#123; //枚举类型 本身就是单例模式 Instance; //添加自己所需要的操作 public void test()&#123; &#125; public static void main(String[] args) &#123; System.out.println(SingletonDemo4.Instance == SingletonDemo4.Instance);//结果为true &#125;&#125;]]></content>
      <categories>
        <category>面试总结</category>
      </categories>
      <tags>
        <tag>单例模式</tag>
        <tag>面向对象的五大基本原则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CDN]]></title>
    <url>%2F2019%2F02%2F17%2FCDN%2F</url>
    <content type="text"><![CDATA[CDN学习CDN介绍CDN也就是内容分布网络(Content Delivery Network)，它是构筑在现有Internet上的一种先进的流量分配网络。其目的是通过在现有的Internet中增加一层新的网络架构，将网站的内容发布到最接近用户的网络“边缘”，使用户可以就近取得所需的内容，提高用户访问网站的响应速度。有别于镜像，它比镜像更智能，可以做这样一个比喻:CDN=镜像(Mirror)+缓存(Cache)+整体负载均衡(GSLB)。因而，CDN可以明显提高Internet中信息流动的效率。 目前CDN都以缓存网站中的静态数据为主，如CSS、JS、图片和静态页面等数据。用户在从主站服务器请求到动态内容后，再从CDN上下载这些静态数据，从而加速网页数据内容的下载速度，如淘宝有90%以上的数据都是由CDN来提供的。 通常来说CDN要达到以下几个目标： 可扩展(Scalability)。性能可扩展性:应对新增的大量数据、用户和事务的扩展能力。成本可扩展性:用低廉的运营成本提供动态的服务能力和高质量的内容分发。 安全性( Security)。 强调提供物理设备、网络、软件、数据和服务过程的安全性，(趋势)减少因为DDoS攻击或者其他恶意行为造成商业网站的业务中断。: 可靠性、 响应和执行(Reliability、 Responsiveness 和Performance)。服务可用性指能够处理可能的故障和用户体验下降的问题，通过负载均衡及时提供网络的容错机制。 CDN架构这个流程其中包括了DNS域名解析的过程，通常是首先去Local DNS Server 请求，如果本地有ip对应的域名缓存，则直接获得对应的IP,但是如果本地没有缓存，那么就去Root DNS Server请求，然后返回一个对应域名的服务器地址，然后再向域名服务器(Name Server)发起请求,然后域名服务器返回对应的IP，这样用户就可以通过域名解析到对应的ip。]]></content>
      <categories>
        <category>CDN</category>
      </categories>
      <tags>
        <tag>CDN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM垃圾收集器]]></title>
    <url>%2F2019%2F02%2F13%2FJVM%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2F</url>
    <content type="text"><![CDATA[JVM垃圾收集器jdk1.7之后HotSpot虚拟机中提供了商用的G1收集器，之前都是实验状态 垃圾回收中的并发编程中的概念并发：用户线程和垃圾收集线程同时进行，用户进程在继续进行，而垃圾回收线程运行于另外一个CPU并行：指的是多条垃圾收集线程同时工作，但是用户线程在等待 Serial收集器这个收集器最大点特点除了是通过一个cpu或一条收集线程完成垃圾收集工作以外，还必须暂停掉其他所有工作的线程直至它收集完成由于单线程的运行机制，简单高效。在限定的单cpu的环境中，没有线程交互的开销，专心做垃圾回收工作，可以获得单线程环境下最高的收集效率虽然上特点会让我们觉着会被舍弃这个收集器，但是目前依然是虚拟机在client默认的新生代垃圾收集器 Serial为什么要用作client端的新生代收集器？原因：在用户的桌面应用中，一般分配给虚拟机的内存一般不会很大，收集几十兆甚至几百兆的内存，收集时间可以在几十毫秒或者几百毫秒之内，只要不频繁发生，这点停顿是可以接受的ParNew收集器是多线程版本的Serial，在Server中默认的新生代垃圾收集器。目前也只有它可以和CMS收集器配合工作。CMS垃圾回收器是 唯一 一个可以并发的垃圾收集器。用户线程可以和垃圾回收线程同时工作，CMS作为老年代垃圾收集器 Parallel Scavenge收集器新生代收集算法，使用复制算法的收集器它和其他的收集器关注点不同，cms等收集器关注点在于尽可能短的缩短停顿的时间，而Parallel Scavenge收集器是达到一个可控制的吞吐量(吞吐量 = 执行用户代码的时间/(运行用户代码时间+垃圾收集时间))，高吞吐量可以高效的使用利用CPU时间，完成计算任务，一般使用于后台计算而不需要太多交互的任务。对于尽可能减少停顿时间的收集器来说，更适合用做用户交互的任务，有很好的交互体验。由于与吞吐量关系密切，ParallelScavenge收集器也经常称为“吞吐量优先”收集器。除上述两个参数之外，Parallel Scavenge收集器还有一个参数-XX:+UseAdaptiveSizePolicy值得关注。这是一个开关参数，当这个参数打开之后，就不需要手工指定新生代的大小(-Xmn)、Eden 与Survivor区的比例(-XX:SurvivorRatio)、 晋升老年代对象年龄(XX:PretenureSizeThreshold)等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为GC自适应的调节策略(GC Ergonomics)。对于收集器运作原来不太了解，手工优化存在困难的时候，使用ParallelScavenge收集器配合自适应调节策略，把内存管理的调优任务交给虚拟机去完成将是一个不错的选择。只需要把基本的内存数据设置好(如-Xmx设置最大堆)，然后使用MaxGCPauseMillis参数( 更关注最大停顿时间)或GCTimeRatio(更关注吞吐量)参数给虚拟机设立一个优化目标，那具体细节参数的调节工作就由虚拟机完成了。 自适应调节策略也是ParallelScavenge收集器与ParNew收集器的一个重要区别。 Serial Old收集器Serial Old是Serial老年代版本，也同样是单线程收集器，使用”标记—整理”算法。这个收集器的主要意思在于在client下使用。如果使用在Server中，主要有两种用途。一中是在JDK1.5之前和ParallelScavenge搭配使用，另一种是作为cms的后备预案。 Parallel Old 收集器Parallel Old是ParallelScavenge收集器老年代的版本，使用多线程和”标记—整理”算法。 cms收集器老年代垃圾收集器，采用的是”标记—清除”算法，也被成为”并发低停顿收集器”CMS (Concurrent Mark Sweep)收集器是一种以获取最矩回收停顿时间为8标的收集器。目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上,这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用护带来较好的体验。CMS收集器就非常符合这类应用的需求。从名字(包含“Mark Sweep”)上就可以看出，CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几种收集器来说更复杂- - 些，整个过程分为4个步骤，包括: 初始标记(EMS initial mark) 并发标记(CMS concurrent mark ) 重新标记(CMS remark ) 并发清除(CMS concurrent sweep ) 其中，初始标记、重新标记这两个步骤仍然简要“Stop The World”.初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行Gc RootsTracing的过程，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。 G1收集器是一款面向服务端的一款垃圾收集器 G1的优点： 并行与并发: G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU (CPU 或者CPU核心)来缩短Stop-The-WorId停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行 分代收集:与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次GC的旧对象以获取更好的收集效果。 空间整合:与CMS的“标记一清理”算法不同，G1从整体来看是基于“标记一整理”算法实现的收集器，从局部(两个Region之间)上来看是基于“复制”算法实现的,但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。 可预测的停顿:这是G1相对于CMS的另一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java (RTSJ)的垃圾收集器的特征了。 在G1之前的收集器都是将JAVA堆区域分成新生代和老年代，但是G1虽然保留这两个概念，但是G1是把Java堆划分为多个大小相等的独立区域。它们不再是物理的隔离，它们都是一部分Region(不需要连续)的集合！ G1中的Region之间的对象引用以及其他收集器中的新生代和老年代的对象间对象引用，在做可达性分析对象是否存活时，需要判断，岂不是要扫描整个Java堆才可以保证准确性。但是，sun公司带来的解决方案是：虚拟机使用Remembered Set来避免全堆扫描的。虚拟机中每一个Region中都有一个Remembered Set，虚拟机发现程序在对Reference类型的数据进行写操作的时候，会产生一个Write Barrier暂停中断操作，检查Reference引用的对象是否存在同一个Region,如果是，便通过CardTable把相关引用信息记录到引用对象所在的Region对应的Rememberd Set之中。当进行垃圾回收时，在GC根节点的枚举范围中加入Rememberd Set 即可保证不对全栈扫描依然不会有遗漏！ 总结通过学习垃圾收集器的具体实现，然后结合之前的垃圾收集的四大方向，理清了JVM虚拟机HotSpot的垃圾收集机制！收益颇多！继续学习。。。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java底层知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HotSpot算法实现]]></title>
    <url>%2F2019%2F01%2F21%2FHotSpot%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[HotSpot算法实现枚举根节点在可达性分析中从GC Roots节点找引用链，可以作为GC Roots的节点主要在全局性引用(例如 常量或静态属性)与执行上下文（例如堆帧中的本地变量表）中，现在很多应用仅仅方法区就有数百兆，如果逐个检查这里面的引用，必然会消耗很多时间。 另一个对时间影响的是GC停顿，因为执行期间必须保证在一致性的快照中进行，意思是整个分析期间整个执行系统看起来好像就冻结在某个时间点，不可以出现分析对象引用关系还在不断变化的情况，如果这点不满足的话会出现结果准确性无法得到保障。这就是导致GC进行时必须停顿所有Java执行程序中最重要的一个原因。 目前主流的Java虚拟机，都是准确性GC，当执行系统停顿下来的时候，并不需要一个不漏的检查完所有执行上下文和全局的引用位置，虚拟机应当知道哪些地方存放着对象引用。在HotSpot实现中，是使用一组成为OopMap的数据结构来达到这个目的 的，这样在GC扫描时就会得知这些信息了。 安全点在OopMap的协助下，HotSpot可以快速且准确地完成GC Roots枚举，但一很现实问题随之而来。可能导致引用关系变化，或者OopMap内容变化的指令非常多，如果为每一条指令都生成对应的OopMap,那将会需要大量的额外空间，这样GC的空间成本将会变得很高，实际上HotSpot 也的确没有为每条指令都生成OopMap，只是在“特定的位置”记录了这些信息，这些位置称为安全点(Safepoint),即程序执行时并非在所有地方都能停顿下来开始GC,只有在到达安全点时才能暂停。Safepoint的选定既不能太少以致于让GC等待时间太长，也不能过于频繁以致于过分增大运行时的负荷。所以，安全点的选定基本上是以程序“是否具有让程序长时间执行的特征”为标准进行选定的，因为每条指令执行的时间都非常短暂程序不太可能因为指令流长度太长这个原因而过长时间运行，“长时间执行”的最明显特征就是指令序列复用，例如方法调用、循环跳转、异常跳转等，所以具有这些功能的指令才会产生Safepoint. 对于Sefepoint;另一个需要考虑的问题是如何在GC发生时让所有线程(这里不包括执行JNI调用的线程)都“跑”到最近的安全点上再停顿来。这里有两种方案可供选择:抢先式中断(Preemptive Suspension) 和主动式中断(Voluntary Suspension)，其中抢先式中断不需要线程的执行代码主动去配合，在GC发生时，首先把所有线程全部中断，如果发现有线程中断的地方不在安全点上，就恢复线程，让它“跑”到安全点上。现在几乎没有虚拟机实现采用抢先式中断来暂停线程从而影响GC事件。 而主动式中断指的是当GC需要中断线程的时候，不需要直接对线程操作，仅仅简单的设置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时，就自己中断挂起。轮询标志的地方和安全点是重合的，另外加上创建对象需要分配的地方。 安全区域使用Safepoint似乎已经完美地解决了如何进人GC的问题，但实际情况却并不一定。Safepoint机制保证了程序执行时，在不太长的时间内就会遇到可进人GC的Safepoint。但是，程序“不执行”的时候呢?所谓的程序不执行就是没有分配CPU时间，典型的例子就是线程处于Sleep状态或者Blocked状态，这时候线程无法响应JVM的中断请求，“走”到安全的地方去中断挂起，JVM也显然不太可能等待线程重新被分配CPU时间。对于这种情况，就需要安全区域( Safe Region)来解决。 安全区域是指在一段代码片段之中，引用关系不会发生变化。在这个区域中的任意地方开始GC都是安全的，我们也可以把SafeRegion看做是被扩展了的Safepoint。在线程执行到Safe Region 中的代码时，首先标识自己已经进人了Safe Region,那样，当在这段时间里JVM要发起GC时，就不用管标识自己为SafeRegion状态的线程了。在线程要离开Safe Region时，它要检查系统是否已经完成了根节点枚举(或者是整个GC过程)，如果完成了，那线程就继续执行，否则它就必须等待直到收到可以安全离开Safe Region的信号为止。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java底层知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM垃圾收集算法]]></title>
    <url>%2F2019%2F01%2F19%2FJVM%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[JVM垃圾收集算法各个平台的虚拟机操作内存的方法各不相同，因此我们只讨论几种算法的思想以及发展过程。 标记—清除算法 最基础的收集算法是“标记-清除”(Mark-Sweep)算法，如同它的名字一样，算法分为“标记”和“清除”两个阶段:首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象，它的标记过程就是引用计数算法。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。它的主要不足有两个:一个是效率问题，标记和清除两个过程的效率都不高;另一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作 复制算法 为了解决效率问题，一种称为“复制”(Copying)的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半，未免太高了一点。 注意：由于新生代的对象98%是”朝生夕死”的，所以我们并不需要按照1:1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中的一块Survivor。当回收时，将Eden和Survivor中还存活的对象一次性的复制到另一块Survivor的空间上，最后清理掉Eden和刚才用过的Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也就是每次新生代中可用内存空间是整个新生代容量的90%(80%+10%),只有10%的内存会被“浪费”。当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收只有不多余10%的对象存活，当Survivor空间不够用的时候，需要依赖其他内存(老年代)进行分配担保。 标记—整理算法 复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。根据老年代的特点，有人提出了另外一种“标记-整理”(Mark-Compact)算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存 分代收集算法分代收集并没有什么新的思想，只是根据对象存活周期不同将内存分为几块。一般Java堆分为新生代和老年代，这样就可以根据各个年代的特点来采用最合适的收集算法。在新生代中，每次垃圾收集时都会发现大批对象死去，只有少量存活，那就采用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外的空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来实现回收。 总结当我深入了解Java虚拟机的时候，才会知道原来我们平时Java虚拟机的GC垃圾回收原来是这么自动回收的，很震撼，也会为以后出现GC机制没有回收一些内存而造成内存溢出寻找原因打下基础]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm底层学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaWeb基础]]></title>
    <url>%2F2019%2F01%2F17%2FJavaWeb%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[JavaWeb基础JDBC技术JDBC操作数据库流程 Class.forName()加载数据库连接驱动 DriverManager.getConnection()获取数据库连接对象 根据SQL获取sql会话对象，有两种方式Statement、PreparedStatement 执行SQL处理结果集，执行SQL前如果有参数值就设置参数值 关闭结果集、关闭会话、关闭连接 关于使用PreparedStatement不使用Statement的原因 PreparedStatement继承自Statement，PreparedStatement实例包含已编译的SQL语句，因此执行速度快 PreparedStatement三个方法execute、executeQuery、executeUpdate已经更改为不再需要参数 PreparedStatement不需要不断的拼接，但是Statement需要 PreparedStatement传入的内容不会和sql语句发生任何的匹配关系，但Statement容易被SQL注入 关系数据库中连接池的机制是：前提：为数据库连接建立一个缓冲池 从连接池获取或者创建一个可用连接 使用完毕后，把连接返回给连接池 在系统关闭前，断开所有连接并释放连接占用的系统资源 能够处理无效连接，限制连接池中的连接总数不低于或者不超过某个限定值 注：数据库连接池数量一直保持一个最小连接数的数量，当数量不够时，数据库会创建一些连接，直到一个最大连接数，之后的数据库连接就会等待。 Http的长连接和短连接Http协议有HTTP/1.0版本和HTTP/1.1版本。HTTP/1.1默认保持长连接，数据传输完成完成了依然保持TCP连接不断开，等待同域名下继续使用这个通道传输数据。HTTP/1.0默认是短连接，浏览器和服务器每一次进行HTTP操作，就建立一次连接，任务结束就中断连接。 Cookie和SessionCookie和Session的区别：Cookie是web服务器发送给浏览器的一块信息，浏览器会在本地一个文件中给每个web服务器存储cookie。以后浏览器再给特定的web服务器发送请求时，同时会发送所有为该服务器存储的cookie。Session是存储在web服务器端的一块信息。session对象存储特定的用户会话所需的属性以及配置信息。当用户在应用程序的web页之间跳转时，存储在Session对象中的变量将不会丢失，而是在整个会话中一直存在下去。 Cookie和Session的不同点： 无论客户端做怎样的配置，session都能正常工作。当客户端禁用cookie时将无法使用cookie 存储方面，session可以存储任何的java对象，cookie只能存储String类型的对象 关于Session在集群和分布式中的共享问题我们可以使用服务器session复制共享，但是session广播通知其他session会造成网络流量瓶颈，同时session中的内容序列化也会消耗系统性能，所以最好使用接触redis实现session共享：原理： 当服务器发现session不在本机内存中，则会去redis中查找，如果redis查到，会复制到本机。这样就可以实现session同步和高可用！有时候我们可能担心redis宕机，所以我们要使用一主多备，由于redis宕机后不会自动切换master，所以需要结合keepalived来实现切换问题！ 单点登录原理后端生成一个session ID,然后设置到cookie，后面的所有请求 浏览器都会带上cookie，然后服务器端从cookie里面获取sessionID,再查找用户信息。所以，保持登录的关键不是cookie,而是通过cookie保存和传输的sessionID,其本质是能获取用户信息的数据。除了cookie,还通常使用HTTP请求头来传输。但是这个请求头浏览器不会像cookie一样自动携带，需要手工处理。 JSP技术Jsp本质上就是一个Servlet，它是Servlet的一种特殊形式，每个jsp页面都是一个Servlet实例。Servlet是由java提供用于开发web服务器应用程序的一个组件，运行在服务端，由servlet容器管理，用来生成动态内容。一个servlet实例是实现了特殊接口Servlet的Java类，所有自定义的servlet均必须实现Servlet接口。 jsp servlet对比：jsp是html页面中内嵌的Java代码，侧重页面显示Servlet是html代码和java代码分离，侧重逻辑控制，mvc设计思想中jsp位于视图层，servlet位于控制层 JVM只能识别java类，并不能识别jsp代码！web容器收到以.jsp为扩展名的url请求时，会将访问请求交给tomcat中jsp引擎处理，每个jsp页面第一次被访问时，jsp引擎将jsp代码解释为一个servlet源程序接着编译成servlet源程序生成.class文件，再由web容器servlet引擎去装载执行servlet程序，实现页面交互。 jsp域对象一个4个域对象 pageContext 指当前页面，在当前jsp页面有效，跳转到其他页面失效 request request域指的是在一次请求范围内有效，从http请求到服务器处理结束，返回响应的整个过程。 session session域指的是当前会话有效范围，浏览器从打开到关闭的过程中，转发、重定向均可以使用。 application context域指的是能在同一个web中使用，服务器未关闭或者重启，数据有效。 XML技术复习xml是一种可扩展性标记语言，支持自定义标签(使用前必须预定义)使用DTD和XML Schema标准化XML结构优点：用于配置文件，格式统一，符合标准；用于在互不兼容的系统间交互数据，共享数据方便。缺点：xml文件格式复杂，数据传输占流量，服务端和客户端解析xml文件占用大量资源且不易维护xml常用解析器有两种： DOM解析，xml文档以DOM树形结构加载入内存 SAX解析，采用事件模型]]></content>
      <categories>
        <category>JavaWeb</category>
      </categories>
      <tags>
        <tag>JavaWeb基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存]]></title>
    <url>%2F2019%2F01%2F16%2FJVM%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[JVM内存内存泄露:是指程序中己动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。 GC机制既然java有垃圾回收(GC)机制，理论上不应该有内存泄露的问题，然而总会有无用但可达的对象，这些对象不能被GC回收，因此也会导致内存泄露的发生。例如： hibernate的Session(一级缓存)中的对象属于持久态，垃圾回收器是不会回收这些对象的，然而这些对象可能存在无用的垃圾对象，如果不及时关闭或者清空一级缓存可能会导致内存泄露 注：栈的pop方法调用，即使栈的程序不再引用这些对象，因为栈内部维护着这些对象的过期引用，所以该不会被当做垃圾回收。这种内存泄露是隐蔽的，垃圾回收机制同时也不会回收内存泄露对象所引用的对象。因此会导致很多对象都排除在垃圾回收之外，从而对性能产生重大的影响 Java中为什么要有GC机制 安全性考虑 减少内存泄露 减少程序员的工作量 Java的GC需要回收那些缓存内存运行时，JVM会有一个运行时数据区来管理内存，包括: 程序计数器 虚拟机栈 本地方法栈 方法区 堆 程序计数器、虚拟机栈、本地方法栈都是每个线程私有的内存空间，随着线程而生，随线程而死。这三个区域的内存分配和回收都是确定的，无序考虑回收的问题，但是方法区和堆就不同了，一个接口的多个实现类需要的内存可能不一样。我们只有在程序运行期间才会知道会创建哪些对象，这部分内存的分配和回收都是动态的，GC主要关注的就是这部分内存 内存溢出的原因很多，简单举几个： 内存中加载的数据量过于庞大，如一次从数据库中取出过多数据 集合类中有对对象的引用，使用完没有情况，使JVM不能回收 代码中存在死循环或者代码中产生过多重复的对象实体]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm底层学习</tag>
        <tag>java底层知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程复习知识点总结]]></title>
    <url>%2F2019%2F01%2F16%2F%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[线程复习知识点总结并行： 指的是多个线程同时运行(多核CPU)并发: 借助CPU的高速运转，只不过切换时间极短，用户察觉不到，这也是多线程运行的原因 JVM启动也是属于多线程的，在运行主线程的同时，与之切换运行的至少也有垃圾回收线程在JAVA实现多线程的两种方法 继承Thread: 由于子类重写了Thread类的run(),当调用start()时，直接去找子类的run()方法 实现Runnable: 构造函数中传入Runnable的引用，成员变量记住了它，start()调用run()方法内部判断成员变量Runable的引用是否为空，不为空编译时看的是Runnable的run(),运行时执行子类的run方法 Thread的方法： Thread.currentThread().getName();获取当前线程然后再获取到线程的名字join():当前线程停止，然后等待其他线程执行结束后，再恢复运行状态(应该抛出中断异常)yield: 让出cpu执行权给其他线程（Thread.yield()）setPriority(): 设置优先级，默认是5,值范围在0-10之间代码块加锁的时候，不能用匿名对象，否则synchronized不起作用非静态的同步方法的锁对象是this静态的同步锁对象是字节码对象 同步代码块嵌套会导致死锁StringBuffer适用于多线程下在字符缓冲区进行大量操作的情况,它是线程安全的StringBuilder适用于单线程下在字符缓冲区进行大量操作的情况，他是线程不安全的String是适用于少量的字符串操作的情况 单例设计模式（保证类在内存中只有一个对象） 线程的生命周期 新建、就绪、阻塞、运行、死亡]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>线程学习总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WEB安全学习总结]]></title>
    <url>%2F2019%2F01%2F16%2FWEB%E5%AE%89%E5%85%A8%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[WEB安全黑客攻击过去大部分都是直接对服务器进行溢出攻击的方式，或者是端口扫描WEB强大的四个原因： 数据库，编程语言，web容器，优秀的程序设计者 攻击者入侵服务器最有可能从以下这几点入手： 攻击者在渗透服务器时，直接对目标下手- -般有三种手段，当我们了解了攻击者的手段之后，防御也就变得简单了。 C段渗透:攻击者通过渗透同一网段内的一台主机对目标主机进行ARP等手段的渗透。 社会工程学:社会工程学是高端攻击者必须掌握的一 -个技能，渗透服务器有时不仅仅只靠技术。 Services:很多传统的攻击方式是直接针对服务进行溢出的，至今一些软件仍然存在溢出漏洞。像之前的MySQL就出现过缓冲区溢出漏洞。当然，对这类服务还有其他入侵方式，这些方式也经常用于内网的渗透中 Http响应码Http协议中的状态码有三个数字组成： 第一位数字定义了响应的类别，且只有以下5种。 1xx:信息提示，表示请求已被成功接收，继续处理。其范围为100~ 101。 2xx: 成功，服务器成功地处理了请求。其范围为200~ 206。 3xx:重定向，重定向状态码用于告诉浏览器客户端，它们访问的资源已被移动，并告诉客户端新的资源地址位置。这时，浏览器将重新对新资源发起请求。其范围为300~305。 4xx:客户端错误状态码，有时客户端会发送一些服务器无法处理的东西，比如格式错误的请求，或者最常见的是，请求一个不存在的URL。其范围为400~415。 5xx:有时候客户端发送了一.条有效请求，但Web服务器自身却出错了，可能是Web服务器运行出错了，或者网站都挂了。5XX就是用来描述服务器内部错误的，其范围为500~ 505。 常见的状态码描述如下200:客户端请求成功，是最常见的状态。302:重定向。 404:请求资源不存在，是最常见的状态。 400:客户端请求有语法错误，不能被服务器所理解。 401:请求未经授权。 403:服务器收到请求，但是拒绝提供服务。500:服务器内部错误，是最常见的状态。 503:服务器当前不能处理客户端的请求，一段时间后可能恢复正常 Https和Http HTTPS协议的全称为Hypetext Transfer Protocol over Secure Socket Layer,它是以安全为目标的HTTP通道，其实就是HTTP的“升级”版本，只是它比单纯的HTTP协议更加安全。 HTTPS的安全基础是SSL,即在HTTP下加入SSL层。也就是HTTPS通过安全传输机制进行传送数据，这种机制可保护网络传送的所有数据的隐秘性与完整性，可以降低非侵入性拦截攻击的可能性。 既然是在HTTP的基础上进行构建的HTTPS协议，所以，无论怎么样，HTTP 请求与响应都是以相同的方式进行工作的。 HTTP协议与HTTPS协议的主要区别如下。 HTTP是超文本传输办议，信息是明文传输，HTTPS则是具有安全性的SSL加密传输协议。 HTTP与HTTP协议使用的是完全不同的连接方式，HTTP采用80端口连接，而HTTP :则是443端口。 HTTPS协议需要到ca申请证书，一-般免费证书很少，需要交费,也有些Web容器提供，如TOMCAT。而HTTP协议却不需要。 HTTP 连接相对简单，是无状态的，而HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，相对来说，它要比HTTP协议更安全。 JS前台校验室不安全的，我们可以绕过Js校验，发现隐藏标签内容前端校验的存在只是为了规范用户的操作，而服务器端验证才是为防止恶意攻击！我们可以使用代理的方式修改HTTP请求，绕过Js校验，并向服务器端提交敏感数据，造成XSS跨站漏洞。 黑帽子SEO入侵黑帽SEO中一个提升排名的手段就是友情链接，与较大的网站做友情链接，那么自身的网站排名就有优势，一般黑客会对网站进行攻击，然后偷偷的挂上友情链接(黑链)，从而获得更好的排名 上面的那种攻击一般上都是利用HTTP协议搞的鬼。主要通过Referer和User-agent,黑帽子SEO就是通过这两个头来欺骗搜索引擎的！其中Referer告诉WEB服务器，用户是从哪个页面找过来的，而USER-AGENT告诉WEB服务器用户使用的浏览器和操作系统信息。当用户通过搜索引擎打开此网站时，一般会引出源页面（Referer头）]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>web安全学习总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM]]></title>
    <url>%2F2019%2F01%2F15%2FJVM%2F</url>
    <content type="text"><![CDATA[深入学习JVM学习总结按照java技术关注的重点业务领域来划分，java技术体系可以划分为4个平台 Java Card: 支持一些Java小程序( Applets) 运行在小内存设备(如智能卡)上的平台。 Java ME (Micro Edition): 支持Java程序运行在移动终端(手机、PDA). 上的平台，对Java API有所精简，并加入了针对移动终端的支持，这个版本以前称为J2ME。 JavaSE(StandardEdition):支持面向桌面级应用(如Windows下的应用程序)的Java平台，提供了完整的Java核心API,这个版本以前称为-J2SE。 Java EE ( Enferprise Edition) :支持使用多层架构的企业应用(如ERP、CRM应用)的Java平台，除了提供Java SE API外，还对其做了大量的扩充并提供了相关的部署支持，这个版本以前称为J2EE。 HotSpot VM是SunJDK和OPenJDK中所带的虚拟机，也是目前使用最广泛的虚拟机，看HotSpot名字就知道，具有基于计数器热点代码探测能力，通过执行计数器找出最具有编译价值的代码，然后通知JIT编辑器以方法为单位进行编译。 多核并行CPU硬件从当初的高频率到现在的多核心，软件也开始关注编程的并行.jdk1.5开始引入java.util.concurrent包实现一个粗粒度的并发框架。在jdk1.7加入了的java.util.concurrent.forkjoin包是对这个框架的一次重要扩充。Fork/Join模式是处理并发编程的一个景点方法，虽然不能解决所有的问题，但是在此模式的使用范围之内，能够轻松的利用多个cpu核心提供的计算资源来协作完成一个负责的计算任务。通过Fork/Join模式，我们能够更加顺畅的过渡到多核时代 OPenJDK的子项目Sumatra,目前显卡的计算运算、并行能力已经远远超过CPU。Sumatra项目就是为java提供使用GPU和APU运算能力的工具。在JDK外围，有专门满足计算需求的计算框架，如Apache的Hadoop Map/Reduce.这个是一个简单易懂的并行框架，能够运行在由上千个商用机器组成的大型集群上，并且能以一种可靠的容错方式并行处理TB级别的数据集 PV: 页面浏览量，通常是衡量一个网络新闻频道或者网站甚至一条网络新闻的主要指标Java堆区的内存大小设置还需要依赖于具体的操作系统平台导致系统瓶颈的计算资源明天继续学习总结…]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm底层学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深挖基础知识]]></title>
    <url>%2F2019%2F01%2F12%2F%E6%B7%B1%E6%8C%96%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[深挖基础知识动静态代理的区别，什么场景使用静态代理通常只代理一个类，动态代理是代理一个接口下的多个实现类静态代理事先知道代理的是什么，而动态代理不知道代理什么东西，只有运行的时候才知道。动态代理是实现JDK里的InvocationHandler接口的invoke方法。但注意的是代理的是接口，也就是你的业务类必须实现接口，通过Proxy里的newProxyInstance得到代理对象AOP是基于动态代理实现的，比如著名的Spring框架、Hibernate框架等待都是动态代理的使用例子 Java中单例设计模式分为懒汉式和饿汉式饿汉式指的是在使用前就提前创建好，懒汉式指的是先声明变量名，然后什么时候使用再创建。 JVM垃圾回收机制和常见算法GC在回收对象前必须发现那些无用的对象，那么如何发现呢？常用的搜索算法： 引用计数器算法(废弃)指的是在创建每个对象时设置一个计数器，当有地方使用时，加1，当引用失效后，计数器减1，当计数器为0的时候，JVM就认为对象不再被使用。但是即使计数器实现简单，效率高，但不能解决循环引用的问题，同时也会带来额外的开销，从jdk1.1之后这个算法就被丢弃了 根搜索算法根搜索算法是通过一些”GC Roots”对象作为起点，从这些节点开始搜索，搜索通过的路径成为引用链，当一个对象没有被GC Roots的引用链连接的时候，说明这个对象不可用 GC Roots对象包括： 虚拟机栈(栈帧中的本地变量表)中的引用对象 方法区域中的静态属性引用的对象 方法区域中常量引用的对象 本地方法栈中JNI中引用的对象 搜索到无用对象后，回收算法： 标记—清除算法(DVM使用的算法)： 效率不高，清除后有许多不连续的空间 复制算法：将内存分成两块，当垃圾回收的时候，把存活的对象复制到另一块，然后把这个内存整个清除掉。但是由于每次只能使用其中的一半，所以内存利用率不高，现在的JVM用复制方法收集新生代，由于新生代大部分对象都是朝生夕死的，所以两块的内存比例不再是一半一半了！ 标记—整理算法：适合收集存活时间比较久的对象，因为他是把存活的对象往内存的一端移动，然后回收边界以外的内存，从而提高了内存利用率。 分代收集： 根据对象的存活时间把内存分为新生代和老年代，每个代采用不同的垃圾回收算法。新生代使用复制算法，然后老年代采用标记整理算法。实现方式依赖于不同的虚拟机。 JVM内存结构 方法区： 静态分配，编译器将变量绑定到某个存储位置，而且绑定不会在运行时改变。常数池，源代码的命名常量、String常量和static变量保存在方法区 Java Stack(栈)： 一个栈的空间可能是连续的，也有可能不连续。栈中存储数据也是运行时确定的 堆分配： 以任意的顺序，在运行时进行存储空间分配和收回的内存管理模型。堆存储的数据通常是大小，数量和生命期在编译是不能确定的 JAVA内存分配 基本数据类型直接在栈空间分配 方法的形式参数，直接在栈空间分配，当方法调用完从栈空间回收 引用数据类型，需要通过new来创建，既在栈空间分配一个地址空间，又在堆空间分配对象的类变量 方法的引用参数，在栈空间分配一个地址空间，并指向堆空间的对象区，当方法调用结束之后从栈空间回收 局部变量通过new出来的，在栈空间和堆空间中分配空间，当局部变量生命周期结束后，栈空间立刻被回收，堆空间区域等待GC回收 方法调用时传入的实际参数，先在栈空间分配，在方法调用完成后从栈空间释放。 字符串常量在 DATA区域分配，this在堆空间分配 数组既在栈空间分配数组名称，又在堆空间分配数组实际的大小 Java强引用，垃圾回收器绝不会回收它，即使内存不够报错。Java引用分为四种级别： 强引用 软引用 弱引用 虚引用 1234String abc = new String("abc"); //强引用SoftReference&lt;String&gt; softRef = new SoftReference&lt;String&gt;(abc); //软引用WeakReference&lt;String&gt; weakRef = new WeakReference&lt;String&gt;(abc); //弱引用softRef.clear(); //虚引用 heap和stack区别 申请方式： stack是系统自动分配。系统自动在栈中开辟空间 heap是程序员自己申请并且指定大小，通过new的方式 申请后系统反应： stack: 只要是栈的剩余空间大于所申请的空间大小，系统将为程序提供内存，否则包异常提示栈溢出 heap: 操作系统有一个记录空间内存地址的链表，当系统收到程序申请时，会遍历链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从链表中删除，并把结点的空间分配程序。系统会将多余的那部分重新放入空闲链表中。 申请的大小限制: stack: 栈是向低地址扩展的数据结构，是一块连续的内存区域。栈顶地址和栈的最大容量是事先设定好的，栈的能获得空间很小 heap:堆是从向高地址扩展的数据结构，不是连续的内存区域。由于系统是用链表来储存空间内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址的。堆的大小受限于计算机系统的有效虚拟内存的大小。由此可见，堆获得的空间比较灵活，也比较大。 申请效率的比较: stack: 由系统自动分配，速度较快。程序员无法控制的 heap: 由new分配的内存，一般速度比较慢，容器产生内存碎片 Java的类加载器种类 根类加载器 扩展类加载器 系统(应用)类加载器 自定义加载器(必须继承ClassLoader) java类加载体系值ClassLoader双亲委托机制java是一种类型安全的语言，它有四类称为安全沙箱机制的安全机制来保证语言的安全性，这四种分别是： 类加载机制 .class文件检验器 内置于java虚拟机(及语言)的安全特性 安全管理器及java api java程序中的.java文件编译完成会生成.class文件，而.class文件就是通过类加载器的ClassLoader加载的，而ClassLoader在加载过程中会使用“双亲委派机制”来加载.class文件]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java底层知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的反射机制]]></title>
    <url>%2F2019%2F01%2F10%2FJava%E7%9A%84%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Java的反射机制什么是反射在运行状态中，对于任意一个类，都能获取这个类的属性和方法，对于任意一个对象，都能调用它的任意一个方法和属性(包含私有的属性和方法)。这种动态获取的信息以及动态调用对象的方法的功能就成为java语言的反射机制。通俗来讲，通过反射，该类对于我们来说是完全透明的，想要获取任何东西都可以。 想要使用反射机制，就必须先获取到该类的字节码文件对象(.class)，通过字节码文件对象，就能够通过该类中的方法获取到我们想要的所有信息(方法、属性、类名、父类名、实现所有的接口等)，每一个类对应着一个字节码文件，也就对应着一个class类型的对象，也就是字节码文件对象。 获取字节码的三种方式 1Class clazz1 = Class.forName("全限定类名"); //通过Class类中的静态方法forName，直接获取到一个类的字节码文件对象，此时该类还是源文件阶段，并没有变为字节码文件。 1Class clazz2 = Person.class; //当类被加载成.class文件时，此时Person类变成了.class，在获取该字节码文件对象，也就是获取自己， 该类处于字节码阶段 1Class clazz3 = p.getClass(); //通过类的实例获取该类的字节码文件对象，该类处于创建对象阶段 反射机制能够获取哪些信息通过字节码对象创建实例对象12Class clazz1 = Class.forName("cn.itcast.pojo.User");User user = (User)clazz1.newInstance(); // 我们就可以使用user获取我们想要的信息 获取指定更多构造器方法，有参构造123Class clazz1 = Class.forName("cn.itcast.pojo.User");clazz1.getConstructor(Integer.class,String.class);User user = (User)clazz1.newInstance(21,"李茂展"); // 通过构造器实例化对象，实际参数传入 获取成员变量并且使用Field对象 ###获取方法并使用Method 上面获取字节码的方式只展示了通过Class类的静态方法forName。其他方式同样可以完成上面的操作。这里就不一一演示了。我觉着，java反射机制理解概念最为重要。 注：上面的学习内容借鉴与此文章。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java反射机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo和SpringBoot]]></title>
    <url>%2F2019%2F01%2F07%2FDubbo%E5%92%8CSpringBoot%2F</url>
    <content type="text"><![CDATA[Dubbo和SpringBoot建议大家看看官方文档springboot对应dubbo版本关系 springboot整合Dubbo灰度发布：指的是新功能发布，部分用户尝试使用，一部分用户继续使用旧的功能，尝试稳定后，慢慢恢复！ 服务提供者pom.xml引入dubbo，由于我使用的是springboot2.1,所以 dubbo必须使用0.2.012345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.0&lt;/version&gt;&lt;/dependency&gt; 代替原先的provider.xml,同样的配置写在application.yml中之前我们对外暴露接口是xml配置，由于以后对外暴露接口太多，为了方便我们使用@Service (import com.alibaba.dubbo.config.annotation.Service);1234567891011dubbo: application: name: boot-service-provider registry: address: zookeeper:127.0.0.1:2181 protocol: name: dubbo port: 20880 # 通信规则# 连接监控中心 monitor: protocol: register 然后启动时，千万别忘了开启dubbo注解配置12345678910111213import com.alibaba.dubbo.config.spring.context.annotation.EnableDubbo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@EnableDubbo // 开启注解的dubbo功能@SpringBootApplicationpublic class BootServiceProvider &#123; public static void main(String[] args) &#123; SpringApplication.run(BootServiceProvider.class,args); &#125;&#125; 服务消费者pom.xml和服务提供者的相同然后使用application.yml替代原先的consumer.xml配置以前我们使用@Autowired,现在我们使用@Reference加载接口12345678dubbo: application: name: boot-service-consumer registry: address: 127.0.0.1 protocol: zookeeper monitor: protocol: register 然后启动时，千万别忘了开启dubbo注解配置123456789101112import com.alibaba.dubbo.config.spring.context.annotation.EnableDubbo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@EnableDubbo@SpringBootApplicationpublic class BootServiceConsumer &#123; public static void main(String[] args) &#123; SpringApplication.run(BootServiceConsumer.class,args); &#125;&#125; 然后运行成功！ Dubbo属性配置加载顺序规则：（方法级优先，接口级次之，全局配置再次之，如果级别一样，消费方优先，提供方次之）官网告诉我们有三种可以dubbo属性配置的方法，它们互补，优先级顺序为： Dubbo启动时检查很多时候，注册中心没有对应的服务的时候，消费者就已经启动了，往往会报错，原因:dubbo默认启动时检查我们可以在yml关闭启动时检查()123dubbo: reference: check: false 关闭所有服务的不检查123dubbo: consumer: check: false 在启动的时候，如果没有注册中心，会报错，但是我们可以关闭123dubbo: registry: check: false 消费者全局配置(dubbo.provider)123dubbo: provider: timeout: 2000 # 单位秒 timeout retries它们两个配合使用，timeout1234dubbo: consumer: timeout: 1000 # 单位毫秒，默认是1000 访问大于1秒就会报错 retries: 3 # 第一次尝试失败不算，总共尝试三次 dubbo多版本就是我们上面提到的灰度发布,我们使用 version版本来控制版本123dubbo: provider: version: 0.0.2 我们在消费者使用时使用*的方式,会随机切换 本地存根客户端一般只有接口，具体的实现都在服务器端，但是有时候我们想要做参数的提前校验，以及做缓存之类的这个时候我们只需要在客户端创建类实现远程调用接口，然后里面必须有一个构造函数12345678910111213141516171819202122232425import com.itcast.gmall.bean.UserAddress;import com.itcast.gmall.service.UserService;import org.springframework.util.StringUtils;import java.util.List;public class UserServiceStub implements UserService &#123; private final UserService userService; public UserServiceStub(UserService userService) &#123; this.userService = userService; &#125; // 构造函数传入真正的远程代理对象 public List&lt;UserAddress&gt; getUserAddressList(String userId) &#123; //如果参数不为空就返回 if(!StringUtils.isEmpty(userId))&#123; List&lt;UserAddress&gt; userAddressList = userService.getUserAddressList(userId); return userAddressList; &#125; return null; &#125;&#125; 然后我们需要在消费者端使用stub来设置1&lt;dubbo:reference interface="com.itcast.gmall.service.UserService" id="userService" stub="gmall.service.impl.UserServiceStub"&gt;&lt;/dubbo:reference&gt; 只有当我们的stub验证通过后，才会执行服务器端的代码(在开发中，我们通常把存根放在接口工程中) Dubbo和SpringBoot整合的三种方式 使用dubbo自动扫描 @Reference（引入服务）,@Service(暴露服务),记得使用@EnableDubbo 使用xml配置，那么我们使用@ImportResource配置xml文件，不需要使用@EnableDubbo 我们使用XXXConfig注册组件的方式，例如 &lt;dubbo:application&gt;&lt;/dubbo:application&gt;,记得使用@EnableDubbo 1234567891011121314import com.alibaba.dubbo.config.ApplicationConfig;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class MyConfig &#123; @Bean public ApplicationConfig applicationConfig()&#123; ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setName("boot-service-consumer"); return applicationConfig; &#125;&#125; 高可用Zookeeper宕机之后是消费者仍可以继续调用生产者的服务，因为他们仍能通过本地缓存通讯我们也可以使用@Reference(url=””)实现dubbo直连 Dubbo的负载均衡Random LoadBalance 基于权重的随机负载均衡机制 dubbo默认负载均衡机制RoundRobin LoadBalance 基于权重的轮询负载均衡机制LeastActive LoadBalance 基于最小活跃数负载均衡机制 我们自定义负载均衡机制12@Reference(loadbalance = "roundrobin")UserService userService; 服务降级我们可以在duubo控制台操作服务的屏蔽或者容错屏蔽：指的是消费者不向生产者发送请求，直接返回空容错：指的是消费者生产者发送请求失败后不报错，然后返回空 Dubbo容错机制dubbo默认的容错机制会切换另一台服务器，当然我们也可以借助springcloud的Hystrix来实现自定义容错机制 首先在服务提供者端引入依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.4.RELEASE&lt;/version&gt;&lt;/dependency&gt; 然后在方法上使用@HystrixCommand注解千万记住开启Hystrix注解模式，在启动类上加上 @EnableHystrix 同样的在消费端，我们也要引入相应的依赖，然后在调用方法上使用@HystrixCommand注解12345678910111213141516@HystrixCommand(fallbackMethod = "errorMethod") public List&lt;UserAddress&gt; initOrder(String userId) &#123; // TODO Auto-generated method stub System.out.println("用户id："+userId); //1、查询用户的收货地址 List&lt;UserAddress&gt; addressList = userService.getUserAddressList(userId); for (UserAddress userAddress : addressList) &#123; System.out.println(userAddress.getUserAddress()); &#125; return addressList; &#125; public List&lt;UserAddress&gt; errorMethod(String userId) &#123; return Arrays.asList(new UserAddress(1,"出错","出错","出错","出错","出错")); &#125; 然后我们需要在启动类上添加 @EnableHystrix dubbo底层原理我建议阅读官方文档]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo和SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo基础]]></title>
    <url>%2F2019%2F01%2F03%2FDubbo%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Dubbo基础现在的网站规模在不断的扩大，常规的垂直应用结构已经无法应对，分布式架构就应运而生 发展演变：dubbo官网的演变图 单一应用架构 所有功能写在一个工程，不利于维护，不能承受高流量访问压力 垂直应用架构 界面和业务逻辑没有实现分离，应用太过于独立，不利于之间交互 分布式服务架构 服务之间采用RPC调用，远程过程调用 流动计算架构 基于访问压力实时管理集群容量，提高集群的利用率 RPC框架： dubbo gRPC（google） Thrift （微软） HSF (阿里) JSF (京东) dubbo学习我们使用dubbo，首先我们进入官网，发现官网推荐我们使用zookeeper作为注册中心所以，我们下载zookeeper,然后我们先在本地调试，步骤如下 首先我们下载好zookeeper,解压到本地，进入config文件夹，修改zoo_sample.cfg为zoo.cfg 我们打开zoo.cfg,找到 dataDir，修改地址，前提是我们已经创建好一个用于存放data的文件夹，修改为 创建好的data文件夹地址 进入bin目录，然后分别先后点击 zkServer.cmd ，zkCli.cmd (注：我们是在window环境下的原因，才点击这两个)启动完成 在dubbo启动成功前提下，我们可以安装启动zookeeper的管理控制台 首先我们去github下载，然后加压 然后进入dubbo-admin\src\main\resources文件夹下，找到application.properties，查看dubbo.registry.address是否正确 然后进入cmd执行mvn-clean,打包得到jar包，java-jar jar包，默认端口7001，然后访问结果，默认用户名和密码都是root dubbo2.6版本以前我们需要zookeeper作为注册中心，我们需要引入zkclientdubbo2.6版本以后我们需要zookeeper作为注册中心，我们需要引入curator 代码基本入门首先我们引入依赖(服务提供者)12345678910111213141516171819202122232425262728293031&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;artifactId&gt;user-service-provider&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;artifactId&gt;gmall-interface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/dubbo --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.6.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.curator/curator-framework --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 服务的消费者提供服务的provider.xml123456789101112131415161718192021&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd"&gt; &lt;!--当前服务的名称--&gt; &lt;dubbo:application name="user-service-provider"&gt;&lt;/dubbo:application&gt; &lt;!--指定注册中心的位置--&gt; &lt;dubbo:registry address="zookeeper://127.0.0.1:2181"&gt;&lt;/dubbo:registry&gt; &lt;!--或者--&gt; &lt;!--&lt;dubbo:registry protocol="zookeeper" address="127.0.0.1:2181"&gt;&lt;/dubbo:registry&gt;--&gt; &lt;!--用dubbo协议在20880端口暴露服务--&gt; &lt;dubbo:protocol name="dubbo" port="20880"&gt;&lt;/dubbo:protocol&gt; &lt;!--声明需要暴露的服务接口--&gt; &lt;!--ref指向服务的真正的实现对象--&gt; &lt;dubbo:service interface="com.itcast.gmall.service.UserService" ref="userServiceImpl"&gt;&lt;/dubbo:service&gt; &lt;bean id="userServiceImpl" class="com.itcast.gmall.service.impl.UserServiceImpl"&gt;&lt;/bean&gt;&lt;/beans&gt; dubbo官方建议我们应该把公共类以及接口放在一个新的工程中 然后运行12345678910public class MainApplication &#123; public static void main(String[] args) throws IOException &#123; ClassPathXmlApplicationContext ioc = new ClassPathXmlApplicationContext("provider.xml"); ioc.start(); System.in.read(); &#125;&#125; 在dubbo管理中心展示 接下来我们完成服务消费者服务消费者的maven依赖和服务提供者的相同然后我们创建consumer.xml1234567891011121314&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;context:component-scan base-package="com.itcast.gmall.service.impl"&gt;&lt;/context:component-scan&gt; &lt;dubbo:application name="order-service-consumer"&gt;&lt;/dubbo:application&gt; &lt;dubbo:registry protocol="zookeeper" address="127.0.0.1:2181"&gt;&lt;/dubbo:registry&gt; &lt;!--声明需要调用的远程服务的接口；生成远程服务代理--&gt; &lt;dubbo:reference interface="com.itcast.gmall.service.UserService" id="userService"&gt;&lt;/dubbo:reference&gt;&lt;/beans&gt; 然后执行结束12345678910public class MainApplication &#123; public static void main(String[] args) throws IOException &#123; ClassPathXmlApplicationContext ioc = new ClassPathXmlApplicationContext("provider.xml"); ioc.start(); System.in.read(); &#125;&#125; 最终dubbo管理中心显示 构建简单的控制中心dubbo-monitor-simple首先我们使用mvn package构建Jar包，然后target中会有一个dubbo-monitor-simple-2.0.0-assembly.tar.gz，然后我们解压它，进入配置文件conf文件下，看看dubbo.properties中配置是否正确，然后进入assembly.bin文件夹后，点击start.sh启动启动后，那么怎么和服务关联在一起呢根据dubbo官网的描述，我们需要使用1&lt;dubbo:monitor protocol="registry"&gt;&lt;/dubbo:monitor&gt; 分别配置服务器端和消费端，然后分别重启，或在监控中心看到]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GIS音乐盒页面]]></title>
    <url>%2F2018%2F12%2F23%2FGIS%E9%9F%B3%E4%B9%90%E7%9B%92%E9%A1%B5%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[GIS音乐盒说明：这个音乐盒网站是我前一段时间做的前后端项目，结果在一个我自己清理文件的时候，不小心删除一个文件夹，下面所有的项目都被我给删除了，当我发现的时候，已经是第二天我准备上线的时候，回收站也已经被我清空了，我很是伤心。昨天我在查找资料的时候，看到了我之前做的前端静态文件，所以我打算拿出来给大家，什么时候用，拿走 注： 页面截屏一个页面截不全，你可以自己下载下来查看 以前测试阶段录的小视频我录了一个测试的小视频，然后转gif,展示出来推荐一个在线wav转gif的网站，很不错，点我去 首页 所有歌手的页面 歌曲详情页（含有评论的回复和再回复） 歌手的页面 所有歌曲的页面 专辑详情页 登录页(自己写了个模态框) 个人主页 总结： 写前端css最浪费时间，我这个页面写了差不多一个星期，包括设计页面的布局 这个后端我已经给删除了，你可以自己加后端功能，建议快速开发springboot 短信我当初使用的是阿里的短信 存储文件我使用的是七牛云，很好用]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端页面</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8——Stream流]]></title>
    <url>%2F2018%2F09%2F15%2FJava8%E2%80%94%E2%80%94Stream%E6%B5%81%2F</url>
    <content type="text"><![CDATA[Java8——Stream流我们先上手个小demo123456789101112import java.util.Arrays;public class DemoStream &#123; public static void main(String[] args) &#123; String[] strList = &#123;"李茂展","董浩","李沫熙","李哲","杨宁宁"&#125;; //接下来我们将使用stream流方式对strList进行操作，返回带 李 ，长度为3的 Arrays.stream(strList).filter((name)-&gt;name.contains("李")) .filter((name)-&gt;name.length()==3) .forEach(name-&gt; System.out.println(name)); &#125;&#125; Stream中集合的处理方案 这张图展示了过滤、映射、跳过、计数等多步操作，这是一个集合元素的处理方案，也就是一种函数模型中间执行过程中集合并不会真正的被处理，而是到最后count的时候才会被执行，这就是函数模型的操作，而之所以这样的得益于Lambda的延迟加载 Stream流获取Stream流获取有两种方式 Collection的有stream()方法获取stream流 1234567891011121314151617181920212223242526import java.util.*;import java.util.stream.Stream;public class DemoStream &#123; public static void main(String[] args) &#123; //list集合获取stream方式 ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); Stream&lt;String&gt; stream1 = list.stream(); //hash获取stream方式 HashSet&lt;String&gt; hashSet = new HashSet&lt;&gt;(); Stream&lt;String&gt; stream2 = hashSet.stream(); //map集合我们可以分别把键值对转换成流对象 HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;(); Set&lt;String&gt; keySet = map.keySet(); Stream&lt;String&gt; stream3 = keySet.stream(); Collection&lt;String&gt; values = map.values(); Stream&lt;String&gt; stream = values.stream(); &#125;&#125; 有一个Java.util.stream有一个静态方法of也可以获得stream流 123456public static void main(String[] args) &#123; //list集合获取stream方式 ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); Stream&lt;ArrayList&lt;String&gt;&gt; stream = Stream.of(list); &#125; Stream方法的学习总结首先分成两类 延迟方法 终结方法 foreach()方法 —— 终结方法遍历之后就不能使用stream流中的其他方法12345678import java.util.stream.Stream;public class ForStream &#123; public static void main(String[] args) &#123; Stream.of("李茂展","李沫熙","杨宁宁").forEach(name-&gt; System.out.println(name)); &#125;&#125; filter()方法 —— 延迟方法执行过滤之后，仍然可以使用stream的其他方法1Stream.of("李茂展","李沫熙","杨宁宁").filter(name-&gt;name.contains("李")).forEach(name-&gt; System.out.println(name)); 类名引用静态方法的使用我们使用Math.abs()来求绝对值首先我们创建一个函数式接口1234@FunctionalInterfacepublic interface AbsFunc &#123; public abstract int myAbs(int num);&#125; 然后我们可以使用lambda表达式来引用Math的静态方法12345678910111213public class DemoStream &#123; public static void getAbs(Integer num,AbsFunc absFunc)&#123; int myAbs = absFunc.myAbs(num); System.out.println(myAbs); &#125; public static void main(String[] args) &#123; getAbs(-10,Math::abs); &#125;&#125; 结构打印出来是 10 同样的使用super引用父类方法的时候，由于在子类中super是存在的，在lambda中我们可以使用super::show来完成调用 同样的使用this的时候，在lambda中我们可以使用this::show来完成调用 同样的使用new的时候，在lambda中我们可以使用Person::new来完成调用]]></content>
      <categories>
        <category>Java8</category>
      </categories>
      <tags>
        <tag>Stream流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8——Lambda表达式]]></title>
    <url>%2F2018%2F09%2F12%2FJava8%E2%80%94%E2%80%94Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Java8——Lambda表达式语法糖指的是使用更方便，但原理不变的代码语法 lambda表达式java8有一个词汇不得不提，就是 函数式接口函数式接口：有且只有一个抽象方法的接口，我们可以在接口上标注@FunctionalInterface，表示是一个函数式接口，主要作为参数或者返回值使用1234567package cn.itcast.helloworld.java8;@FunctionalInterfacepublic interface MyFunc &#123; public abstract void save();&#125; lambda表达式的重要特征: 可选类型声明：不需要声明参数类型，编译器可以统一识别参数值。 可选的参数圆括号：一个参数无需定义圆括号，但多个参数需要定义圆括号。 可选的大括号：如果主体包含了一个语句，就不需要使用大括号。 可选的返回关键字：如果主体只有一个表达式返回值则编译器会自动返回值，大括号需要指定明表达式返回了一个数值。 注：借鉴菜鸟教程，感觉总结特别好 接下来展示一个小demo12345678910111213141516171819202122public static void save(MyFunc myFunc)&#123; myFunc.save(); &#125; public static void main(String[] args) &#123; //传递接口的匿名内部类 save(new MyFunc() &#123; @Override public void save() &#123; System.out.println("执行完成"); &#125; &#125;); //由于方法的参数是一个函数式接口，所以可以使用lambda表达式 save(()-&gt;&#123; System.out.println("lambda表达式的使用"); &#125;); //由于函数式接口的方法没有参数，而且只有一条执行语句 save(()-&gt;System.out.println("lambda表达式的使用")); &#125; lambda表达式是延迟执行，可以对代码执行结果不急用用lambda语法，有助于提高性能lambda执行的前提是必须有函数式接口我们做了一个demo最适合解释lambda表达式的用法123456789101112131415161718192021/** 我们做了这么一个案例：* 当level的值为1的时候，打印日志,* 其他都不打印，为了防止我们苦费心思拿到日志之后，结果level不为 1，就损耗了性能* 所以我们使用有延迟加载作用的lambda** */public class Demo &#123; public static void save(int level,MyFunc myFunc)&#123; if(level == 1) myFunc.printLog(); &#125; //只有level的数字是1的时候，lambda表达式才会执行 public static void main(String[] args) &#123; save(1,()-&gt; System.out.println("这是日志")); &#125;&#125; Java中也给我们提供弄了很多函数式接口Comparator比较型接口在java中，Comparator接口是个函数式接口，内部只有一个抽象方法，所以按照lambda表达式规则，可以这样写12345678910111213141516171819202122public class MyCompare &#123; public static Comparator&lt;String&gt; myComparator()&#123; //匿名内部类// return new Comparator&lt;String&gt;() &#123;// @Override// public int compare(String o1, String o2) &#123;// return o2.length()-o1.length();// &#125;// &#125;; //采用Lambda表达式 return (o1,o2)-&gt;o2.length()-o1.length(); &#125; public static void main(String[] args) &#123; String[] arrList = &#123;"aaaaa","b","cccc","dddd"&#125;; System.out.println("原先顺序："+Arrays.toString(arrList)); Arrays.sort(arrList,myComparator()); System.out.println("现在顺序："+Arrays.toString(arrList)); &#125;&#125; 生产型接口指的是接口的泛型是什么类型，那么接口最后的返回值就是什么类型 Supplier生产型接口12345678910111213import java.util.function.Supplier;public class ProduceInterface &#123; public static String myPrint(Supplier&lt;String&gt; supplier)&#123; return supplier.get(); &#125; public static void main(String[] args) &#123; String str = myPrint(()-&gt;"李茂展"); System.out.println(str); &#125;&#125; Consumer消费型接口消费型接口，指的是泛型执行什么类型，就可以消费什么类型的数据12345678910111213141516import java.util.function.Consumer;public class ConsumerInterface &#123; public static void myConsumer(String name, Consumer&lt;String&gt; consumer)&#123; consumer.accept(name); &#125; public static void main(String[] args) &#123; //我们实现翻转输出 myConsumer("李茂展",(name)-&gt;&#123; String nameReverse = new StringBuffer(name).reverse().toString(); System.out.println(nameReverse); &#125;); &#125;&#125; Consumer中有一个默认方法andThen,我们可以这样使用123456789101112131415import java.util.function.Consumer;public class ConsumerInterface &#123; public static void myConsumer(String name, Consumer&lt;String&gt; consumer1, Consumer&lt;String&gt; consumer2)&#123; //谁写在前面谁先消费 consumer1.andThen(consumer2).accept(name); &#125; public static void main(String[] args) &#123; //我们实现先大写后小写输出 myConsumer("Tom",(name)-&gt; System.out.println(name.toUpperCase()),(name)-&gt; System.out.println(name.toLowerCase())); &#125;&#125; Predicate判断型接口predicate是用于判断的函数式接口，内部有一个test抽象方法，返回值是bool类型1234567891011121314import java.util.function.Predicate;public class PredicateInterface &#123; public static boolean myPredicate(String str, Predicate&lt;String&gt; predicate)&#123; return predicate.test(str); &#125; public static void main(String[] args) &#123; String str = "abcdefg"; boolean bool = myPredicate(str, (str1) -&gt; str1.length() &gt; 5); System.out.println(bool); &#125;&#125; predicate有三个默认方法： and: 表示条件同时满足 123456789101112131415import java.util.function.Predicate;public class PredicateInterface &#123; public static boolean myPredicate(String str, Predicate&lt;String&gt; predicate1,Predicate&lt;String&gt; predicate2)&#123; return predicate1.and(predicate2).test(str); &#125; public static void main(String[] args) &#123; String str = "abcdefg"; //判断长度大于5并且包含f字母，结果输出为true boolean bool = myPredicate(str, (str1) -&gt; str1.length() &gt; 5,(str1) -&gt; str1.contains("f")); System.out.println(bool); &#125;&#125; or: 表示条件只需要满足一个就可以返回true和上面的代码差不多相同，区别就是把上面的and替换成or,return predicate1.or(predicate2).test(str); negate： 表示取反 123456789101112131415import java.util.function.Predicate;public class PredicateInterface &#123; public static boolean myPredicate(String str, Predicate&lt;String&gt; predicate)&#123; return predicate.negate().test(str); &#125; public static void main(String[] args) &#123; String str = "abcdefg"; //判断长度大于5,然后结果应该是true，由于加上了negate,所以结果是false boolean bool = myPredicate(str, (str1) -&gt; str1.length() &gt; 5); System.out.println(bool); &#125;&#125; Function转换型接口Function中最主要的抽象方法是apply(T,t)，T表示转换前的类型，t表示转换后的类型123456789101112131415import java.util.function.Function;public class MyFunction &#123; public static void myFunc(String str, Function&lt;String,Integer&gt; function)&#123; Integer val = function.apply(str); System.out.println(val); &#125; public static void main(String[] args) &#123; //使用lambda表达式把字符串 "123"输出为数字 123 myFunc("123",(str)-&gt;Integer.parseInt(str)); &#125;&#125; Function有个默认方法andThen12345678910111213public class MyFunction &#123; public static void myFunc(String str, Function&lt;String,Integer&gt; function1,Function&lt;Integer,String&gt; function2)&#123; String str_val = function1.andThen(function2).apply(str); System.out.println(str_val); &#125; public static void main(String[] args) &#123; //使用lambda表达式把字符串转成数字然后再加上10再转换为字符串 myFunc("123",(str)-&gt;Integer.parseInt(str),(val)-&gt;String.valueOf(val +=10)); &#125;&#125;]]></content>
      <categories>
        <category>Java8</category>
      </categories>
      <tags>
        <tag>Lambda表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python flask做的二手交易商城]]></title>
    <url>%2F2018%2F08%2F09%2F%E4%BA%8C%E6%89%8B%E4%BA%A4%E6%98%93%E5%95%86%E5%9F%8E%2F</url>
    <content type="text"><![CDATA[看了几天python，想着做一个东西出来，就做出了一个小型二手 商城练练手1.解释以下的二手 商城展示，商品照片为了好看，从京东上爬下来的，有一些动态效果，我只制作了一张，在线转换成gif的话由于录制屏幕视频文件太大不太容易转格式 2.用户在没有登录的时候点击买东西，会弹出首先登录，同时也可以选择注册 3.卖东西的界面使用了可以拖拽的方式让用户上传商品更方便 4.用户添加商品到购物车的界面，由于二手商品数量每件比较少，所以限定用户在提交到购物车20分钟内完成结算，否则商品会从购物车内清除 5.加入购物车之后，用户可以去个人中心查看(顺便展示一下更换照片的界面) 6. 这个时候商品已经在你的购物车内，你在个人中心也可以看到购物车并且去结算 7. 去结算 8. 如果用户没有完成结算的话，会在订单中，同样也有时间限制，每件商品都有根据当初进入订单那个时间算起至三十分钟后自动从订单中取消 9. 商品列表页面 10. 在二手商城中难免有些买家觉着卖家定价不合适，会跟商家交谈，所以我也做了一个商品议价的模块，可以实现回复再回复的问题 11.我的总结： 上面只是简单的页面展示，具体代码在github上，这个项目中有很多的知识点 希望大家又遇到同样的功能不知道怎么实现的时候，我的代码能够帮到你 调bug是一件培养心态的一件事，做web也有二年左右了，感觉从代码中培养了好性格 12.github地址是:https://github.com/lmx110522/nyist_python_secondmall.git上面的页面可能不太好看，我是一个写后端代码的小码农却喜欢做前台页面，我去努力进步的！，希望你的支持，谢谢花费时间看我的博客，万分感谢！]]></content>
      <categories>
        <category>python flask</category>
      </categories>
      <tags>
        <tag>jQuery</tag>
        <tag>商城</tag>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Druid数据源]]></title>
    <url>%2F2018%2F06%2F01%2FDruid%E6%95%B0%E6%8D%AE%E6%BA%90%2F</url>
    <content type="text"><![CDATA[Druid 数据源Druid能够提供强大的监控和扩展功能。隶属于阿里巴巴旗下的连接池我们使用druid和SpingBoot结合 首先我们引入druid 的maven依赖 123456&lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt;&lt;/dependency&gt; yml配置如下1234567spring: datasource: username: root password: root url: jdbc:mysql://192.168.13.131:3306/springboot01 driver-class-name: com.mysql.jdbc.Driver type: com.alibaba.druid.pool.DruidDataSource 我们仍然可以使用druid其他的yml配置1234567891011121314151617# 数据源其他配置 initialSize: 5 minIdle: 5 maxActive: 20 maxWait: 60000 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: SELECT 1 FROM DUAL testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙# filters: stat,wall,log4j maxPoolPreparedStatementPerConnectionSize: 20 useGlobalDataSourceStat: true connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500 然后由于很多属性值druid无法映射，我们可以使用yml属性绑定的方式12345@ConfigurationProperties(prefix = "spring.datasource") @Bean public DataSource druid()&#123; return new DruidDataSource(); &#125; 然后我们需要配置druid的后台管理servlet以及监控的filter1234567891011121314151617181920212223//配置管理后台的servlet @Bean public ServletRegistrationBean statViewServlet()&#123; ServletRegistrationBean bean = new ServletRegistrationBean(new StatViewServlet(), "/druid/*"); Map&lt;String,String&gt; map = new HashMap&lt;&gt;(); map.put("loginUsername","admin"); map.put("loginPassword","admin"); map.put("allow","");//默认允许所有访问 map.put("deny","192.168.13.132");//禁止192.168.13.132访问 bean.setInitParameters(map);//初始化参数 return bean; &#125; //配置一个web监控的filter @Bean public FilterRegistrationBean webStatFilter()&#123; FilterRegistrationBean&lt;Filter&gt; bean = new FilterRegistrationBean&lt;&gt;(); bean.setFilter(new WebStatFilter()); Map&lt;String,String&gt; map = new HashMap&lt;&gt;(); map.put("exclusions","*.js,*.css,/druid/*"); //不拦截这些 bean.setInitParameters(map); //初始化参数 bean.setUrlPatterns(Arrays.asList("/*")); //表示拦截所有请求 return bean; &#125; 然后输入localhost/druid就可运行成功]]></content>
      <categories>
        <category>Druid</category>
      </categories>
      <tags>
        <tag>SpringBoot druid数据源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot的难点总结]]></title>
    <url>%2F2018%2F05%2F14%2FSpringBoot%E7%9A%84%E9%9A%BE%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[SpringBoot的难点总结WebJars:以jar包的方式引入例如jquery,我们可以这样引入12345&lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;jquery&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt;&lt;/dependency&gt; 然后在目录结构是： html中引入 /webjars/jquery/3.0.0/jquery.js就可以加载到 分析 WebMvcAutoConfiguration“/**”访问当前项目的任何资源(静态资源文件夹)12345"classpath:/META‐INF/resources/","classpath:/resources/","classpath:/static/","classpath:/public/""/"：当前项目的根路径 欢迎页； 静态资源文件夹下的所有index.html页面；被”/**”映射访问 localhost/ 会首先找Index.html 所有的 **/favicon.ico 都是在静态资源文件下找；SpringBoot自定义web配置文件以及拦截器springboot1.x版本的时候我们会继承WebMvcConfigurerAdapter,但是在2.x版本以后被标注@Deprecated，表示这个方法再慢慢被其他用法给替代所以我们使用实现WebMvcConfigurer,然后重写其方法12345678@Configurationpublic class MyConfig implements WebMvcConfigurer&#123; public void addViewControllers(ViewControllerRegistry registry) &#123; //主要处理一些不需要直接操作，只需要映射地址的 registry.addViewController("/index").setViewName("index"); &#125;&#125; 当然我们也可以这样使用123456789101112@Configurationpublic class MyConfig implements WebMvcConfigurer&#123; public WebMvcConfigurer webMvcConfigurer()&#123; return new WebMvcConfigurer() &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController("/test").setViewName("test"); &#125; &#125;; &#125;&#125; SpringBoot的拦截器我们往往在操作前要校验权限，所以拦截器有必要使用创建一个类，实现HandlerInterceptor接口123456789101112131415161718@Componentpublic class LoginInterceptor implements HandlerInterceptor &#123; public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; String username = (String) request.getSession().getAttribute("username"); if(StringUtils.isEmpty(username))&#123; username = request.getParameter("username"); if(!StringUtils.isEmpty(username))&#123; request.getSession().setAttribute("username",username); &#125; //没有输入username并且没有登录转发给登录页面 request.getRequestDispatcher("/index").forward(request,response); return false; &#125; return true; &#125;&#125; 我使用的是把拦截器注册到ioc容器中，这样防止以后我在拦截器中注入其他组件不能使用的问题12345678910111213141516171819202122232425262728@Configurationpublic class MyConfig implements WebMvcConfigurer&#123; @Autowired private LoginInterceptor loginInterceptor; public void addViewControllers(ViewControllerRegistry registry) &#123; //主要处理一些不需要直接操作，只需要映射地址的 registry.addViewController("/index").setViewName("index"); &#125; public WebMvcConfigurer webMvcConfigurer()&#123; return new WebMvcConfigurer() &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController("/test").setViewName("test"); &#125; // 按住ctrl+O // springboot 1.x版本静态资源默认不拦截，但是2.x以后会拦截静态资源 @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(loginInterceptor).addPathPatterns("/**"). excludePathPatterns("/index","/login","/"); &#125; &#125;; &#125;&#125; 我使用的12@Autowired private LoginInterceptor loginInterceptor; 注意： 加载ioc容器中的拦截组件，然后registry.addInterceptor(loginInterceptor)加载，而不是使用 registry.addInterceptor(new loginInterceptor())方式，这种情况时，自定义的interceptor中不能注入其他内容，比 如redis或者其他service，如果要注入，必须使用上面这种方法 SpringBoot错误处理机制查看源码 ErrorMvcAutoConfiguration类的使用当访问后出现4XX或者5XX的错误的时候，会转发/error请求，然后查看静态文件夹有没有error文件夹，如果没有，根据请求的设备不同，会有不同的处理结果(默认错误页面)检查设备是PC会返回html,其他设备返回json格式的数据 如何定制错误呢 有模板引擎的情况下；error/状态码; 【将错误页面命名为 错误状态码.html 放在模板引擎文件夹里面的error文件夹下】，发生此状态码的错误就会来到 对应的页面；我们可以使用4xx和5xx作为错误页面的文件名来匹配这种类型的所有错误，精确优先（优先寻找精确的状态码.html）； 页面能获取的信息； timestamp：时间戳 status：状态码 error：错误提示 exception：异常对象 message：异常消息 errors：JSR303数据校验的错误都在这里 没有模板引擎（模板引擎找不到这个错误页面），静态资源文件夹下找； 以上都没有错误页面，就是默认来到SpringBoot默认的错误提示页面； 定义错误页面1234567891011121314//出现异常会进入这个类中的方法@ControllerAdvicepublic class MyException &#123; @ExceptionHandler(CustomException.class) public String handleException(Exception e)&#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put("code","500"); map.put("message",e.getMessage()); return "forward:/error"; &#125;&#125; 但是上面这一种不具有适配性，所以我们可以这样做123456789public class MyErrorAttributes extends DefaultErrorAttributes &#123; @Override public Map&lt;String, Object&gt; getErrorAttributes(WebRequest webRequest, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; map = super.getErrorAttributes(webRequest, includeStackTrace); map.put("company","nyist"); return map; &#125;&#125; SpringBoot嵌入式Servlet容器优点： 简单、便携缺点： 默认不支持JSP，优化定制比较复杂我们可以外置的Servlet容器，然后我们可以这样做 创建成一个war项目 将嵌入式的tomcat设置成provided 必须编写一个类 12345678public class ServletInitializer extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; return application.sources(TomcatDemoApplication.class); &#125;&#125; 启动就可以使用了 我们也要配置静态资源的访问12spring.mvc.view.prefix=/WEB-INF/spring.mvc.view.suffix=.jsp]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>SpringBoot难点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[南阳理工下载中心]]></title>
    <url>%2F2018%2F04%2F09%2F%E5%8D%97%E9%98%B3%E7%90%86%E5%B7%A5%E4%B8%8B%E8%BD%BD%E4%B8%AD%E5%BF%83%2F</url>
    <content type="text"><![CDATA[springboot实现使用ftp实现下载由于前后台都是我本人写的，加上就四五天的时间，所以，有点瑕疵！给我评论哟springboot特点有以下 1、使编码变得简单2、使配置变得简单3、使部署变得简单4、使监控变得简单由于时间比较紧张，有些功能或许不太完善，后期回去完善，谢谢您的查看! 里面大致功能 阿里验证码 springboot框架下的RabbitMq解决同时注册削锋的问题 springboot使用redis以及session实现避免多用户造成给数据库压力 网站多处使用ajax异步技术实现异步加载数据 sppringdatajpa的使用，多条件共同作用下的查询结果异显示在页面 本站本来要使用socket实现管理员消息推送，但是这个功能和上个spingboot模拟QQ相似，所以就没写 希望它对您有帮助 先上截图 1 首页 2 全部下载，这个有点含金量，多条件同时传递筛选，然后异步显示 3 登录，使用了阿里的手机验证码登录，以及jquery实现的滑块验证 4. 上传页面，实现了图片在线预览，以及自动识别格式 5. 更换头像少不了的功能 6.下载项详细页，里面包含评论，还有同类型精准匹配推荐 7. 下载须知，这个样式有必要展示一下，挺好看的 8. 管理员后台登录 9. 管理员主界面， 10. 审核界面不一一介绍了，希望你如果真的想了解这些功能，下载下来，看看具体功能实现步骤，上面的网站照片主要是让你了解一下网站的大致功能 以及如何显示，具体代码请查看github网站，如果喜欢，给个小星星 ！ github地址： https://github.com/lmx110522/download-nyist.git **]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>jQuery</tag>
        <tag>FTP</tag>
        <tag>redis</tag>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker学习]]></title>
    <url>%2F2018%2F03%2F22%2FDocker%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Docker学习docker是一个开源的应用容器引擎，基于GO语言并遵循Apache2.0协议开源Docker支持将软件编译成一个镜像，然后在镜像中做好各个软件的配置，将镜像发布出去，其他使用者就可以直接使用这个镜像docker安装需要centos内核高于3.10（uname -r 查看内核版本） 核心概念docker主机： 安装了docker程序的机器docker客户端(Client)：连接docker主机进行操作；docker仓库(Registry)：用来保存各种打包好的软件镜像；docker镜像(Images)：软件打包好的镜像；放在docker仓库中；docker容器(Container)：镜像启动后的实例称为一个容器；容器是独立运行的一个或一组应用 使用docker的步骤： 安装好docker程序 yum install docker 启动docker程序 systemctl start docker 去docker容器查找你所需要的镜像 docker search 镜像 下载对应的镜像 docker pull 镜像::版本 查看下载好的镜像 docker images 安装对应的镜像 docker run 查看安装好的镜像 docker ps -a 命令补充: 查看在运行的镜像: docker ps 删除容器: docker rm 容器id 关闭容器: docker stop 容器id 查看启动日志: docker logs 容器id 删除镜像： dokcer rmi 容器id MYSQL安装案例 mysql docker run --name mysql -e MYSQL_ROOT_PASSWORD=123456 -p 3306:3306 -d mysql]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker基础知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot实现模拟QQ的实现(超具体)]]></title>
    <url>%2F2018%2F02%2F08%2Fspringboot%E5%AE%9E%E7%8E%B0%E6%A8%A1%E6%8B%9FQQ%E7%9A%84%E5%AE%9E%E7%8E%B0(%E8%B6%85%E5%85%B7%E4%BD%93)%2F</url>
    <content type="text"><![CDATA[springboot实现QQ在线聊天，大部分功能已经实现！ 如果需要的话，去我的github空间download,有不足，希望大家指出~ 1.登录页面 2.先来看看主界面是什么样子 3.然后我们再看看聊天界面是什么样的 4.添加好友的时候什么样子呢! 5.对方加你好友的时候，你的接受好友申请的界面 6.你点击同意之后，你可以选择好友在哪个好友分组，当然你也可以添加分组 7.基本的功能都已经实现主要难点有以下 数据库如何保存聊天信息，如果频繁操作数据库，会让网页每次访问压力很大，不利于体验效果 作为一个后端人员，做网页效果难度很大，还好我闲暇时间都会去看看前端，这个前后端完全来自我一个人四天的努力，所以难免有点地方不足，请大家给我留言 逻辑比较清楚，但是实现起来比较麻烦！变量传来传去，丢参数很正常，但是，现在程序一切运行正常，大家可以从下载下来，在idea运行，有一个问题，在chrome内核的浏览器上支持度比较好，在其他浏览器的滚动条有点问题！ 注册功能我没有写，我下一条博客准备发我的用python框架flask写的小型商城，那个里面有邮箱注册，到时候大家可以从哪里瞅瞅 希望你的小星星点赞我的github，谢谢 我的github站点：https://github.com/lmx110522/nyist_chat_project.git 谢谢大家花时间看我的博客，万分感谢~~~]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>socket</tag>
        <tag>jQuery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot的配置]]></title>
    <url>%2F2018%2F01%2F15%2FSpringBoot%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[配置文件加载位置springboot 启动会扫描以下位置的application.properties或者application.yml文件作为Spring boot的默认配置文件 file:./config/ file:./ classpath:/config/ classpath:/ 加载规则如下： 优先级由高到底，高优先级的配置会覆盖低优先级的配置； SpringBoot会从这四个位置全部加载主配置文件；互补配置； 我们还可以通过spring.config.location来改变默认的配置文件位置 java -jar test.jar –spring.config.location=D:/application.yml 项目打包好以后，我们可以使用命令行参数的形式，启动项目的时候来指定配置文件的新位置；指定配置文件和默认加载的这些配置文件共同起作用形成互补配置； 外部配置加载顺序SpringBoot也可以从以下位置加载配置； 优先级从高到低；高优先级的配置覆盖低优先级的配置，所有的配置会形成互补配置1.命令行参数所有的配置都可以在命令行上进行指定java -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar –server.port=8087 –server.context-path=/abc多个配置用空格分开； 配置项=值2.来自java:comp/env的JNDI属性3.Java系统属性（System.getProperties()）4.操作系统环境变量5.RandomValuePropertySource配置的random.*属性值由jar包外向jar包内进行寻找；优先加载带profile6.jar包外部的application-{profile}.properties或application.yml(带spring.profile)配置文件7.jar包内部的application-{profile}.properties或application.yml(带spring.profile)配置文件再来加载不带profile8.jar包外部的application.properties或application.yml(不带spring.profile)配置文件9.jar包内部的application.properties或application.yml(不带spring.profile)配置文件10.@Configuration注解类上的@PropertySource11.通过SpringApplication.setDefaultProperties指定的默认属性]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>springboot知识点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring琐碎知识汇总]]></title>
    <url>%2F2018%2F01%2F10%2FSpring%E7%90%90%E7%A2%8E%E7%9F%A5%E8%AF%86%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[SpringBoot学习总结SpringBoot简化spring开发，约定大于配置 优点： 快速创建独立运行的Spring项目以及与主流框架集成 使用嵌入式的Servlet容器,应用无需打成WAR包 starters自动依赖与版本控制 大量的自动配置,简化开发,也可修改默认值 无需配置XML ,无代码生成,开箱即用 准生产环境的运行时应用监控 与云计算的天然集成 使用springboot也跟目前大时代背景有关，现在企业级应用如此庞大，集群，微服务，SOA词汇渐渐进入我们的视野提到了微服务，我们就要看看马丁大叔的个人主页,马丁大叔14年提到了微服务，提倡服务之间应使用restful风格，后来我们将要学习的springcloud采用的就是基于restful风格的架构方案 开发springboot最好用的是IDEA，这是我的百度网盘链接，拿去用吧IDEA工具下载 配置文件SpringBoot使用一个全局的配置文件，配置文件名是固定的 application.yml application.properties YAML是”YAML Ain’t a Markup Language”（YAML不是一种置标语言）的递归缩写yml是一种标记语言，yml以数据为中心，相比于xml,xml花费太多的时间在标签上，效率不高 yml语法：1、基本语法k:(空格)v：表示一对键值对（空格必须有）； 以空格的缩进来控制层级关系；只要是左对齐的一列数据，都是同一个层级的123server: port: 80 path: /test 2、值的写法字面量 字符串默认不用加上单引号或者双引号 双引号不会转义特殊字符，例如：”spring \n boot” 输出则是 “spring”换行“boot” 单引号会转义特殊字符，例如：”spring \n boot” 输出则是 “spring \n boot” 对象 通常下面写法：123dog: name: 阿黄 age: 12 也可以下面这种行内写法1dog: &#123;name: 阿黄,age: 12&#125; 数组1234pets: - dog - cat - pig 它也有一个行内写法1pets: [dog,cat,pig] yml语法还支持占位符 随机数 age: ${random.uuid} 使用上面定义好的 1234dog: name: 阿黄 age: $&#123;random.uuid&#125; nickname: 小$&#123;dog.name:狗狗&#125; 狗狗表示是如果加载不到dog.name，狗狗就是就是默认值 注：在yml中，last-name和lastName是表示的一样 从yml得到数据绑定给pojoyml数据123person: username: 旺财 password: 123 @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定，prefix=”person”配置文件中哪个下面的所有属性进行一一映射12345678910111213141516171819202122232425262728293031323334353637383940@Component @ConfigurationProperties(prefix = "person") public class Person &#123; private String username; private String password; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125;&#125; 然后我们使用springboot的测试功能```java@RunWith(SpringRunner.class)@SpringBootTestpublic class HelloworldApplicationTests &#123; @Autowired private Person person; @Test public void contextLoads() &#123; System.out.println(person.getUsername()); &#125;&#125; 成功打印出： 旺财，成功绑定 这个用法是springboot中很多底层源码都会用的到,源码摘取： redis属性和yml数据绑定，就是用的这个方法 ConfigurationProperties和Value的对比 @ConfigurationPropertie @Value 功能 批量注入配置文件中的属性 一个个指定 松散绑定（松散语法） 支持 不支持 SpEL 不支持 支持 JSR303数据校验 支持 不支持 复杂类型封 支持 不支持 在注解ConfigurationProperties的情况下在类上添加@Validated实现JSR303校验 @PropertySource和@ImportSource区别由于我们使用ConfigurationProperties默认会从application.properties/yml中获取数据，所以，如果我们自己写了一个properties，我们则需要@PropertySource1234567891011121314151617181920212223242526272829303132333435package cn.itcast.helloworld.pojo;import org.hibernate.validator.constraints.Length;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.PropertySource;import org.springframework.stereotype.Component;import org.springframework.validation.annotation.Validated;@Component@PropertySource(value = &#123;"classpath:person.properties"&#125;)@ConfigurationProperties(prefix = "person")@Validatedpublic class Person &#123; @Length(min = 8,max = 16) private String username; private String password; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125;&#125; @ImportSource：导入spring的配置文件，让配置文件生效1@ImportResource(locations = &#123;"classpath:beans.xml"&#125;) profile环境配置，在spring注解的时候有@Profile,和在学习注解版的时候作用是相同的，有两种方法可以根据环境不同来实现配置文件不同 application-dev.properties、application-prod.properties的方式 分区文档快，yml文件可以分区，如下，注意看红线 重要的知识点来了 如何激活环境 运行时配置环境 –spring.profiles.active=dev 项目打包好，我们在命令行可以使用 java jar test.jar –spring.profiles.active=dev 虚拟机参数 -Dspring.profiles.active=dev]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>yml</tag>
        <tag>springboot入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring注解驱动开发（二）]]></title>
    <url>%2F2017%2F12%2F18%2Fspring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[spring注解驱动开发（二）@Import的使用目前我们知道的往ioc容器中注册组件的方式有两种 在类上标注@component、@Service、@Controller、@Repository，然后通过@ComponentScan的方式扫描到ioc容器中 在配置类中需要注册到ioc容器的组件使用@Bean主机的方式出了上面的方法，那么我们再介绍几种方法 @Import可以实现快速注册组件的目的@Import({MyImportSelector.class})然而在ioc中的id是该类的全类名 FactoryBean接口可以实现注册组件的目的我们可以创建一个类实现FactoryBean接口1234567891011121314151617181920public class PersonFactoryBean implements FactoryBean&lt;Person&gt;&#123; //返回对象会加载到ioc容器中 public Person getObject() throws Exception &#123; // TODO Auto-generated method stub System.out.println("成功调用"); return new Person(); &#125; //指定类型 public Class&lt;?&gt; getObjectType() &#123; // TODO Auto-generated method stub return Person.class; &#125; //指定是否是单例模式 public boolean isSingleton() &#123; // TODO Auto-generated method stub return true; &#125;&#125; 然后我们可以测试12345AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MyConfig.class); Object bean = context.getBean("personFactoryBean"); System.out.println(bean.getClass());//打印出来的是class cn.itcast.pojo.Person Object bean1 = context.getBean("&amp;personFactoryBean"); System.out.println(bean1.getClass());//打印出来的是class cn.itcast.config.PersonFactoryBean 注：上面在获取bean的时候，有一个符号&amp;，通过加上这个符号可以获得注册组件自己 ImportSelector接口可以实现注册组件的目的我们把要注册到ioc容器中组件的全类名放在返回的数组中1234567public class MyImportSelector implements ImportSelector&#123; public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123; return new String[] &#123;"cn.itcast.pojo.Role","cn.itcast.pojo.Dog"&#125;; &#125;&#125; 记得把MyImportSelector注册到ioc容器中，这里我们采用快速注入的方式@Import({MyImportSelector.class})我们可以一次注册多个组件到容器中 ImportBeanDefinitionRegistrar接口可以实现注册组件的目的123456789101112131415public class MyImportBeanDefinitionRegister implements ImportBeanDefinitionRegistrar&#123; public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; //首先判断ioc中是否有role这个组件，如果有的话，就注册bean boolean flag = registry.containsBeanDefinition("cn.itcast.pojo.Role"); if(flag) &#123; //注册person组件 RootBeanDefinition beanDefinition = new RootBeanDefinition(Person.class); registry.registerBeanDefinition("person",beanDefinition); &#125; &#125;&#125; @Bean中的initMethod、destroyMethod原先我们使用xml配置的方式表示为:1234567891011121314151617181920public class Role &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public void init() &#123; System.out.println("容器初始化"); &#125; public void destory() &#123; System.out.println("容器被销毁"); &#125;&#125; 123&lt;bean id="role" class="cn.itcast.pojo.Role" init-method="init" destroy-method="destory"&gt; &lt;property name="name" value="bean生命周期"&gt;&lt;/property&gt;&lt;/bean&gt; 在@Bean中有两个属性1234@Bean(initMethod="init",destroyMethod="destory") public Role role() &#123; return new Role(); &#125; 注：在销毁的时候，单实例容器会销毁，但是多实例，容器不负责销毁，所以在多实例下销毁方法不调用 在初始化的时候，单实例容器运行时，会调用初始化（init）方法，多实例在调用对象的时候创建(执行init的方法) @Value、@PropertySource的使用以前我们使用下面方式给组件赋值123&lt;bean id="dog" class="cn.itcast.pojo.Dog"&gt; &lt;property name="name" value="旺财"&gt;&lt;/property&gt; &lt;/bean&gt; 在注解版中我们可以使用1234@Value("旺财")private String name;@Value("#&#123;2*3&#125;")private String nickName; 当然这种硬编码不太好，所以我们可以加载配置文件中的值，那么引入@PropertySource实现引入配置文件然后使用属性占位符的方式得到12@Value("$&#123;dog.name&#125;")private String name; 当然你也可以使用SPEL表达式得到。12 @Value("#&#123;systemProperties['dog.name']&#125;")private String name; @Autowired、@Qualifier、@Primary注解的使用@Autowired用作组件的自动装配，装配的规则是 首先按照组件的类型从ioc容器中查找，查找到装配完成 如果遇到多个同类型的组件，那么会使用属性名作为查找ioc容器组件的id 如果没有查到到，会报错！但是我们又不想让它报错，那么我们可以使用@Autowired(required=false)当然我们也可以自己指定需要查找组件的id,用@Qualifier(&quot;indexService1&quot;),这样我们就可以去ioc容器中查找id是indexService1的组件同时呢，spring也给我们提供了@Primary，意思是要找此类型的组件，首选此组件12345@Primary @Bean public IndexService indexService1() &#123; return new IndexService(); &#125; 注：@Primary注解使用的时候，就不要使用@Qualifier注解了 spring也支持@Resource(JSR250)和@Inject(JSR330),这些都是java规范@Resource默认按照属性的名称作为组件的id去ioc容器查找，当然我们也可以使用@Resource（name=’indexDao1’）设置@Inject需要导入javax.inject的包，在使用上和@Autowired一样@Autowired可以使用在构造器，方法，属性上面、参数位置，如果组件只有一个有参构造器，参数位置的@Autowired可以省略，还有@Bean中的参数，也不用写@Autowired，都可以从容器中自动装配 @Profile注解的使用Spring为我们提供的可以根据当前环境，动态的激活和切换一系列组件的功能默认的profile是default我们在某个组件上面加上@Profile(&#39;test&#39;),一旦加上之后，就是当环境激活的时候，对应的bean才可以注册到容器中那么如何激活呢 在运行到时候，设置命令行参数的方式 -Dspring.profiles.active=test 可以借助applicationContext方式激活环境，例如：1234567AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext();//设置需要激活的环境context.getEnvironment().setActiveProfiles("test","dev");//注册主配置类context.register(MyConfig.class);//启动刷新容器context.refresh();]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring注解驱动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring注解驱动开发（一）]]></title>
    <url>%2F2017%2F12%2F15%2Fspring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[spring注解驱动开发（一）初步介绍 spring注解驱动开发随着springboot这个简洁化开发，约定大于配置的大环境下，spring注解版知识点使用的也开始越来越多，所以我已经学习了基础springboot之后果断停止，开始学习spring注解驱动开发,下面是我总结的一些注解知识,这个页面会一直更新，用于以后的查阅 1、@Configurable注解以及@Bean的使用Configurable表示这个一个配置类，代替原先xml配置之前我们用xml做DI(依赖注入)，现在我们可以通过class的方式来声明一个配置类 xml配置1234567891011&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.0.xsd"&gt; &lt;bean id="person" class="cn.itcast.pojo.Person"&gt; &lt;property name="username" value="lmx"&gt;&lt;/property&gt; &lt;property name="password" value="123"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; 现在可以使用123456789101112131415package cn.itcast.config;import org.springframework.beans.factory.annotation.Configurable;import org.springframework.context.annotation.Bean;import cn.itcast.pojo.Person;@Configurablepublic class MyConfig &#123; @Bean(name="lmx") public Person person() &#123; return new Person("lmz","456"); &#125;&#125; 上面的bean代替旧的即&lt;bean/&gt;可以实现向容器注册组件，其中bean的name属性指的是注册组件在容器中的ID，默认是方法名作为组件的ID 然后通过下面的测试，果然简单有效，赞！1234567891011121314151617181920212223242526package cn.itcast.test;import org.springframework.context.annotation.AnnotationConfigApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import cn.itcast.config.MyConfig;import cn.itcast.pojo.Person;public class MainTest &#123; public static void main(String[] args) &#123;// ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext("beans.xml");// Person person = (Person)applicationContext.getBean("person");// System.out.println("姓名："+person.getUsername());// System.out.println("密码："+person.getPassword()); AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MyConfig.class); Person bean = context.getBean(Person.class); System.out.println("姓名："+bean.getUsername()); System.out.println("密码："+bean.getPassword()); String[] beanNamesForType = context.getBeanNamesForType(Person.class); for (String string : beanNamesForType) &#123; System.out.println(string); &#125; &#125;&#125; 2、@ComponentScan包扫描注解context:component-scan主要用于扫描对应包下面的注解到容器中，一般有以下注解 @Controller @Service @Repository @Component 对应的xml配置 &lt;context:component-scan base-package=&quot;cn.itcast&quot;/&gt;’ 用class类文件的方式，把下面配置配在config文件的上面，这样可以实现包扫描 @ComponentScan(basePackages= {“cn.itcast”})’ @excludeFilters可以除去不想扫描进容器的注解1234@ComponentScan(basePackages= &#123;"cn.itcast"&#125;,excludeFilters= &#123; @Filter(type=FilterType.ANNOTATION,classes=Controller.class), @Filter(type=FilterType.ANNOTATION,classes=Service.class)&#125;) use-default-filters这个语句主要是关闭默认扫描对应包下面的所有注解 @includeFilters中要把use-default-filters设置成false xml中这样写 &lt;context:component-scan base-package=&quot;cn.itcast&quot; use-default-filters=&quot;false&quot; /&gt; 使用class文件这样写就ok了1234@ComponentScan(basePackages = &#123;"cn.itcast"&#125;,includeFilters = &#123;@Filter(type=FilterType.ANNOTATION,classes=Controller.class),@Filter(type=FilterType.ANNOTATION,classes=Service.class)&#125;,useDefaultFilters = false) 由于java8以上才有@Repeatable这个注解，表示可以注解重复，但是java8以下不支持，所以我们要做兼容性有一个注解@ComponentScans，可以包含多个@ComponentScan 3、 @Scope注解扫描到容器的默认是单实例的我们可以通过scope改变默认值xml中我们是这样来表示scope的1234&lt;bean id="person" class="cn.itcast.pojo.Person" scope="prototype"&gt; &lt;property name="username" value="lmx"&gt;&lt;/property&gt; &lt;property name="password" value="123"&gt;&lt;/property&gt; &lt;/bean&gt; class类方式在@Bean注解上添加@Scope 注： 单实例是ioc容器启动的时候就就把对象创建放进容器了，但多实例是什么时候调用就什么时候创建 例如：@Scope(&#39;prototype&#39;)这个表明扫描进容器的组件是多实例的，当然我们也可以使用@Scope(&#39;singleton&#39;)或者不写，可以实现单实例12345@Scope(value="SCOPE_PROTOTYPE") @Bean(name="lmx") public Person person() &#123; return new Person("lmz","456"); &#125; 4、 @Lazy懒加载的使用把这个注解放在@Bean的上面表示懒加载，即IOC容器启动的时候创建，什么时候使用什么时候创建 注:这个属性主要针对的是单实例的 5、 @Conditional条件注解的使用这个注解在springboot的底层源码用的最多，所以有必要好好深挖一下我写了一个demo1234567891011@Conditional(WindowsCondition.class) @Bean(name="bill") public Person person01() &#123; return new Person("Bill Gates","123"); &#125; @Conditional(LinuxCondition.class) @Bean(name="linus") public Person person02() &#123; return new Person("linus","456"); &#125; 分别创建WindowsCondition、LinuxCondition，都要实现Condition接口12345678910111213141516171819202122232425262728public class LinuxCondition implements Condition&#123; //参数 context 上下文环境 // 参数 metadata 当前注释此注解的信息 public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; // //获得ioc使用的beanfactory// ConfigurableListableBeanFactory beanFactory = context.getBeanFactory();// // //获取类加载器// ClassLoader classLoader = context.getClassLoader();// // //获取bean定义的注册类// BeanDefinitionRegistry registry = context.getRegistry(); // //判断对应的bean是不是在ioc容器中已经存在// boolean isExist = registry.containsBeanDefinition("lmx");// //获取当前系统环境信息 Environment environment = context.getEnvironment(); //获取操作系统属性 String property = environment.getProperty("os.name"); if(property.contains("Linux")) return true; return false; &#125;&#125; 123456789101112public class WindowsCondition implements Condition&#123; public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; // TODO Auto-generated method stub Environment environment = context.getEnvironment(); String property = environment.getProperty("os.name"); if(property.contains("Windows")) return true; return false; &#125;&#125; 然后做测试12345AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MyConfig.class); String[] strings = context.getBeanNamesForType(Person.class); for (String string : strings) &#123; System.out.println(string); &#125; 结果：由于我的系统是Windows，所以ioc容器中注册的组件id是 bill 下一篇还有spring注解驱动开发（二）]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring注解驱动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx]]></title>
    <url>%2F2017%2F11%2F25%2FNginx%2F</url>
    <content type="text"><![CDATA[Nginxnginx安装nginx安装手册，这个讲解的特别详细，nginx安装手册安装成功之后你在本地输入之后会看到，如果访问不到，请检查防火墙问题 nginx主要的功能 Nginx是一个轻量级、高性能、稳定性高、并发性好的HTTP和反向代理服务器 主要功能 反向代理正向代理：某些情况下，代理我们用户去访问服务器，需要用户手动的设置代理服务器的ip和端口号。反向代理：是用来代理服务器的，代理我们要访问的目标服务器。代理服务器接受请求，然后将请求转发给内部网络的服务器(集群化)，并将从服务器上得到的结果返回给客户端，此时代理服务器对外就表现为一个服务器。 反向代理的优点： 1、充当防火墙 2、可以使负载均衡 Nginx在反向代理上，提供灵活的功能，可以根据不同的正则采用不同的转发策略 负载均衡多在高并发情况下需要使用。其原理就是将数据流量分摊到多个服务器执行，减轻每台服务器的压力，多台服务器(集群)共同完成工作任务从而提高了数据的吞吐量Nginx可使用的负载均衡策略有：轮询（默认）、权重、ip_hash（对负载均衡有破坏） nginx模块我们要好好研究一下Nginx的配置文件nginx.conf daemondaemon on| off:是否已进程的方式守护nginx默认情况下是守护的，所以我们不用修改它 master_processmaster_process on| off:默认一个master进程管理多个worker进程的，关闭之后nginx不会fork出子进程来处理请求，默认是可以的，不用修改它 nginx pidnginx进程的pid nginx反向代理123456789101112131415server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; deny 192.168.13.130; # 禁止192.168.13.130域名访问 allow 192.168.13.0/131; # 表示允许192.168.13.0到192.168.13.131之间的域名访问 deny all; # 表示除了上面允许的ip能够访问意外，其他都不允许访问 root /home/ynn; index index.html index.htm; &#125; 上面的listen表示监听的端口是80,server_name，对应的域名是localhost,location后面有一个 /表示访问localhost/会去服务器/home/ynn下去查找我一般用nginx作为反向代理，使用ftp提高文件给服务器，然后使用反向代理的方式去访问服务器中的内部资源 nginx的负载均衡配置1234567891011121314151617upstream nyist_mall &#123; server 192.168.13.131:8081 weight = 5 max_fails=3 fail_timeout=30s; server 192.168.13.131:8082 weight = 3; server 192.168.13.131:8083 weight = 2; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; proxy_pass http://nyist_mall; &#125; max_fails:表示请求连续失败三次就认定此服务器已经宕机，不再去请求该服务器fail_timeout: 表示请求时长超过30s没有响应，表示请求失败 当我发送localhost访问服务器的时候，nginx负载均衡机制会把我的访问分发给三台服务器，这样可以实现将数据流量分摊给多台服务器执行，减轻每台服务器压力，多台服务器协作，增加数据的吞吐量 Nginx+Tomcat集群和上面我配置的负载均衡相同，只需要把你的tomcat访问地址放在upstrea下面的server中皆可以了，然后设置自己的负责均衡策略这样一个tomcat集群就设置完成了 keepalived + Nginx 实现nginx高可用关于配置，我觉着这个博客写的就很好了，Keepalived+nginx高可用配置我的理解:首先我们必须要设置一个虚拟IP,然后我们使用keepalived绑定虚拟IP,nginx要和keepalived绑定在一起，当nginx宕机的时候，keepalived会检测到，然后停掉nginx,接着关闭自己，然后备用keepalived发送响应给主keepalived,然后在规定时间内没有发送成功，keepalived认定对应的服务已经挂掉，然后自己从备用转成主用。重启后，再次回到原先的主备状态]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>nginx的重点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息中间件]]></title>
    <url>%2F2017%2F10%2F17%2F%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[消息中间件 常用的消息中间件1. ActiveMQ Apache出品的，开发常用2. RabbitMQ 完全支持JMS1.1和J2EE 1.4规范3. kafka Kafka的目的是通过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群来提供实时的消息。 消息中间件可以提高系统性能 JMSJMS 是一套消息中间件的技术规范，定义了一系列的接口规范。JMS 定义了五种不同的消息正文格式，以及调用的消息类型，允许你发送并接收以一些不同形式的数据，提供现有消息格式的一些级别的兼容性。 TextMessage–一个字符串对象 MapMessage–一套名称-值对 ObjectMessage–一个序列化的 Java 对象 BytesMessage–一个字节的数据流 StreamMessage – Java 原始值的数据流 对于消息的传递有两种类型： 一种是点对点的，即一个生产者和一个消费者一一对应； 另一种是发布、订阅模式，即一个生产者产生消息并进行发送后，可以由多个消费者进行接收。 消息中间件用的比较多的还是activeMQ点对点模式消息生产者生产消息（点对点模式）1234567891011121314151617181920212223242526272829303132333435363738import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;public class QueueProducer &#123; public static void main(String[] args) throws JMSException &#123; //创建连接工厂 ActiveMQConnectionFactory activeMQConnectionFactory = new ActiveMQConnectionFactory("tcp://192.168.13.131:61616"); //创建连接 Connection connection = activeMQConnectionFactory.createConnection(); //启动连接 connection.start(); //获取session（会话对象） 参数1:是否启动事物 参数2:消息确认方式 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //创建队列对象 Queue queue = session.createQueue("sms"); //创建消息生产者对象 MessageProducer producer = session.createProducer(queue); //创建消息(文本对象) TextMessage textMessage = session.createTextMessage("你好，jms"); //发送消息 producer.send(textMessage); //关闭连接 producer.close(); session.close(); connection.close(); &#125;&#125; 消费者消费消息（点对点模式）1234567891011121314151617181920212223242526272829303132333435363738394041424344import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;public class QueueConsumer &#123; public static void main(String[] args) throws JMSException &#123; //创建连接工厂 ActiveMQConnectionFactory activeMQConnectionFactory = new ActiveMQConnectionFactory("tcp://192.168.13.131:61616"); //创建连接 Connection connection = activeMQConnectionFactory.createConnection(); //启动连接 connection.start(); //获取session（会话对象） 参数1:是否启动事物 参数2:消息确认方式 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //创建队列对象 Queue queue = session.createQueue("sms"); //创建消息消费者对象 MessageConsumer consumer = session.createConsumer(queue); //设置监听 consumer.setMessageListener(new MessageListener() &#123; public void onMessage(Message message) &#123; TextMessage textMessage = (TextMessage) message; try &#123; String messageText = textMessage.getText(); System.out.println("接收到的消息是："+messageText); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); consumer.close(); session.close(); connection.close(); &#125;&#125; 发布订阅模式消息生产者生产消息（发布订阅模式）123456789101112131415161718192021222324252627282930313233343536373839import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;public class QueueProducer &#123; public static void main(String[] args) throws JMSException &#123; //创建连接工厂 ActiveMQConnectionFactory activeMQConnectionFactory = new ActiveMQConnectionFactory("tcp://192.168.13.131:61616"); //创建连接 Connection connection = activeMQConnectionFactory.createConnection(); //启动连接 connection.start(); //获取session（会话对象） 参数1:是否启动事物 参数2:消息确认方式 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //创建主题对象 Topic topic = session.createTopic("sms2"); //创建消息生产者对象 MessageProducer producer = session.createProducer(topic); //创建消息(文本对象) TextMessage textMessage = session.createTextMessage("你好，jms2"); //发送消息 producer.send(textMessage); //关闭连接 producer.close(); session.close(); connection.close(); &#125;&#125; 消费者消费消息（发布订阅模式）1234567891011121314151617181920212223242526272829303132333435363738394041424344import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;public class QueueConsumer &#123; public static void main(String[] args) throws JMSException &#123; //创建连接工厂 ActiveMQConnectionFactory activeMQConnectionFactory = new ActiveMQConnectionFactory("tcp://192.168.13.131:61616"); //创建连接 Connection connection = activeMQConnectionFactory.createConnection(); //启动连接 connection.start(); //获取session（会话对象） 参数1:是否启动事物 参数2:消息确认方式 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //创建主题对象 Topic topic = session.createTopic("sms2"); //创建消息消费者对象 MessageConsumer consumer = session.createConsumer(topic); //设置监听 consumer.setMessageListener(new MessageListener() &#123; public void onMessage(Message message) &#123; TextMessage textMessage = (TextMessage) message; try &#123; String messageText = textMessage.getText(); System.out.println("接收到的消息是："+messageText); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); consumer.close(); session.close(); connection.close(); &#125;&#125; 注意点 发布订阅模式下，生产者发布消息，消费者必须在开启的情况下才可以接受到，否则消息就浪费掉，就消失了。 Spring整合Jms Spring生产者xml文件配置（点对点） 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:amq="http://activemq.apache.org/schema/core" xmlns:jms="http://www.springframework.org/schema/jms" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;context:component-scan base-package="cn.itcast.demo"&gt;&lt;/context:component-scan&gt; &lt;!-- 真正可以产生Connection的ConnectionFactory，由对应的 JMS服务厂商提供--&gt; &lt;bean id="targetConnectionFactory" class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;property name="brokerURL" value="tcp://192.168.13.131:61616"/&gt; &lt;/bean&gt; &lt;!-- Spring用于管理真正的ConnectionFactory的ConnectionFactory --&gt; &lt;bean id="connectionFactory" class="org.springframework.jms.connection.SingleConnectionFactory"&gt; &lt;!-- 目标ConnectionFactory对应真实的可以产生JMS Connection的ConnectionFactory --&gt; &lt;property name="targetConnectionFactory" ref="targetConnectionFactory"/&gt; &lt;/bean&gt; &lt;!-- Spring提供的JMS工具类，它可以进行消息发送、接收等 --&gt; &lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;!-- 这个connectionFactory对应的是我们定义的Spring提供的那个ConnectionFactory对象 --&gt; &lt;property name="connectionFactory" ref="connectionFactory"/&gt; &lt;/bean&gt; &lt;!--这个是队列目的地，点对点的 文本信息--&gt; &lt;bean id="queueTextDestination" class="org.apache.activemq.command.ActiveMQQueue"&gt; &lt;constructor-arg value="queue_text"/&gt; &lt;/bean&gt; &lt;!--这个是订阅模式 文本信息--&gt; &lt;bean id="topicTextDestination" class="org.apache.activemq.command.ActiveMQTopic"&gt; &lt;constructor-arg value="topic_text"/&gt; &lt;/bean&gt; &lt;/beans&gt; Spring生产者生产消息（点对点）1234567891011121314151617181920import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jms.core.JmsTemplate;import org.springframework.stereotype.Component;import javax.jms.Destination;@Componentpublic class SpringQueueProducer &#123; @Autowired private JmsTemplate jmsTemplate; @Autowired private Destination queueTextDestination; //发送消息 public void sendTextMessage(final String text)&#123; jmsTemplate.convertAndSend(text); &#125;&#125; 123456789101112@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations="classpath:applicationContext-jms-producer.xml")public class TestQueue &#123; @Autowired private QueueProducer queueProducer; @Test public void testSend()&#123; queueProducer.sendTextMessage("SpringJms-点对点"); &#125; &#125; Spring消费者接收消息（点对点）Spring消费者接收xml配置12345678910111213141516171819202122232425262728293031323334&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:amq="http://activemq.apache.org/schema/core" xmlns:jms="http://www.springframework.org/schema/jms" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;!-- 真正可以产生Connection的ConnectionFactory，由对应的 JMS服务厂商提供--&gt; &lt;bean id="targetConnectionFactory" class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;property name="brokerURL" value="tcp://192.168.25.131:61616"/&gt; &lt;/bean&gt; &lt;!-- Spring用于管理真正的ConnectionFactory的ConnectionFactory --&gt; &lt;bean id="connectionFactory" class="org.springframework.jms.connection.SingleConnectionFactory"&gt; &lt;!-- 目标ConnectionFactory对应真实的可以产生JMS Connection的ConnectionFactory --&gt; &lt;property name="targetConnectionFactory" ref="targetConnectionFactory"/&gt; &lt;/bean&gt; &lt;!--这个是队列目的地，点对点的 文本信息--&gt; &lt;bean id="queueTextDestination" class="org.apache.activemq.command.ActiveMQQueue"&gt; &lt;constructor-arg value="queue_text"/&gt; &lt;/bean&gt; &lt;!-- 监听类 --&gt; &lt;bean id="myMessageListener" class="cn.itcast.demo.MyMessageListener"&gt;&lt;/bean&gt; &lt;!-- 消息监听容器 --&gt; &lt;bean class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="destination" ref="queueTextDestination" /&gt; &lt;property name="messageListener" ref="myMessageListener" /&gt; &lt;/bean&gt; &lt;/beans&gt; Spring消费者消费消息（点对点）1234567891011121314package cn.itcast.demo;import javax.jms.Message;import javax.jms.MessageListener;import javax.jms.TextMessage;public class MyMessageListener implements MessageListener &#123; public void onMessage(Message message) &#123; TextMessage textMessage = (TextMessage) message; System.out.println("接受到的消息为："+textMessage); &#125;&#125; 123456789101112@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations="classpath:applicationContext-jms-consumer-queue.xml")public class TestQueue &#123; @Test public void testQueue()&#123; try &#123; System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; spring整合jms，对于订阅广播模式，xml配置和点对点一样，我被对应配置已经放在里面了然后只有执行语句不一样 Spring生产者生产消息（发布订阅模式）1234567891011121314151617181920@Componentpublic class TopicProducer &#123; @Autowired private JmsTemplate jmsTemplate; @Autowired private Destination topicTextDestination; /** * 发送文本消息 * @param text */ public void sendTextMessage(final String text)&#123; jmsTemplate.send(topicTextDestination, new MessageCreator() &#123; public Message createMessage(Session session) throws JMSException &#123; return session.createTextMessage(text); &#125; &#125;); &#125;&#125; 12345678910111213141516import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import cn.itcast.demo.TopicProducer;@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations="classpath:applicationContext-activemq-producer.xml")public class TestTopic &#123; @Autowired private TopicProducer topicProducer; @Test public void sendTextQueue()&#123; topicProducer.sendTextMessage(); &#125; &#125; Spring消费者消费消息（发布订阅模式）123456789101112@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations="classpath:applicationContext-jms-consumer-topic.xml")public class TestTopic &#123; @Test public void testTopic()&#123; try &#123; System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 上面的代码 1System.in.read(); 是防止程序启动结束就会关闭，所以让窗口一直等待输入 学习总结花了一两天来了解jms以及和spring的整合，用处很大！有以下两点 可以用来在发送短信的功能中，把短信验证码发送到队列中，然后点对点方式让用户接受到，起到了一定程度的削锋 发布订阅模式可以用在集群环境下，由于集群环境下，同一个页面在不同的服务器上存在多份，可以使用发布订阅模式完成同时渲染多个服务器上的相同的页面]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>消息中间件</tag>
        <tag>JMS</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis的学习总结]]></title>
    <url>%2F2017%2F04%2F17%2Fredis%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[redis的学习总结总结不已，好好珍惜 关系型数据库 特点：数据和数据之间，表和字段之间，表和表之间是存在关系的 优点： 数据之间有关系，进行数据的增删改查时非常方便的。 关系型数据库 有事务操作。 保证数据的完整性 缺点： 数据和数据之间的关系，是有底层算法保证的，大量算法会拉低系统运行速度 海量数据的增删改查时会显得无能为力，很可能宕机 海量数据环境下对数据表进行维护/扩展，也会变得无能为 非关系型数据库（NOSQL）：为了处理海量数据，需要将关系型数据库的关系 去掉。优点： 海量数据的增删改查，非常轻松应对 海量数据的维护非常轻松。 缺点： 数据和数据之间没有关系，所以不能一目了然 非关系型数据库，没有关系，没有强大的事务保证数据的 完整和安全 海量数据的操作redis使用最多，新浪网Redis的使用地方： 作为关系型数据库的缓存 可以做任务队列 大量数据运算 排行榜（类似于微博热搜榜） 字符串在Redis中是二进制安全的便意味着该类型存入和获取的数据相同。在Redis中字符串类型的Value最多可以容纳的数据长度是512M 什么是二进制安全的？关系型数据库是二进制不安全的，关系型数据库需要频繁的编辑码，很可能导致码表不同造成乱码redis是二进制安全的，在服务器端不进行编码，只起到传递数据的目的，解码编码只发生在客户端 Redis的安装（Centos） redis是C语言开发，安装redis需要先将官网下载的源码进行编译，编译依赖gcc环境。如果没有gcc环境，需要安装gcc:（环境已经导入完成） 解压文件tar –zxvf redis-3.0.0.tar.gz 编译redis (编译，将.c文件编译为.o文件)进入解压文件夹，cd redis-3.0.0执行make 安装make PREFIX=/usr/local/redis install copy文件redis启动需要一个配置文件，可以修改端口号等信息。cp redis.conf /usr/local/redis 注：如果没有配置文件redis也可以启动，不过将启用默认配置，这样不方便我们修改端口号等信息 Redis启动 Redis启动-后端模式 修改redis.conf配置文件， daemonize yes 以后端模式启动。vim /usr/local/redis/redis.conf 启动时，指定配置文件cd /usr/local/redis/ ./bin/redis-server ./redis.conf 查看是否启动 ps -ef | grep -i redis redis的关闭 查询到PID,kill -9 pid 【断电，非正常关闭，一般不用，否则造成数据丢失】 正常关闭 【正常关闭，数据保存】./bin/redis-cli shutdown Redis数据类型redis使用的键值对的方式保存数据 Redis——String类型的操作Key: 必须是字符串Value: String,hash,list,set,zset(有序的set集合) 赋值： set key value：设定key持有指定的字符串value，如果该key存在则进行覆盖操作。总是返回”OK” 如果赋予相同的key，新的value会覆盖老的value取值： get key：获取key的value。如果与该key关联的value不是String类型，redis将返回错误信息，因为get命令只能用于获取String value；如果该key不存在，返回(nil)。删除：del key：删除指定key,返回值是数字类型，表示删了几条数据getset：先去除第一个值然后设置给第二个incr key：原子性递增decr key：原子性递减Incr和decr 只能对字符串是数字的操作append key value: 拼凑字符串。如果该key存在，则在原有的value后追加该值；如果该key不存在，则重新创建一个key/value Redis——Hash类型的操作hash存储的特点：占用磁盘空间极少flushall,flushdb 删除所有的键值对，第一个表示删除所有db下的键值对，第二个表示删除当前db下的所有键值对设置hset: hset hash1 username zhangsan 设置key为hash1，username=zhangsanhmset: hmset hash2 username uname zhangsan age 18取出hget: 获取key中的多个filed的值 hget hash1 usernamehmget: ： 获取key中的多个filed的值 hget hash2 uname agehgetall: ： 获取key中的所有filed-vaule hgetall hash2删除hdel hash1 uname 删除hash1中的uname属性keys： 查询所有的key(各个类型都可以这样查找使用)hincrby: hincrby hash2 age 20 增加20hexists hexists hash1 uname 判断是uname字段是否存在hlens hlens hash2 得到hash2中字段个数hkeys hkeys hash2 获取所有的keyhvals hvals hash2 获取所有的值 Redis——list类型的操作（类似于java中的链表list）lpush key 参数1….：加入参数到list集合，例如 1,2,3 插入结果是:3,2,1rpush key 参数1….：加入参数到list集合lrange key start end： 获取从左往右数起从start到end的元素,其中end可为-1表示导入第一个元素lpop key： list集合从左侧弹出keyrpop key： list集合从右侧演出keyllen key：list集合的长度lrem key a：从左侧查找删除所有的alrem key count value：从左侧查找删除所有的key然后删除count个value值 Redis——set类型的操作set无序，不重复，适用于两个大集合的运算add key values[value1、value2…]：向set中添加数据，如果该key的值已有则不会重复添加srem key members[member1、member2…]：删除set中指定的成员smembers key：获取set中所有的成员sismember key member：判断参数中指定的成员是否在该set中，1表示存在，0表示不存在或者该key本身就不存在。（无论集合中有多少元素都可以极速的返回结果 集合运算sdiff key1 key2…：返回key1与key2中相差的成员，而且与key的顺序有关。即返回差集。表示属于key1不属于key2,有顺序的sinter key1 key2…：返回交集。即属于key1,属于key2，无顺序sunion key1 key2 …：返回并集，返回key1,key2 上面的方法都可以加上store,例如sdiff为sdiffstore key3 key1 key2:把key1、key2的交集存放在key3上 其他延伸scard key1:返回key1的长度 Redis——zset(有序set集合)类型的操作zset: 有序不重复这个功能很适合用作 排行榜之所以是有序，就是因为每个元素我们都要赋予一个分数 zadd key score member score2 member2 … ：将所有成员以及该成员的分数存放到sorted-set中。如果该元素已经存在则会用新的分数替换原有的分数zscore key member：返回指定成员的分数zcard key1:返回key1的长度zrem key member[member…]：移除集合中指定的成员，可以指定多个成员zrange key start end [withscores]：获取集合中脚标为start-end的成员，[withscores]参数表明返回的成员包含其分数。（分数由小到大排列）zrevrange key start end [withscores]：获取集合中脚标为start-end的成员，[withscores]参数表明返回的成员包含其分数（分数由大到小排列） 通用命令keys* ：表示查找所有的keydel key1 ：表示删除key1exists key：表示key是否存在rename key newkey：表示给key重名为newkeytype key：表示得到key的类型expire key time：表示给key设置生存时间为time秒ttl key：表示得到key的剩余生存时间 subscribe,publish 频道的订阅与发布subscribe test表示订阅test频道publish test key 表示在test频道发布内容key,然后订阅频道的会接收到key内容 Redis的数据库默认redis创建好了数据量,总共16个数据库，分别0,1…15；数据库和数据库之间，不能共享键值对。切换数据库：select 数据库名; 把某个键值对进行数据库移植：move newkey 1：将当前库的key移植到1号库中 Redis的事务MySQL-事务： 目的为了保证数据完整性，安全。Redis-事务： 目的为了进行redis语句的批量化执行 multi：开启事务用于标记事务的开始，其后执行的命令都将被存入命令队列，直到执行EXEC时，这些命令才会被原子的执行，类似与关系型数据库中的：begin transactionexec：提交事务，类似与关系型数据库中的：commit 执行批量化discard：事务回滚，类似与关系型数据库中的：rollback 不执行批量化操作 Redis的其他命令dbsize： 返回当前数据库中key 的数目info 查看redis数据 Redis的持久化redis所有的增删改，都在内存中操作，断电之后内存中的数据是不存在的，由于redis部分内容存在硬盘上，所以是部分丢失数据 redis有两种持久化策略 RDB:是redis的默认持久化机制,相当于 照快照，保存的是一种状态 优点： 快照保存数据速度极快，还原数据速度较快 适用于灾难备份 缺点： RDB机制符合要求就会照快照(随时随地启动)，会占用一部分系统资源，小机器不适合使用 RDB何时进行照快照： ①服务器正常关闭时，会照一次快照 ./bin/redis-cli shutdown ②key满足一定条件，会照一次快照 AOF: AOF: 使用日志功能保存数据操作。 默认AOF机制关闭的。 每秒同步（默认）：每秒进行一次AOF保存数据。 安全性低，比较节省系统资源 每修改同步：只要有key变化语句，就进行AOF保存数据。比较安全，但是极为浪费效率 不同步：不进行任何持久化操作 不安全 AOF操作：只会保存导致key变化的语句 AOF配置： always #每次有数据修改发生时都会写入AOF文件 everysec #每秒钟同步一次，该策略为AOF的缺省策略 no #从不同步。高效但是数据不会被持久化 优点：①持续性占用极少量的内存资源 缺点：①日志文件会特别大，不适用于灾难恢复 ②恢复效率远远低于RDB 适用于：内存比较小的计算机]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis缓存的使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络知识自我总结]]></title>
    <url>%2F2017%2F03%2F05%2F%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E8%87%AA%E6%88%91%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[网络知识自我总结两种软件架构： b/s c/s 无论哪一种，都需要网络 网络通信协议它对数据的传输格式，传输速率，传输步骤等做了统一规定，通信双方必须同时遵守才能完成数据交换 TCP/IP协议:是internet最基本的协议通常我们会把七层结构简化为四层结构，每一层都要告诉它的下一层所提供的协议来完成自己的需求 网络层是TCP/IP的核心，用于将传输的数据进行分组，将分组的数据传输到目标计算机或者网络 两种通信协议的介绍UDP:数据报协议UDP是无连接通信协议，即在数据传输时，数据的接受端和发送端不建立逻辑连接。由于使用UDP协议消耗资源小，通信效率高，所以通常被使用为视频音频，因为偶尔丢失一两个数据包，也不会对接受结果产生太大的影响由于UDP面向无连接性，不能保证数据的完整性，因此在传输重要数据时候不建议使用UDP协议特点：数据限制在64KB以内 TCP:面向连接三次握手，保证数据的安全，用于文件传输，浏览网页等 在tcp中，首先是先启动服务器端，等待着客户端来连接，然后客户端发送请求给服务器端，服务器端响应请求给客户端，然后客户端再次向服务器端发送请求确认连接，三次握手结束。成功建立连接。 网上有一个比较形象的图 网络编程三要素 协议：计算机网络通信必须要遵守的规则 IP地址：互联网协议地址 端口：有两个字节组成，取值范围0-65535之间，0-1024我们不能使用，已经被系统分配给已知软件了]]></content>
      <categories>
        <category>网络知识</category>
      </categories>
      <tags>
        <tag>TCP协议</tag>
        <tag>UDP协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux的chmod赋权限语句]]></title>
    <url>%2F2017%2F02%2F19%2Flinux%E7%9A%84chmod%E8%B5%8B%E6%9D%83%E9%99%90%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[linux下chmod 755的解释很多时候在Linux系统下给安装好的软件赋权限的时候回用的755、555,那么数字表示什么呢？ 普及一下chmod的数字 chmod是Linux下设置文件权限的命令，后面的数字表示不同用户或用户组的权限。 一般是三个数字： 第一个数字表示文件所有者的权限 第二个数字表示与文件所有者同属一个用户组的其他用户的权限 第三个数字表示其它用户组的权限。 权限分为三种：读（r=4），写（w=2），执行（x=1） 。 综合起来还有可读可执行（rx=5=4+1）、可读可写（rw=6=4+2）、可读可写可执行(rwx=7=4+2+1)。 举个例子 1234chmod 755 设置用户的权限为： 1.文件所有者可读可写可执行 --7 2.与文件所有者同属一个用户组的其他用户可读可执行 --5 3.其它用户组可读可执行]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>命令</tag>
      </tags>
  </entry>
</search>
