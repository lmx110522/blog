<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Zookeeper深入学习总结]]></title>
    <url>%2F2019%2F03%2F27%2FZookeeper%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[zookeeper深入学习（观察者设计模式）Zookeeper = 文件系统 + 通知机制Zookeeper是一个分布式的服务框架，主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储。但是，zookeeper并不是专门存储数据的，它主要是维护和监控系统的数据的状态的变化的。通过监控这些数据的变化，从而达到基于数据的集群管理。Zookeeper所提供的服务主要是通过: 数据结构+原句+watcher机制这三个部分来实现的。 初步了解zookeeper的节点初步介绍zookeeper中的数据存储在一个叫做ReplicatedDataSource的数据库中，该数据是一个内存数据库，既然是内存数据库，数据量就不会很大zookeeper的数据存储在内存中，由于内存空间的限制，存储的节点需要根据需求和功能进行选择，都是有ZK节点的性质和该节点所关联的数据实现的。 Zookeeper中每个节点存储的数据都是要进行原子性的操作，也就是读操作将获取与节点相关的所有数据，写操作将替换掉节点所有的数据。每一个节点都拥有自己的ACL(访问控制列表)，这个列表规定了用户的权限，即限定了特定用户对目标节点可以执行的操作。 特点 zookeeper节点类型主要有两种，一种是 临时节点，另一种是 永久节点，节点的类型在创建时即被确定，并且不能改变。 临时节点该节点的生命周期依赖于创建它们的会话。一旦会话(Session)结束，临时节点将被自动删除，当然可以也可以手动删除。虽然每个临时的Znode都会绑定到一个客户端会话，但他们对所有的客户端还是可见的。另外，ZooKeeper的临时节点不允许拥有子节点。 永久节点该节点的生命周期不依赖于会话，并且只有在客户端显示执行删除操作的时候，他们才能被删除。 存储结构是一个树状，每个节点被称为一个ZNode,默认能够存储1MB的数据，并且每个ZNode都是可以通过路径唯一标识 Zookeeper的常用方式统一配置信息把集群的中各个服务器配置存放于每一个ZNode中，节点信息变化，会通知到各个服务器 统一集群模式主要是把各个集群的状态存放于节点中，哪台服务器宕机了，其他节点会立刻被通知到 服务器动态上下线服务节点上下线会把信息返回给客户端，客户端将不再调用此服务 软负载均衡把服务器的访问量存储在ZNode中，然后，客户端去访问的时候，把访问的请求分发给请求少的服务器 Zookeeper监听原理 首先要有一个main（）线程 在main线程中创建zookeeper客户端，这时就会创建两个线程，一个负责网络连接通信(connect),一个负责监听(listener) 通过connect线程将注册的监听事件发给zookeeper 在zookeeper的注册监听列表中将注册的监听事件添加到列表中 zookeeper监听到数据或者路径有变化时，会将这个消息发送给listener线程 listener线程内部调用process()方法。 常见的监听类型 监听节点数据的变化 get [path] watch 监听节点数量的变化 ls [path] watch]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql优化后续总结]]></title>
    <url>%2F2019%2F03%2F23%2Fmysql%E4%BC%98%E5%8C%96%E5%90%8E%E7%BB%AD%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[mysql优化后续总结show status like ‘innodb_row_lock%’ 查看行级锁的状态 show status like ‘table%’ 查看表级锁的状态 explainid select_key table type key possible_key key_len ref rows extra 执行顺序id相同，从上往下执行id不同，从大向小执行type: all-&gt;index-&gt;range-&gt;ref-&gt;eq_ref-&gt;const-&gt;systempossible_key: 可能用到的索引key: 实际用到的索引ref: const,实际引用extra: using index using where using filesort(效率偏差，最左匹配原则断层) using temporty(从上往下) 写sql的时候注意点 不对索引建立操作 != &lt;&gt; 适当选择使用 exists in 索引最左匹配 order by 、group by和where一样，根据最左匹配原则合理创建索引 字符类型一定要加双引号 索引操作创建索引create index 索引名 on 表名(索引列1,..)alter table 表名 add index 索引名(索引列1,..) 删除索引drop index 索引名 on 表名 查找所有的索引show index from 表名 执行过程详细查看接着我们需要详细查看执行情况 show variables like ‘profiling’ 默认关闭 set global profiling = 1;打开然后 使用 show profiles 查看所有的语句执行 然后根据某个语句执行id show profile cpu,block io 或者(all) for query id(上面的id);可以获得哪个执行的秒数情况，用来排查 其实我们还可以使用mysql全局监测 set global general_log = 1;默认关闭，是自带数据库mysql中的select * from mysql.general_log;获得以往执行情况 mysql锁表级索 行级索 inndb表级索 myisam mysql5.5以后默认innodb 以 innodb为例： 首先 设置读锁lock table 表名 read; 不可以对表进行写，但是可以读，只能读当前表其他session可以读，但是呢，写的话会阻塞 unlock tables; 释放所有的锁 设置写锁 lock table 表名 write; 不能写也不能读 unlock tables;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蚂蚁金服面试总结]]></title>
    <url>%2F2019%2F03%2F21%2F%E8%9A%82%E8%9A%81%E9%87%91%E6%9C%8D%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[阿里蚂蚁金服面试总结——查漏补缺内存泄露与内存溢出原理内存溢出out of memory出现的原因是，程序再向系统申请内存的时候，系统没有足够的内存提供给应用程序。 内存泄露经常报错的提示是 memory leak,出现的原因，程序向系统申请内存，系统有内存，但是释放不出来。比如，之前打开一个应用程序，申请了一个内存空间，但是用完之后，没有释放掉。等到了下一个程序用，这份已经闲置的内存就不能用，可能是指针的丢失。 常发性内存泄露发生内存泄露的代码会被多次执行到，每次执行的时候都会导致一块内存的泄露。 偶发性内存泄露发生内存泄露的代码只是在某些特定的环境或操作的过程中才会发生。常发性和偶发性是相对的。对于特定的环境，偶发性也许就会变成常发性。所以测试环境和测试方法对检测内存泄漏至关重要。 一次性内存泄漏发生内存泄漏的代码只会被执行一次，或者由于算法上的缺陷，导致总会有一块仅且一块内存发生泄漏。比如，在类的构造函数中分配内存，在析构函数中却没有释放该内存，所以内存泄漏只会发生一次。 隐式内存泄漏程序在运行过程中不停的分配内存，但是直到结束的时候才释放内存。严格的说这里并没有发生内存泄漏，因为最终程序释放了所有申请的内存。但是对于一个服务器程序，需要运行几天，几周甚至几个月，不及时释放内存也可能导致最终耗尽系统的所有内存。所以，我们称这类内存泄漏为隐式内存泄漏。 内存溢出总结内存溢出中隐式内存泄漏比较难以检测到，所以危害比较大。 总结内存泄露如果不是特别严重，泄露一点半点的，可以容忍，系统的内存空间可能很大，足够分配给新的应用，但是泄露很多，或者一直泄露，这时候会导致，系统闲置的空间越来越小，也就是常讲的，内存泄露最终会导致内存溢出。 内存溢出形成内存溢出的原因有很多种，如下： 内存中加载的数据量过于庞大，如一次从数据库中取出过多数据； 集合类中有对 对象 的引用，使用完后没有清空，是的jvm不能回收； 代码中存在死循环或者循环产生或多重复的对象实体 启动参jvm内存时参数值设定过小和面试官讨论了关于死循环是否会产生内存溢出的问题，所以理由是什么？我后来总结了一下，如果你死循环中大量创建对象，然后就会出现out of memory，由于创建的对象存放在堆区，所以堆区溢出也会造成内存溢出，和递归调用同样的道理。 解决方案 修改虚拟机的参数,直接增加内存 -xmx -xms 检查日志错误，查看“OutOfMemory”错误前是否有其它异常或错误 对代码进行走查和分析，找出可能发生内存溢出的位置 检查对数据库查询中，是否有一次获得全部数据的查询。一般来说，如果一次取十万条记录到内存，就可能引起内存溢出。这个问题比较隐蔽，在上线前，数据库中数据较少，不容易出问题，上线后，数据库中数据多了，一次查询就有可能引起内存溢出。因此对于数据库查询尽量采用分页的方式查询。 检查代码中是否有死循环或递归调用（重复产生新对象实体）。 检查List、MAP等集合对象是否有使用完后，未清除的问题。List、MAP等集合对象会始终存有对对象的引用，使得这些对象不能被GC回收。 socket心跳机制因为防火墙会关闭长时间处于非活跃状态的连接而导致socket连接中断，通过心跳机制可以保持长连接。 原理客户端会每个一段时间向服务器端发送一个心跳包，同时开启定时器。服务器返回一个相同的心跳包给客户端。如果客户端能够接受到心跳包，说明连接正常，删除定时器。如果超时未收到心跳包，则认为连接断开，这个时候进行重连设置。 当客户端和服务器断掉的时候，我们可以重连设置，如何设置直连当与服务器断开连接或网络错误的时候，先不要处理当前socket，应该首先另起一个socket服务，与服务器尝试连接，当连接成功，通知当前socket重新连接，每6秒连接一次，如果30秒内没有连接上，通知掉线，然后继续尝试连接，直到连接上。 快速排序的最坏情况这个其实是会的，但是由于当时紧张脑子有点放空！快速排序的最好情况是，每次恰好能够均分序列，树的深度为log2n+1,仅需要递归log2n次；最坏情况是O(n^2),每次划分序列为一个元素和其他元素部分，退化为冒泡排序，有点像单斜树 mysql的性能优化方面有很多，如：索引优化，查询优化，查询缓存，服务器设置优化，操作系统和硬件优化，应用层面优化(web服务器优化，换缓存) mysql性能的开销指标 执行时间 查询的数据量 返回的结果数量 几种简单的优化查询优化 count的优化计算id大于5的城市 a. select count() from world.city where id &gt; 5; b. select (select count() from world.city) – count() from world.city where id &lt;= 5; a语句当行数超过11行的时候需要扫描的行数比b语句要多， b语句扫描了6行，此种情况下，b语句比a语句更有效率。当没有where语句的时候直接select count() from world.city这样会更快，因为mysql总是知道表的行数 避免使用不兼容的数据类型数据库类型的不兼容可能使优化器无法执行一些本来可以优化的操作 索引字段进行运算会使索引失效（会导致引擎放弃索引进行全表扫描）如： SELECT FROM T1 WHERE F1/2=100 应改为: SELECT FROM T1 WHERE F1=100*2 避免使用!=或＜＞、IS NULL或IS NOT NULL、IN ，NOT IN等这样的操作符 因为这会使系统无法使用索引,而只能直接搜索表中的数据。例如: SELECT id FROM employee WHERE id != “B%” 优化器 将无法通过索引来确定将要命中的行数,因此需要搜索该表的所有行。在in语句中能用exists语句代替的就用exists. 能够用BETWEEN的就不要用IN 能够用DISTINCT的就不用GROUP BY 尽量不要使用SELECT INTO语句。SELECT INTO 语句会导致表被锁定，阻止其他用户访问该表 1234SELECT LastName,Firstname INTO Persons_backup FROM Persons WHERE City='Beijing'将查询后的结果存放在一个新表 Persons_backup中，其中查询的过程表会被锁定 必要的时候强制查询优化器使用某个索引 1SELECT * FROM T1 WHERE nextprocess = 1 AND processid IN (8,32,45) 改成： SELECT * FROM T1 (INDEX = IX_ProcessID) WHERE nextprocess = 1 AND processid IN (8,32,45) 则查询优化器将会强行利用索引IX_ProcessID 执行查询。 Order By语句的Mysql优化 ORDER BY + LIMIT组合的索引优化 索引建立在order by上 Where+ORDER BY + LIMITz组合索引优化 索引建立在where 和 order by 上 WHERE+ORDER BY多个栏位+LIMIT 索引建立在where和多个order by上 不要在选择的栏位上放置索引，应该在条件选择的语句上合理的放置索引，比如order by where 数据类型优化避免使用NULL类型，因为大多数数据库要进行对他特殊处理，最好使用0或者1来标识 先总结那么多，后续再去进行添加总结]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>蚂蚁金服面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程总结(四)]]></title>
    <url>%2F2019%2F03%2F15%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%80%BB%E7%BB%93-%E5%9B%9B%2F</url>
    <content type="text"><![CDATA[线程总结(四)怎么检测一个线程是否拥有锁？ 可以调用wait()方法，如果出现异常，就说明java中的线程没有持有锁。否则将持有锁。(这种方式不推荐) 我们可以使用API，Thread的一个静态方法boolean isHave = Thread.holdsLock(User.class);如果存在则返回true,没有持有User这个对象的锁，则返回false; Jdk中排查多线程问题用什么命令jstack作用： 生成JVM当前时刻线程的快照(threaddump,当前进程中所有线程的信息)目的：帮助快速定位程序问题出现的原因，如长时间停顿、cpu占用率过高。 向线程传递参数的三种基本方法1. 通过构造方法传递数据 1234567891011121314151617181920package com.nyist.thread; public class MyThread extends Thread&#123; private String name; public MyThread(String name) &#123; this.name = name; &#125; public void run() &#123; System.out.println("hello " + name); &#125; public static void main(String[] args) &#123; Thread thread = new MyThread("demo"); thread.start(); &#125;&#125; 2.通过变量和方法传递数据12345678910111213141516171819202122package com.nyist.thread;public class MyThread1 implements Runnable&#123; private String name; public void setName(String name) &#123; this.name = name; &#125; public void run() &#123; System.out.println("hello " + name); &#125; public static void main(String[] args) &#123; MyThread2 myThread = new MyThread2(); myThread.setName("demo"); Thread thread = new Thread(myThread); thread.start(); &#125;&#125; 3.通过回调函数传递数据1234567891011121314151617181920212223242526272829303132333435363738394041package com.nyist.thread; class Data&#123; public int value = 0;&#125;class Work&#123; public void process(Data data, Integer numbers) &#123; for (int n : numbers) &#123; data.value += n; &#125; &#125;&#125;public class MyThread2 extends Thread&#123; private Work work; public MyThread3(Work work) &#123; this.work = work; &#125; public void run() &#123; java.util.Random random = new java.util.Random(); Data data = new Data(); int n1 = random.nextInt(1000); int n2 = random.nextInt(2000); int n3 = random.nextInt(3000); work.process(data, n1, n2, n3); // 使用回调函数 System.out.println(String.valueOf(n1) + "+" + String.valueOf(n2) + "+" + String.valueOf(n3) + "=" + data.value); &#125; public static void main(String[] args) &#123; Thread thread = new MyThread3(new Work()); thread.start(); &#125;&#125; 锁的降级和升级ReadWriteLock是读写锁接口，里面有两个方法123456789101112131415public interface ReadWriteLock &#123; /** * Returns the lock used for reading. * * @return the lock used for reading */ Lock readLock(); /** * Returns the lock used for writing. * * @return the lock used for writing */ Lock writeLock();&#125; 一个是读锁，一个写锁 降级锁： 由写锁到读锁 升级锁： 由读锁到写锁 1234567891011121314package com.nyist.thread;import java.util.concurrent.locks.ReentrantReadWriteLock;public class Test1 &#123; public static void main(String[] args) &#123; ReentrantReadWriteLock rtLock = new ReentrantReadWriteLock(); rtLock.readLock().lock(); System.out.println("获得读锁."); rtLock.writeLock().lock(); System.out.println("阻塞"); &#125;&#125; 结果打印出来是 获得读锁. 这说明ReentrantReadWriteLock不可以锁升级1234567891011121314package com.nyist.thread;import java.util.concurrent.locks.ReentrantReadWriteLock;public class Test2 &#123; public static void main(String[] args) &#123; ReentrantReadWriteLock rtLock = new ReentrantReadWriteLock(); rtLock.writeLock().lock(); System.out.println("写锁"); rtLock.readLock().lock(); System.out.println("获得读锁"); &#125;&#125; 结果打印出来是 写锁 获得读锁 这说明ReentrantReadWriteLock可以锁降级 FutureTask和Future区别Future是一个接口，代表可以取消的任务，并且返回执行的结果。FutureTask是实现了Futrue和Runnable接口]]></content>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程总结(三)以及HashMap底层源码跟读]]></title>
    <url>%2F2019%2F03%2F14%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%80%BB%E7%BB%93-%E4%B8%89%2F</url>
    <content type="text"><![CDATA[多线程的总结(三)Synchronized有哪几种用法方法声明时使用放在声明符之后，返回值之前，即一次只有一个线程进入该方法。，其他线程排队等候，等当前线程执行结束之后才可以进入执行。 对于某一代码块使用synchronized后跟括号,括号里是变量,这样,一次只有一个线程进入该代码块123456789public int synMethod(int a1)&#123; synchronized(a1) &#123; //一次只能有一个线程进入 &#125; &#125; synchronized后面括号里是一对象,此时,线程获得的是对象锁如果线程进入，获得是对象锁，那么别的线程在该类所有对象上都不能进行任何操作，使用对象级锁范围太过于大，所以性能不高，完全可以让其他线程访问该类上的其他同步方法来共享资源。由于每个对象都有锁，所以可以使用虚拟对象锁来上锁。 12345678910111213141516171819202122232425262728293031323334353637class FineGrainLock &#123; MyMemberClass x, y; Object xlock = new Object(), ylock = new Object(); public void foo() &#123; synchronized(xlock) &#123; //access x here &#125; //do something here - but don't use shared resources synchronized(ylock) &#123; //access y here &#125; &#125; public void bar() &#123; synchronized(this) &#123; //access both x and y here &#125; //do something here - but don't use shared resources &#125;&#125; 不推荐这样使用this，范围太大了，导致进入其他对象不能访问其他同步方法，最好使用虚拟变量来上锁 synchronized后面括号里是类如果线程进入,则线程在该类中所有操作不能进行,包括静态变量和静态方法,实际上,对于含有静态方法和静态变量的代码块的同步,我们通常用 类.class 来加锁. 锁的四种声明方式总结 锁是和对象相关联的，每个对象有一把锁，为了执行synchronized语句，线程必须能够获得synchronized语句中表达式指定的对象的锁，一个对象只有一把锁，被一个线程获得之后它就不再拥有这把锁，线程在执行完synchronized语句后，将获得锁交还给对象。 在方法前面加上synchronized修饰符即可以将一个方法声明为同步化方法。同步化方法在执行之前获得一个锁。如果这是一个类方法，那么获得的锁是和声明方法的类相关的Class类对象的锁。如果这是一个实例方法，那么此锁是this对象的锁总之： 同步synchronized(.class)代码块的作用其实和synchronized static方法作用一样。Class锁对类的所有对象实例起作用。synchronized应用在static方法上，那是对当前对应的.Class进行持锁。 synchronized同步方法①对其它的synchronized同步方法或synchronized(this)同步代码块调用是堵塞状态；②同一时间只有一个线程执行synchronized同步方法中的代码。 synchronized(this)同步代码块①对其它的synchronized同步方法或synchronized(this)同步代码块调用是堵塞状态；②同一时间只有一个线程执行synchronized同步方法中的代码 重入锁可重入锁最大的作用就是避免死锁中断响应： 对于synchronized块来说，要么获取到锁执行，要么持续等待。而重入锁的中断响应功能就合理地避免了这样的情况。比如，一个正在等待获取锁的线程被“告知”无须继续等待下去，就可以停止工作了 公平锁：所有的等待锁线程都排在队列中，使用FIFO的方式来获取锁非公平锁：等待线程在无论在不在队列中或者队列末尾都会直接抢夺锁，抢不到进入队列中，下次继续抢夺12345678910ReentrantLock lock = new ReentrantLock();lock.lockInterruptibly(); // 以可以响应中断的方式加锁Thread t1 = new Thread(deadLock1);Thread t2 = new Thread(deadLock2);t1.start();t2.start();Thread.sleep(1000);t2.interrupt();//线程t2响应中断，不会继续等待t1所持有的锁 tryLock 锁申请等待限时1234567891011121314151617181920212223242526import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.ReentrantLock;public class TryLockTest implements Runnable&#123; public static ReentrantLock lock = new ReentrantLock(); @Override public void run() &#123; try &#123; if (lock.tryLock(1, TimeUnit.SECONDS)) &#123; // 等待1秒 Thread.sleep(2000); //休眠2秒 &#125; else &#123; System.err.println(Thread.currentThread().getName() + "获取锁失败！"); &#125; &#125; catch (Exception e) &#123; if (lock.isHeldByCurrentThread()) lock.unlock(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; TryLockTest test = new TryLockTest(); Thread t1 = new Thread(test); t1.setName("线程1"); Thread t2 = new Thread(test); t1.setName("线程2"); t1.start();t2.start(); &#125;&#125; 首先普及一下APIisFair（）：作用是判断ReentrantLock是否是公平锁。返回true为公平锁，false为非公平锁。isHeldByCurrentThread（）查询当前线程是否保持锁isLocked（）：查询锁是否有线程保持。 Fork/Join框架是干什么的(执行任务的框架)是Java7提供的用于执行任务的框架，是把一个大任务分割成若干个小任务，然后把各个小任务执行的结果汇总就是大任务的结果。完成两件事情1. 任务分割：首先Fork/Join框架需要把大的任务分割成多个子任务，如果子任务比较大的话还要继续分割2.执行任务并合并结果：分割的子任务分别放到双端队列里，然后几个启动线程分别从双端队列里获取任务执行。子任务执行完的结果都放在另外一个队列里，启动一个线程从队列里取数据，然后合并这些数据 HashMap和HashTable集合线程不安全: 多个线程操作同一个集合时，需要自己设置同步机制，否则会出现异常 HashMap是线程不安全的，多线程环境下可能会发生死锁。HashTable是线程安全的，因为它的每个方法都加入了synchronized方法。HashMap比HashTable执行效率高。当需要多线程的操作的时候，我们可以使用ConcurrentHashMap,多线程环境下ConcurrentHashMap比HashTable的执行效率高好几倍。因为ConcurrentHashMap使用了分段锁，并不对整个数据进行锁定。 HashTable键值对都不可以为空，否则会抛出空指针异常。，HashMap的键是可以为空的，但是只可以一个键为空。值也可以为null,所以我们不可以使用get()方法来判断是否map中有没有key,因为返回null并不意味着键不存在，有可能有键但是值为null。所以我们可以使用containsKey()方法来判断 继承的父类不同。 HashMap继承AbstractMap,而HashTable继承Dictionary类，由于Dictionary类已经被废弃，所以使用的不多了 初始容量不同和每次扩充容量不同HashTable的初始容量是11,而HashMap的初始容量是16。在创建时，如果给定了容量初始值，那么Hashtable会直接使用给定的大小，而HashMap则会将其扩充为2的幂次方大小。Hashtable会尽量使用素数、奇数。原因在于两种侧重面不同。HashTable更侧重于将结果分布均匀，是哈希冲突减少。HashMap使用位运算(&gt;&gt; &lt;&lt;)能够快速定位位置。但是Hash冲突也增加了。因为得出的hash值的低位相同的概率比较高，为了解决这个冲突，让取到的位置更分散，然后将得到的hashcode再进行了一次位处理。源码： 什么是装载因子？他有什么作用？1234/** * The load factor used when none specified in constructor. */ static final float DEFAULT_LOAD_FACTOR = 0.75f; 作用:就是控制什么时候map需要通过resize方法扩容，然后通过rehash方法把原有的元素复制到新的容器里面是否resize,由装载因子和初始容量决定的。 HashMap源码解读前面我们知道了装载因子(用来衡量HashMap满的程度)，那么HashMap如何计算呢size: 表示HashMap中所有的KV数量，包括链表和树的总和然后capacity表示顺序表的长度然后 size/capacity(初始大小为16，第二次要增加到64,以后每次翻2倍，所以都是2的幂次方)和装载因子比较，大于装载因子就进行resize操作，然后通过rehash方式把原有的元素复制到新的容器里面。threshold = 装载因子(LoadFactor)*capacity，就是说size的数量什么时候超过threshold就执行resize方法。那么什么时候会将链表树化呢？跟源码]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>HashMap底层原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入学习消息中间件 —— RabbitMQ]]></title>
    <url>%2F2019%2F03%2F13%2F%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6-%E2%80%94%E2%80%94-RabbitMQ%2F</url>
    <content type="text"><![CDATA[深入学习消息中间件 —— RabbitMQ消息丢失了怎么办？由于我比较了解RabbitMQ，所以我们以RabbitMQ为例子介绍消息丢失分为三个不同的丢失 生产者丢失问题 消息中间件丢失问题 消费者丢失问题 生产者端丢失（RabbitMQ）生产者生产的消息要发送到RabbitMQ,但是很容易数据在半路上弄丢，或者网络原因。所以如何保证消息可以安全送达到RabbitMQ呢解决方案有两个 1、开启RabbitMQ事务机制(同步)（RabbitMQ）我们可以使用channel.txSelect来开启事务，然后如果消息没有预期到达RabbitMQ,那么会执行事务回退channel.Rollback执行成功的话提交事务channel.txCommit。但是由于事务机制是同步的，会导致吞吐量减少，太耗费性能。 2、开启confirm模式(异步)（RabbitMQ）生产者生产的每一个消息都会有一个唯一的id,自身会在内存中维护这个id的状态信息，然后将消息写入RabbitMQ,如果RabbitMQ接受到消息，会回传一个ack消息,告诉生产者这个消息我已经接受到了，但是如果消息没有被RabbitMQ处理，那么会回传一个nack，如果你收到这个nack回传消息或者很久没有收到任何响应就利用内存维护的对应Id状态信息再次发送。 事务机制和confirm两个不同点（RabbitMQ）由于事务机制是同步的，即你提交一个事务之后会阻塞到那儿，但是confirm机制是异步的，消息发送出去之后，然后继续发送，然后RabbitMQ收到消息之后会异步回调给生产者一个接口来通知你消息收到了 RabbitMQ端丢失（RabbitMQ）我们解决的方案可以开启RabbitMQ持久化，就是将消息写入之后持久化到磁盘，就算某个时候RabbitMQ宕机了，恢复之后也会读取之前存储的数据。但是仍然也会有一种情况，消息存入到RabbitMQ，还没有来得及持久化，RabbitMQ就发生宕机了，从而导致数据丢失，那么如何解决呢？我们可以结合confirm机制，当生产者发送消息给RabbitMQ的时候，我们将数据存入并且持久化到磁盘时再回传ack，这样就可以解决上面的RabbitMQ还没有来得及持久化就宕机了。 消费者端丢失（RabbitMQ）情形：让消费者从RabbitMQ拿到数据之后，还没有来得及消费，自身就宕机了，可是RabbitMQ以为你已经消费了解决办法：使用由于RabbitMQ提供的ack机制。简单来说，就是必须关闭RabbitMQ的自动ack,可以通过一个api来调用就行，每次在代码中确认处理完成之后，自己添加ack，这样如果你没有处理完，就无法返回ack,那么RabbitMQ会认为你没没有处理，会把消息让别的消费者处理。 消息中间件的优缺点（RabbitMQ）优点（RabbitMQ）解耦合（RabbitMQ）加入B系统、C系统、D系统都使用A系统执行的结果，那么如何解决C宕机或者需要添加E系统调用，太麻烦了，耦合度太高，每次修改都需要更改原先的代码，所以我们可以使用消息中间件。把A返回的消息存储在消息中间件中，然后任何系统需要用，就去其中拿，不需要就不拿。 异步（RabbitMQ）加入用户写操作需要往A,B,C三个系统中写数据，但是A需要2ms,B需要200ms,C需要300ms，那么用户写一次数据需要502ms，那么用户可能会崩溃，一次操作需要等待那么久，所以我们可以让A执行操作后，把B、C操作放入到消息中间件中，然后再逐个从其中取出执行，那么用户就会感受到执行速度很快 削锋（RabbitMQ）一般系统的流量访问都是不均衡的，可能夜里访问人数就几十个，但是例如外卖互联网公司，饭点的时候系统的对数据的操作可能就比较繁重，用户请求大到几K，但是MySQL数据库的每秒的访问到达2k已经差不多了，所以超过这个数量之后，MySQL就会扛不住甚至崩溃，那么我们可以使用消息中间件，把数据库最大操作数量交由数据库处理，剩余的放在消息中间件，等待数据库处理完，我们可以继续从消息中间件取数据。从而解决了高并发下对数据库的压力 缺点（RabbitMQ）系统可用性降低（RabbitMQ）系统引入外面依赖越多，越容易挂掉。系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，人 ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整，MQ 一挂，整套系统崩溃的，你不就完了？如何保证消息队列的高可用 系统复杂度提高（RabbitMQ）硬生生加个 MQ 进来，你怎么[保证消息没有重复消费]？怎么[处理消息丢失的情况]？怎么保证消息传递的顺序性？这些问题都要去解决 一致性问题（RabbitMQ）A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了 如何保证消息的一致性（RabbitMQ）RabbitMQ假如我们把对于数据库的操作放进RabbitMQ,那么插入和删除的顺序必须和送入RabbitMQ的顺序一致，否则执行结果就不一样了，所以我们必要要保证一致性我们能不能这样解决，由于队列有序(先进先出)，就是当消费者消费消息，RabbitMQ等待消费者消费结束之后返回给RabbitMQ一个内容，然后再去执行下一个消息，显然这样不符合高并发下的生产条件，效率太低了。即 在MQ中创建多个queue,按照某一规则，有顺序的放进MQ的queue里面，然后消费者只取一个queue里面的数据消费。或者还是只有一个 queue 但是对应一个消费者，然后这个消费者内部用内存队列做排队，然后分发给底层不同的 worker 来处理。 消息中间件的高可用（RabbitMQ）RabbitMQ可以有三种模式 单机模式 普通集群模式 镜像集群模式(高可用) 镜像集群模式你创建的每个queue里面的消息或者元数据都会同步到其他的queue，对于每一个RabbitMQ节点，都有这个queue的一个完整镜像，包含queue的全部数据的意思。缺点： 性能开销太大，因为数据需要同步到各个RabbitMQ节点 不是分布式，没有可扩展性，如果queue负载过重，即使加机器，也是把所有的节点都复制到新的机器上，并没有办法扩展。 知识补记分布式和集群理解 理解 分布式 一个业务拆分为多个子业务，部署到多个服务器上 集群 同一个业务部署在多个服务器上 主从和集群的更新 更新 主从 服务器之间是异步的，从服务器可能和主服务器不一致 集群 更新是同步的，数据节点都是一致的]]></content>
      <categories>
        <category>消息中间件</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[多线程总结（二）]]></title>
    <url>%2F2019%2F03%2F12%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%80%BB%E7%BB%93%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[多线程总结(一)java多线程中的死锁、活锁、饥饿、无锁死锁死锁是多线程中最差的一种情况，多个线程相互占用对方的资源的锁，而又相互等对方释放锁，此时若无外力干预，这些线程则一直处理阻塞的假死状态，形成死锁 活锁活锁这个概念大家应该很少有人听说或理解它的概念，而在多线程中这确实存在。活锁恰恰与死锁相反，死锁是大家都拿不到资源都占用着对方的资源，而活锁是拿到资源却又相互释放不执行。当多线程中出现了相互谦让，都主动将资源释放给别的线程使用，这样这个资源在多个线程之间跳动而又得不到执行，这就是活锁。 饥饿我们知道多线程执行中有线程优先级这个东西，优先级高的线程能够插队并优先执行，这样如果优先级高的线程一直抢占优先级低线程的资源，导致低优先级线程无法得到执行，这就是饥饿。当然还有一种饥饿的情况，一个线程一直占着一个资源不放而导致其他线程得不到执行，与死锁不同的是饥饿在以后一段时间内还是能够得到执行的，如那个占用资源的线程结束了并释放了资源。 无锁无锁，即没有对资源进行锁定，即所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。无锁典型的特点就是一个修改操作在一个循环内进行，线程会不断的尝试修改共享资源，如果没有冲突就修改成功并退出否则就会继续下一次循环尝试。所以，如果有多个线程修改同一个值必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。之前的文章我介绍过JDK的CAS原理及应用即是无锁的实现 并发编程中的三个概念原子性原子性：即一个操作或多个操作要不 不执行且执行过程不会被任何外界因素所打断，要么不执行 可见性可见性指的是当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看到修改的值 有序性有序性指的是程序的执行的顺序按照代码的先后顺序执行。 什么是守护线程（Daemon）通俗的例子就是任何一个守护线程都是JVM中非守护线程的“保姆”只要当前JVM实例存在一个没有结束的非守护线程，那么守护线程就会全部运行。只有当最后一个非守护线程结束的时候，守护线程会随着JVM一起结束工作。 用户线程和线程区别几乎一样，唯一区别是，JVM的离开，如果用户进程全部退出了，那么守护进程和JVM一起结束，因为没有了守护者，守护进程就没有守护的进程的意义，所以没有继续运行的必要性了 典型的守护进程GC线程，只要有用户线程在，垃圾收集线程就不会退出。 注意点 设置setDaemon（true）必须在new Thread().start执行之前执行，普通线程不可以转换成守护线程 守护线程内部产生的新线程也是守护线程 并不是所有的应用都可以分配Daemon来守护，例如读写操作或计算逻辑 void setDaemon(boolean on) 标志着该线程是 守护线程或用户线程 on可以取true或者false 多线程下的异常如何处理异常不同处理的方式不同 非运行时异常(UnCheckedException)多线程中run方法不支持抛出,所以必须捕获处理 运行时异常（Runtime Exception）可以选择打印在控制台，或者设置UncaughtException异常处理器来自定义处理操作]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程总结(一)]]></title>
    <url>%2F2019%2F03%2F12%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%80%BB%E7%BB%93-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[多线程总结（一）多线程实现的五种方法1、使用Synchronized关键字修饰方法，java对象都有一个内置锁，当用此关键字修饰方法时，内置锁会保护整个方法。在调用该方法前，需要获得内置锁，否则就处于阻塞状态。2、 使用Synchronized静态代码块3、 使用局部变量方式ThreadLocal来创建一个static变量，多线程执行时会在自身工作区域创建局部变量副本4、 使用volatile来修饰共享变量，这样每次线程需要操作变量时，从主内存拿，而不是从操作自己的工作内存的那个副本5、 使用重入锁实现线程同步 死锁的产生是必须要满足一些特定条件1.互斥条件：进程对于所分配到的资源具有排它性，即一个资源只能被一个进程占用，直到被该进程释放2.请求和保持条件：一个进程因请求被占用资源而发生阻塞时，对已获得的资源保持不放。3.不剥夺条件：任何一个资源在没被该进程释放之前，任何其他进程都无法对他剥夺占用4.循环等待条件：当发生死锁时，所等待的进程必定会形成一个环路（类似于死循环），造成永久阻塞。 线程池的submit和execute方法区别虽然executor是线程池的顶层接口，但真正实现的接口却是：executorService submit有返回值，而execute没有用到返回值的例子，比如说我有很多个做validation的task，我希望所有的task执行完，然后每个task告诉我它的执行结果，是成功还是失败，如果是失败，原因是什么。然后我就可以把所有失败的原因综合起来发给调用者。个人觉得cancel execution这个用处不大，很少有需要去取消执行的。 ###submit方便Exception处理意思就是如果你在你的task里会抛出checked或者unchecked exception，而你又希望外面的调用者能够感知这些exception并做出及时的处理，那么就需要用到submit，通过捕获Future.get抛出的异常。 代码展示区别12345678910111213141516171819202122232425262728public class RunnableTestMain &#123; public static void main(String[] args) &#123; ExecutorService pool = Executors.newFixedThreadPool(2); /** * execute(Runnable x) 没有返回值。可以执行任务，但无法判断任务是否成功完成。 */ pool.execute(new RunnableTest("Task1")); /** * submit(Runnable x) 返回一个future。可以用这个future来判断任务是否成功完成。请看下面： */ Future future = pool.submit(new RunnableTest("Task2")); try &#123; if(future.get()==null)&#123;//如果Future's get返回null，任务完成 System.out.println("任务完成"); &#125; &#125; catch (InterruptedException e) &#123; &#125; catch (ExecutionException e) &#123; //否则我们可以看看任务失败的原因是什么 System.out.println(e.getCause().getMessage()); &#125; &#125;&#125; 实现一个多线程的类123456789101112131415public class RunnableTest implements Runnable &#123; private String taskName; public RunnableTest(final String taskName) &#123; this.taskName = taskName; &#125; @Override public void run() &#123; System.out.println("Inside "+taskName); throw new RuntimeException("RuntimeException from inside " + taskName); &#125;&#125; Java的CountDownLatch和CyclicBarrier的理解和区别CountDownLatch从字面上可以看CountDown表示减法计数，Latch表示门阀的意思，当什么时候计数变成0的时候，门阀打开表示主线程等其他所有线程执行完毕才开始执行，当计数为0的时候，下一步的动作实施者是main函数12345678910111213141516171819202122232425262728293031323334353637package com.nyist.thread;import java.util.Random;import java.util.concurrent.CountDownLatch;public class CountDownLatchDemo &#123; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch latch = new CountDownLatch(4); for(int i = 0; i &lt; latch.getCount();i++)&#123; new Thread(new MyThread(latch),"玩家"+i).start(); &#125; System.out.println("所有玩家都已经准备好"); latch.await(); System.out.println("开始游戏"); &#125; private static class MyThread implements Runnable&#123; private CountDownLatch latch; public MyThread(CountDownLatch latch) &#123; this.latch = latch; &#125; public void run() &#123; try &#123; int randowNum = new Random().nextInt(10) + 1000; Thread.sleep(randowNum); System.out.println(Thread.currentThread().getName()+"已经准备好，所用时间"+randowNum); latch.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; CyclicBarrier主线程不等待其他线程直接结束，而其他线程必须同时执行完一个任务去执行下一个任务之前等待其他线程执行完毕才可以执行下一个任务12345678910111213141516171819202122232425262728293031323334353637383940414243package com.nyist.thread;import java.util.Random;import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;public class CyclicBarrierDemo &#123; public static void main(String[] args) &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(4); for(int i = 0; i &lt; cyclicBarrier.getParties();i++)&#123; new Thread(new MyThread(cyclicBarrier),"玩家"+i).start(); &#125; System.out.println("游戏结束！"); &#125; private static class MyThread implements Runnable&#123; private CyclicBarrier cyclicBarrier; public MyThread(CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; for(int i = 0; i&lt; 3;i++)&#123; try &#123; int t1 = new Random().nextInt(1000) + 1000; Thread.sleep(t1); System.out.println(Thread.currentThread().getName()+"通过"+(i+1)+"个障碍，耗时"+t1+"毫秒"); cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; CountDownLatch和CyclicBarrier区别两个都有让多个线程等待同步之后再去执行下一步的意思！但是呢，CountDownLatch是主线程等待其他线程，而CyclicBarrier主线程早早结束，然后其他执行完毕的线程来等待还没有执行完成的线程，最后再一起进入下一步的执行过程！]]></content>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式集群下session共享解决方案]]></title>
    <url>%2F2019%2F03%2F12%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E4%B8%8Bsession%E5%85%B1%E4%BA%AB%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[分布式Session共享解决方案Session是服务器用来保存用户操作的一系列会话信息，由Web容器进行管理。单机情况下，不存在Session共享的情况，分布式情况下，如果不进行Session共享会出现请求落到不同机器要重复登录的情况，一般来说解决Session共享有以下几种方案。 session复制session复制是早期的企业级的使用比较多的一种服务器集群session管理机制。应用服务器开启web容器的session复制功能，在集群中的几台服务器之间同步session对象，使得每台服务器上都保存所有的session信息，这样任何一台宕机都不会导致session的数据丢失，服务器使用session时，直接从本地获取。 这种方式在应用集群达到数千台的时候，就会出现瓶颈，每台都需要备份session，出现内存不够用的情况。 session绑定利用hash算法，比如nginx的ip_hash,使得同一个Ip的请求分发到同一台服务器上。 这种方式不符合对系统的高可用要求，因为一旦某台服务器宕机，那么该机器上的session也就不复存在了，用户请求切换到其他机器后么有session，无法完成业务处理。 利用cookie记录sessionsession记录在客户端，每次请求服务器的时候，将session放在请求中发送给服务器，服务器处理完请求后再将修改后的session响应给客户端。这里的客户端就是cookie。 利用cookie记录session的也有缺点，比如受cookie大小的限制，能记录的信息有限；每次请求响应都需要传递cookie，影响性能，如果用户关闭cookie，访问就不正常。但是由于cookie的简单易用，可用性高，支持应用服务器的线性伸缩，而大部分要记录的session信息比较小，因此事实上，许多网站或多或少的在使用cookie记录session。 session服务器session服务器可以解决上面的所有的问题，利用独立部署的session服务器（集群）统一管理session，服务器每次读写session时，都访问session服务器。 这种解决方案事实上是应用服务器的状态分离，分为无状态的应用服务器和有状态的session服务器，然后针对这两种服务器的不同特性分别设计架构。 对于有状态的session服务器，一种比较简单的方法是利用分布式缓存（memcached), 数据库等。在这些产品的基础上进行包装，使其符合session的存储和访问要求。 如果业务场景对session管理有比较高的要求，比如利用session服务基层单点登录（sso),用户服务器等功能，需要开发专门的session服务管理平台。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>session共享解决方案</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四种线程池]]></title>
    <url>%2F2019%2F03%2F10%2F%E5%9B%9B%E7%A7%8D%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[四种线程池总结java的线程池是什么，有哪些类型，作用分别是什么线程池是一种多线程处理形式，处理过程中将任务添加队列，然后在创建线程后自动启动这些任务，每个线程都使用默认的堆栈大小，以默认的优先级运行，并处在多线程单元中，如果某个线程在托管代码中空闲，则线程池将插入另一个辅助线程来使所有处理器保持繁忙。如果所有线程池都始终保持繁忙，但队列中包含挂起的工作，则线程池将在一段时间后辅助线程的数目永远不会超过最大值。超过最大值的线程可以排队，但他们要等到其他线程完成后才能启动。 java里面的线程池的顶级接口是Executor，Executor并不是一个线程池，而只是一个执行线程的工具，而真正的线程池是ExecutorService。 java中的有哪些线程池1.newCachedThreadPool创建一个可缓存线程池 2.newFixedThreadPool 创建一个定长线程池 3.newScheduledThreadPool 创建一个定时或周期线程池 4.newSingleThreadExecutor 创建一个单线程化的线程池 分别解释四种线程池newCachedThreadPoolnewCachedThreadPool,是一种线程数量不定的线程池，并且其最大线程数为Integer.MAX_VALUE，这个数是很大的，一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。但是线程池中的空闲线程都有超时限制，这个超时时长是60秒，超过60秒闲置线程就会被回收。调用execute将重用以前构造的线程(如果线程可用)。这类线程池比较适合执行大量的耗时较少的任务，当整个线程池都处于闲置状态时，线程池中的线程都会超时被停止。12345678910111213141516171819202122232425262728public class PoolExecutorTest &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub ExecutorService mCachelThreadPool = Executors.newCachedThreadPool(); for(int i = 0;i &lt; 7;i++ ) &#123; final int index = i; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; mCachelThreadPool.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println("第" +index +"个线程" +Thread.currentThread().getName()); &#125; &#125;); &#125; &#125; &#125; 从结果可以看到，执行第二个任务的时候第一个任务已经完成，会复用执行第一个任务的线程，不用每次新建线程。 newFixedThreadPoolnewFixedThreadPool 创建一个指定工作线程数量的线程池，每当提交一个任务就创建一个工作线程，当线程 处于空闲状态时，它们并不会被回收，除非线程池被关闭了，如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到池队列（没有大小限制）中。由于newFixedThreadPool只有核心线程并且这些核心线程不会被回收，这样它更加快速的响应外界的请求。12345678910111213141516171819202122232425262728public class PoolExecutorTest &#123; public static void main(String[] args) throws InterruptedException &#123; // TODO Auto-generated method stub //设置最大线程数5个 ExecutorService mFixedThreadPool = Executors.newFixedThreadPool(5); for(int i = 0;i &lt; 7;i++ ) &#123; final int index = i; mFixedThreadPool.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println("时间是:"+System.currentTimeMillis()+"第" +index +"个线程" +Thread.currentThread().getName()); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; &#125; 由于设置最大线程是5，所以当执行完这5个线程后，等待两秒后，在执行后面2个线程 newScheduledThreadPoolnewScheduledThreadPool 创建一个线程池，它的核心线程数量是固定的，而非核心线程数是没有限制的，并且当非核心线程闲置时会被立即回收，它可安排给定延迟后运行命令或者定期地执行。这类线程池主要用于执行定时任务和具有固定周期的重复任务12345678910111213141516171819202122public class PoolExecutorTest &#123; public static void main(String[] args) throws InterruptedException &#123; // TODO Auto-generated method stub //设置池中核心数量是2 ScheduledExecutorService mScheduledThreadPool = Executors.newScheduledThreadPool(2); System.out.println("现在的时间:"+System.currentTimeMillis()); mScheduledThreadPool.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; // TODO Auto-generated method stub System.out.println("现在的时间:"+System.currentTimeMillis()); &#125; &#125;, 2, 3,TimeUnit.SECONDS);//这里设置延迟2秒后每3秒执行一次 &#125; &#125; 可发现确实延迟2秒后每隔3秒后就会执行一次，程序不退出就一直执行下去 newSingleThreadExecutornewSingleThreadExecutor这类线程池内部只有一个核心线程，以无界队列方式来执行该线程，这使得这些任务之间不需要处理线程同步的问题，它确保所有的任务都在同一个线程中按顺序中执行，并且可以在任意给定的时间不会有多个线程是活动的123456789101112131415161718192021222324252627public class PoolExecutorTest &#123; public static void main(String[] args) throws InterruptedException &#123; // TODO Auto-generated method stub ExecutorService mSingleThreadPool = Executors.newSingleThreadExecutor(); for(int i = 0;i &lt; 7;i++) &#123; final int number = i; mSingleThreadPool.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println("现在的时间:"+System.currentTimeMillis()+"第"+number+"个线程"); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; &#125; 可发现是有顺序地去执行上面6个线程 上面的总结来自于csdn,总结的比较好，拿来自己收藏保存，没有抄袭！]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL深入学习 —— 主从分离]]></title>
    <url>%2F2019%2F03%2F07%2FMySQL%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0-%E2%80%94%E2%80%94-%E4%B8%BB%E4%BB%8E%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[MySQL深入学习 —— 主从分离如何实现MySQL的读写分离基于主从复制架构，有一个主库，挂多个从库，然后我们写在主库，读在从库 MySQL主从复制原理主库将变更写入binlog日志中，然后从库连接主库之后，从库有一个IO线程，将主库的binlog日志拷贝到自己本地，然后写入一个叫做relay中继日志中，接着从库有一个SQL线程从中继日志中取出binlog日志内容，然后执行，相当于执行了一遍sql语句，这样就保证了自己和主库的数据是一致的。 注：主库是并行执行的，但是从库是串行化执行的，所以在高并发下，从库数据与主库数据同步会有延迟。 然后会衍生出来一个问题，如果主库执行后还没有来得及给从库，就发生宕机了，那么从库数据就得不到同步。所以有两种比较不错的解决方案1. 半同步复制即 一旦主库变更写入binlog日志中，就会强制此时立即将数据同步到从库，从库日志写入自己的relay中继日志中之后，接着会返回主库一个ack表示，主库收到至少一个ack标识，就认为写操作完成了。2. 并行复制从库开启多个线程，并行读取relay log中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。 延迟比较严重，有以下解决方案 分库： 将一个主库拆分为多个主库，然后这样就可以减少一个主库的并发，从而缓轻从库的主从复制压力 重写代码： 在执行写之后一段时间内，不进行读操作 并行： 打开从库的并行复制 设置直连主库 ，这样分离没有意义 说到这儿了，还没有说为什么要读写分离(主从复制)，接下来说说 什么时候使用读写分离其实就是将数据库分为主库和从库，主库用来读，从库用来读，然后主从进行数据同步。由于互联网的应用大部分都是读多写少，所以我们可以使用读写分离方式来解决数据库的写瓶颈。但是选择读写分离要面对一下几个问题 数据库连接池要进行区分，哪些是读连接池，哪些是写连接池，研发难度很大 要保持主从一致性 为了保证高可用，读连接池要能使用故障自动迁移。 所以我们完全可以使用缓存来解决这些问题的，但是必须实现高可用，否则集群挂掉，所有的访问压力全部集中于数据库，数据库会瘫痪。 数据库的瓶颈以及解决办法数据容量是瓶颈，例如订单表，数据量只增不减，历史数据又必须要留存，非常容易成为性能的瓶颈，而要解决这样的数据库瓶颈问题，“读写分离”和缓存往往都不合适，最适合的是什么呢？答案是数据切分 数据切分切分的目的在于减少数据库的负担，缩短查询时间！数据库分布式的核心就是数据切分，以及切分后对数据的定位、整合数据切分根据其切分类型，可以分为两种方式：垂直（纵向）切分和水平（横向）切分详细学习，比较难理解，后续继续学习！]]></content>
      <categories>
        <category>mysql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[XML初步总结]]></title>
    <url>%2F2019%2F03%2F03%2FXML%E5%88%9D%E6%AD%A5%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[XML可扩展标记语言，是一种标记语言非常灵活，没有固定的标签，所有的标签都是自定义！通常用于信息的记录和传递！ xml格式格式良好的xml文档 必须有xml声明语句 必须有且仅有一个根元素 标签大小写敏感 属性值用双引用 标签成对 元素正确嵌套 有效的XML文档 首先必须有良好的格式 使用DTD和XSD定义语义约束 注释写法1&lt;!--这是注释--&gt; 123456789101112131415&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;books&gt; &lt;book&gt; &lt;name&gt;十月围城&lt;/name&gt; &lt;price&gt;21&lt;/price&gt; &lt;/book&gt; &lt;book&gt; &lt;name&gt;李沫熙&lt;/name&gt; &lt;price&gt;22&lt;/price&gt; &lt;/book&gt; &lt;book&gt; &lt;name&gt;杨宁宁&lt;/name&gt; &lt;price&gt;11&lt;/price&gt; &lt;/book&gt;&lt;/books&gt; xml解析然后我们需要解析到xml标签中的数据我们可以使用以下四种方法来解析1、DOM解析；2、SAX解析；3、JDOM解析；4、DOM4J解析我们着重了解一下 SAX解析方式 我们定义的xml内容 123456789101112131415&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;books&gt; &lt;book&gt; &lt;name&gt;十月围城&lt;/name&gt; &lt;price&gt;21&lt;/price&gt; &lt;/book&gt; &lt;book&gt; &lt;name&gt;李沫熙&lt;/name&gt; &lt;price&gt;22&lt;/price&gt; &lt;/book&gt; &lt;book&gt; &lt;name&gt;杨宁宁&lt;/name&gt; &lt;price&gt;11&lt;/price&gt; &lt;/book&gt;&lt;/books&gt; 然后使用SAX解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package com.nyist.xml;import org.xml.sax.Attributes;import org.xml.sax.SAXException;import org.xml.sax.helpers.DefaultHandler;import javax.xml.parsers.ParserConfigurationException;import javax.xml.parsers.SAXParser;import javax.xml.parsers.SAXParserFactory;import java.io.IOException;import java.util.ArrayList;import java.util.List;/** * SAX解析 */public class Test1 &#123; public static void main(String[] args) throws ParserConfigurationException, SAXException, IOException &#123; //1.获取解析工厂 SAXParserFactory factory =SAXParserFactory.newInstance(); //2. 从解析工厂获取解析器 SAXParser parser = factory.newSAXParser(); //3.编写处理器 BookHandler handler = new BookHandler(); //开始解析 parser.parse(Thread.currentThread().getContextClassLoader().getResourceAsStream("test.xml"),handler); //获得解析的数据 List&lt;Book&gt; books = handler.getBooks(); //使用增强for循环遍历 for (Book book : books) &#123; System.out.println("书名:"+book.getName()+"--&gt;"+"价格:"+book.getPrice()); &#125; &#125;&#125;class BookHandler extends DefaultHandler&#123; private List&lt;Book&gt; books; private Book book; private String tag; @Override public void startDocument() throws SAXException &#123; books = new ArrayList&lt;&gt;(); &#125; @Override public void startElement(String uri, String localName, String qName, Attributes attributes) throws SAXException &#123; if(qName != null)&#123; if(qName.equals("book"))&#123; book = new Book(); &#125; tag = qName; &#125; &#125; @Override public void characters(char[] ch, int start, int length) throws SAXException &#123; String str = new String(ch, start, length).trim(); if(str.length() &gt; 0)&#123; if(tag.equals("name"))&#123; book.setName(str); &#125;else if(tag.equals("price"))&#123; book.setPrice(Integer.valueOf(str)); &#125; &#125; &#125; @Override public void endElement(String uri, String localName, String qName) throws SAXException &#123; if(qName != null)&#123; if(qName.equals("book"))&#123; books.add(book); &#125; &#125; qName = null; &#125; public List&lt;Book&gt; getBooks() &#123; return books; &#125;&#125; 于是我们可以从我们的xml得到数据]]></content>
      <categories>
        <category>XML</category>
      </categories>
      <tags>
        <tag>XML初步总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2F2019%2F03%2F02%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[#正则表达式正则表达式是一个独立的语言，不区别于语言 标准字符表示的意义 自定义符合集合[] 方括号表示匹配方式，能够匹配方括号中的任意一个字符其中[]小数点不用转义，但是呢 - d 等都要转义 贪婪模式 | 不贪婪模式{}符号可以表示匹配前一个字符的次数，例如\d{5}表示匹配5位，同样的也有\d{2,6}表示最少匹配2位，最多匹配6位，但是会默认贪婪模式，默认匹配6位！我们可以在对应的后面添加?表示开启不贪婪模式，默认匹配最少的！我们也可以使用\d{3,}匹配最少3位，最多没有限制！ 其他使用方法 \b表示前面的字符和后面的字符不全是\w，用于匹配一个单词边界！ 选择符和分组我们可以使用反向引用的方式实现对分组已经捕获的字符串进行引用。具体操作： 每一对()都分配一个编号，具体顺序以左侧符号出现顺序为准，从1开始编号！ 预搜索只对子表达式进行匹配，匹配后的内容不计入最终的结果！是对位置的匹配！ 常用正则表达式亲测有效]]></content>
      <categories>
        <category>正则表达式</category>
      </categories>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式漏洞]]></title>
    <url>%2F2019%2F03%2F02%2F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E6%BC%8F%E6%B4%9E%2F</url>
    <content type="text"><![CDATA[单例模式的漏洞我们实现单例模式可以有5种实现方式，分别是 懒汉式、饿汉式、双重锁模式、枚举模式、静态内部类模式，但是呢，由于双重锁和JMM结构不一致吗，一般不推荐使用，但是其他的除了枚举模式以外，其他的都可被攻破！ 反射攻击模式1234567//1.通过反射攻破单例模式 Class&lt;SingletonDemo2&gt; clazz = (Class&lt;SingletonDemo2&gt;) Class.forName("com.nyist.singleton.SingletonDemo2"); Constructor constructor = clazz.getDeclaredConstructor(null); constructor.setAccessible(true); SingletonDemo2 singletonDemo21 = clazz.newInstance(); SingletonDemo2 singletonDemo22 = clazz.newInstance(); System.out.println(singletonDemo21 == singletonDemo22); 最后打印出的结果是false。也就是创建了不同的对象，即打破了单例模式。那么如何补救呢，可以这样，构建方法内判断对象存在后再决定是否创建 1234567891011121314public class SingletonDemo1 &#123; private static SingletonDemo1 demo1 = new SingletonDemo1(); //类初始化的时候，立刻加载对象 private SingletonDemo1() &#123; if(demo1 == null)&#123; demo1 = new SingletonDemo1(); &#125; &#125; public static SingletonDemo1 getInstance()&#123; return demo1; &#125;&#125; 序列化反序列化方式我们可以结合对象字节流的操作，将字节流先存储在文件中，然后读取，会创建一个不一样的对象12345678910111213141516171819202122232425262728//2.通过序列化攻破单例模式 FileOutputStream fileOutputStream = null; ObjectOutputStream objectOutputStream = null; ObjectInputStream objectInputStream = null; FileInputStream fileInputStream = null; try &#123; SingletonDemo2 singletonDemo2 = SingletonDemo2.getInstance(); System.out.println("开始"); System.out.println(singletonDemo2); fileOutputStream = new FileOutputStream("D:/test.txt"); objectOutputStream = new ObjectOutputStream(fileOutputStream); objectOutputStream.writeObject(singletonDemo2); fileInputStream = new FileInputStream("D:/test.txt"); objectInputStream = new ObjectInputStream(fileInputStream); SingletonDemo2 demo2 = (SingletonDemo2) objectInputStream.readObject(); System.out.println("结束"); System.out.println(demo2); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; fileInputStream.close(); objectInputStream.close(); objectOutputStream.close(); fileOutputStream.close(); &#125; 结果demo2和singletonDemo2的地址不相同，表示没有遵守单例模式我们如何避免呢在相应的类中加上此方法即可以后学习中，继续总结，走起…]]></content>
      <categories>
        <category>面试总结</category>
      </categories>
      <tags>
        <tag>单例漏洞和补修</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试总结(One)]]></title>
    <url>%2F2019%2F03%2F02%2F%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93-One%2F</url>
    <content type="text"><![CDATA[笔试总结(One)面向对象的五大基本原则 单一职责原则（SRP）一个类，最好只做一件事，只有一个引起它的变化。单一职责原则可以看做是低耦合、高内聚在面向对象原则上的引申，将职责定义为引起变化的原因，以提高内聚性来减少引起变化的原因。 开放封闭原则（OCP）软件实体应该是可扩展的，而不可修改的。也就是，对扩展开放，对修改封闭的 里氏替换原则（LSP）子类必须能够替换其基类。这一思想体现为对继承机制的约束规范，只有子类能够替换基类时，才能保证系统在运行期内识别子类，这是保证继承复用的基础。 依赖倒置原则（DIP）依赖于抽象。具体而言就是高层模块不依赖于底层模块，二者都同依赖于抽象；抽象不依赖于具体，具体依赖于抽象。 接口隔离原则（ISP）使用多个小的专门的接口，而不要使用一个大的总接口 单例模式饿汉式加载12345678910111213141516171819package com.nyist.singleton;/** * 饿汉式单例模式 * 线程安全 */public class SingletonDemo1 &#123; private static SingletonDemo1 demo1 = new SingletonDemo1(); //类初始化的时候，立刻加载对象 private SingletonDemo1() &#123; &#125; public static SingletonDemo1 getInstance()&#123; return demo1; &#125;&#125; 懒汉式什么时候需要什么时候加载1234567891011121314151617181920package com.nyist.singleton;/** * 懒汉式 */public class SingletonDemo2 &#123; private static SingletonDemo2 s; private SingletonDemo2()&#123; &#125; public static synchronized SingletonDemo2 getInstance()&#123; if(s == null)&#123; s = new SingletonDemo2(); &#125; return s; &#125;&#125; 静态内部类实现方式1234567891011121314151617package com.nyist.singleton;//静态内部类实现方式(也是一种懒加载的方式)public class SingletonDemo3 &#123; private static class SingletonClassInstance&#123; private static final SingletonDemo3 singletonDemo3 = new SingletonDemo3(); &#125; private SingletonDemo3() &#123; &#125; public SingletonDemo3 getInstance()&#123; return SingletonClassInstance.singletonDemo3; &#125;&#125; 枚举方式(没有懒加载的功能)12345678910111213141516package com.nyist.singleton;public enum SingletonDemo4 &#123; //枚举类型 本身就是单例模式 Instance; //添加自己所需要的操作 public void test()&#123; &#125; public static void main(String[] args) &#123; System.out.println(SingletonDemo4.Instance == SingletonDemo4.Instance);//结果为true &#125;&#125;]]></content>
      <categories>
        <category>面试总结</category>
      </categories>
      <tags>
        <tag>单例模式</tag>
        <tag>面向对象的五大基本原则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CDN]]></title>
    <url>%2F2019%2F02%2F17%2FCDN%2F</url>
    <content type="text"><![CDATA[CDN学习CDN介绍CDN也就是内容分布网络(Content Delivery Network)，它是构筑在现有Internet上的一种先进的流量分配网络。其目的是通过在现有的Internet中增加一层新的网络架构，将网站的内容发布到最接近用户的网络“边缘”，使用户可以就近取得所需的内容，提高用户访问网站的响应速度。有别于镜像，它比镜像更智能，可以做这样一个比喻:CDN=镜像(Mirror)+缓存(Cache)+整体负载均衡(GSLB)。因而，CDN可以明显提高Internet中信息流动的效率。 目前CDN都以缓存网站中的静态数据为主，如CSS、JS、图片和静态页面等数据。用户在从主站服务器请求到动态内容后，再从CDN上下载这些静态数据，从而加速网页数据内容的下载速度，如淘宝有90%以上的数据都是由CDN来提供的。 通常来说CDN要达到以下几个目标： 可扩展(Scalability)。性能可扩展性:应对新增的大量数据、用户和事务的扩展能力。成本可扩展性:用低廉的运营成本提供动态的服务能力和高质量的内容分发。 安全性( Security)。 强调提供物理设备、网络、软件、数据和服务过程的安全性，(趋势)减少因为DDoS攻击或者其他恶意行为造成商业网站的业务中断。: 可靠性、 响应和执行(Reliability、 Responsiveness 和Performance)。服务可用性指能够处理可能的故障和用户体验下降的问题，通过负载均衡及时提供网络的容错机制。 CDN架构这个流程其中包括了DNS域名解析的过程，通常是首先去Local DNS Server 请求，如果本地有ip对应的域名缓存，则直接获得对应的IP,但是如果本地没有缓存，那么就去Root DNS Server请求，然后返回一个对应域名的服务器地址，然后再向域名服务器(Name Server)发起请求,然后域名服务器返回对应的IP，这样用户就可以通过域名解析到对应的ip。]]></content>
      <categories>
        <category>CDN</category>
      </categories>
      <tags>
        <tag>CDN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM垃圾收集器]]></title>
    <url>%2F2019%2F02%2F13%2FJVM%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2F</url>
    <content type="text"><![CDATA[JVM垃圾收集器jdk1.7之后HotSpot虚拟机中提供了商用的G1收集器，之前都是实验状态 垃圾回收中的并发编程中的概念并发：用户线程和垃圾收集线程同时进行，用户进程在继续进行，而垃圾回收线程运行于另外一个CPU并行：指的是多条垃圾收集线程同时工作，但是用户线程在等待 Serial收集器这个收集器最大点特点除了是通过一个cpu或一条收集线程完成垃圾收集工作以外，还必须暂停掉其他所有工作的线程直至它收集完成由于单线程的运行机制，简单高效。在限定的单cpu的环境中，没有线程交互的开销，专心做垃圾回收工作，可以获得单线程环境下最高的收集效率虽然上特点会让我们觉着会被舍弃这个收集器，但是目前依然是虚拟机在client默认的新生代垃圾收集器 Serial为什么要用作client端的新生代收集器？原因：在用户的桌面应用中，一般分配给虚拟机的内存一般不会很大，收集几十兆甚至几百兆的内存，收集时间可以在几十毫秒或者几百毫秒之内，只要不频繁发生，这点停顿是可以接受的ParNew收集器是多线程版本的Serial，在Server中默认的新生代垃圾收集器。目前也只有它可以和CMS收集器配合工作。CMS垃圾回收器是 唯一 一个可以并发的垃圾收集器。用户线程可以和垃圾回收线程同时工作，CMS作为老年代垃圾收集器 Parallel Scavenge收集器新生代收集算法，使用复制算法的收集器它和其他的收集器关注点不同，cms等收集器关注点在于尽可能短的缩短停顿的时间，而Parallel Scavenge收集器是达到一个可控制的吞吐量(吞吐量 = 执行用户代码的时间/(运行用户代码时间+垃圾收集时间))，高吞吐量可以高效的使用利用CPU时间，完成计算任务，一般使用于后台计算而不需要太多交互的任务。对于尽可能减少停顿时间的收集器来说，更适合用做用户交互的任务，有很好的交互体验。由于与吞吐量关系密切，ParallelScavenge收集器也经常称为“吞吐量优先”收集器。除上述两个参数之外，Parallel Scavenge收集器还有一个参数-XX:+UseAdaptiveSizePolicy值得关注。这是一个开关参数，当这个参数打开之后，就不需要手工指定新生代的大小(-Xmn)、Eden 与Survivor区的比例(-XX:SurvivorRatio)、 晋升老年代对象年龄(XX:PretenureSizeThreshold)等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为GC自适应的调节策略(GC Ergonomics)。对于收集器运作原来不太了解，手工优化存在困难的时候，使用ParallelScavenge收集器配合自适应调节策略，把内存管理的调优任务交给虚拟机去完成将是一个不错的选择。只需要把基本的内存数据设置好(如-Xmx设置最大堆)，然后使用MaxGCPauseMillis参数( 更关注最大停顿时间)或GCTimeRatio(更关注吞吐量)参数给虚拟机设立一个优化目标，那具体细节参数的调节工作就由虚拟机完成了。 自适应调节策略也是ParallelScavenge收集器与ParNew收集器的一个重要区别。 Serial Old收集器Serial Old是Serial老年代版本，也同样是单线程收集器，使用”标记—整理”算法。这个收集器的主要意思在于在client下使用。如果使用在Server中，主要有两种用途。一中是在JDK1.5之前和ParallelScavenge搭配使用，另一种是作为cms的后备预案。 Parallel Old 收集器Parallel Old是ParallelScavenge收集器老年代的版本，使用多线程和”标记—整理”算法。 cms收集器老年代垃圾收集器，采用的是”标记—清除”算法，也被成为”并发低停顿收集器”CMS (Concurrent Mark Sweep)收集器是一种以获取最矩回收停顿时间为8标的收集器。目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上,这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用护带来较好的体验。CMS收集器就非常符合这类应用的需求。从名字(包含“Mark Sweep”)上就可以看出，CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几种收集器来说更复杂- - 些，整个过程分为4个步骤，包括: 初始标记(EMS initial mark) 并发标记(CMS concurrent mark ) 重新标记(CMS remark ) 并发清除(CMS concurrent sweep ) 其中，初始标记、重新标记这两个步骤仍然简要“Stop The World”.初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行Gc RootsTracing的过程，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。 G1收集器是一款面向服务端的一款垃圾收集器 G1的优点： 并行与并发: G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU (CPU 或者CPU核心)来缩短Stop-The-WorId停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行 分代收集:与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次GC的旧对象以获取更好的收集效果。 空间整合:与CMS的“标记一清理”算法不同，G1从整体来看是基于“标记一整理”算法实现的收集器，从局部(两个Region之间)上来看是基于“复制”算法实现的,但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。 可预测的停顿:这是G1相对于CMS的另一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java (RTSJ)的垃圾收集器的特征了。 在G1之前的收集器都是将JAVA堆区域分成新生代和老年代，但是G1虽然保留这两个概念，但是G1是把Java堆划分为多个大小相等的独立区域。它们不再是物理的隔离，它们都是一部分Region(不需要连续)的集合！ G1中的Region之间的对象引用以及其他收集器中的新生代和老年代的对象间对象引用，在做可达性分析对象是否存活时，需要判断，岂不是要扫描整个Java堆才可以保证准确性。但是，sun公司带来的解决方案是：虚拟机使用Remembered Set来避免全堆扫描的。虚拟机中每一个Region中都有一个Remembered Set，虚拟机发现程序在对Reference类型的数据进行写操作的时候，会产生一个Write Barrier暂停中断操作，检查Reference引用的对象是否存在同一个Region,如果是，便通过CardTable把相关引用信息记录到引用对象所在的Region对应的Rememberd Set之中。当进行垃圾回收时，在GC根节点的枚举范围中加入Rememberd Set 即可保证不对全栈扫描依然不会有遗漏！ 总结通过学习垃圾收集器的具体实现，然后结合之前的垃圾收集的四大方向，理清了JVM虚拟机HotSpot的垃圾收集机制！收益颇多！继续学习。。。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java底层知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HotSpot算法实现]]></title>
    <url>%2F2019%2F01%2F21%2FHotSpot%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[HotSpot算法实现枚举根节点在可达性分析中从GC Roots节点找引用链，可以作为GC Roots的节点主要在全局性引用(例如 常量或静态属性)与执行上下文（例如堆帧中的本地变量表）中，现在很多应用仅仅方法区就有数百兆，如果逐个检查这里面的引用，必然会消耗很多时间。 另一个对时间影响的是GC停顿，因为执行期间必须保证在一致性的快照中进行，意思是整个分析期间整个执行系统看起来好像就冻结在某个时间点，不可以出现分析对象引用关系还在不断变化的情况，如果这点不满足的话会出现结果准确性无法得到保障。这就是导致GC进行时必须停顿所有Java执行程序中最重要的一个原因。 目前主流的Java虚拟机，都是准确性GC，当执行系统停顿下来的时候，并不需要一个不漏的检查完所有执行上下文和全局的引用位置，虚拟机应当知道哪些地方存放着对象引用。在HotSpot实现中，是使用一组成为OopMap的数据结构来达到这个目的 的，这样在GC扫描时就会得知这些信息了。 安全点在OopMap的协助下，HotSpot可以快速且准确地完成GC Roots枚举，但一很现实问题随之而来。可能导致引用关系变化，或者OopMap内容变化的指令非常多，如果为每一条指令都生成对应的OopMap,那将会需要大量的额外空间，这样GC的空间成本将会变得很高，实际上HotSpot 也的确没有为每条指令都生成OopMap，只是在“特定的位置”记录了这些信息，这些位置称为安全点(Safepoint),即程序执行时并非在所有地方都能停顿下来开始GC,只有在到达安全点时才能暂停。Safepoint的选定既不能太少以致于让GC等待时间太长，也不能过于频繁以致于过分增大运行时的负荷。所以，安全点的选定基本上是以程序“是否具有让程序长时间执行的特征”为标准进行选定的，因为每条指令执行的时间都非常短暂程序不太可能因为指令流长度太长这个原因而过长时间运行，“长时间执行”的最明显特征就是指令序列复用，例如方法调用、循环跳转、异常跳转等，所以具有这些功能的指令才会产生Safepoint. 对于Sefepoint;另一个需要考虑的问题是如何在GC发生时让所有线程(这里不包括执行JNI调用的线程)都“跑”到最近的安全点上再停顿来。这里有两种方案可供选择:抢先式中断(Preemptive Suspension) 和主动式中断(Voluntary Suspension)，其中抢先式中断不需要线程的执行代码主动去配合，在GC发生时，首先把所有线程全部中断，如果发现有线程中断的地方不在安全点上，就恢复线程，让它“跑”到安全点上。现在几乎没有虚拟机实现采用抢先式中断来暂停线程从而影响GC事件。 而主动式中断指的是当GC需要中断线程的时候，不需要直接对线程操作，仅仅简单的设置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时，就自己中断挂起。轮询标志的地方和安全点是重合的，另外加上创建对象需要分配的地方。 安全区域使用Safepoint似乎已经完美地解决了如何进人GC的问题，但实际情况却并不一定。Safepoint机制保证了程序执行时，在不太长的时间内就会遇到可进人GC的Safepoint。但是，程序“不执行”的时候呢?所谓的程序不执行就是没有分配CPU时间，典型的例子就是线程处于Sleep状态或者Blocked状态，这时候线程无法响应JVM的中断请求，“走”到安全的地方去中断挂起，JVM也显然不太可能等待线程重新被分配CPU时间。对于这种情况，就需要安全区域( Safe Region)来解决。 安全区域是指在一段代码片段之中，引用关系不会发生变化。在这个区域中的任意地方开始GC都是安全的，我们也可以把SafeRegion看做是被扩展了的Safepoint。在线程执行到Safe Region 中的代码时，首先标识自己已经进人了Safe Region,那样，当在这段时间里JVM要发起GC时，就不用管标识自己为SafeRegion状态的线程了。在线程要离开Safe Region时，它要检查系统是否已经完成了根节点枚举(或者是整个GC过程)，如果完成了，那线程就继续执行，否则它就必须等待直到收到可以安全离开Safe Region的信号为止。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java底层知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM垃圾收集算法]]></title>
    <url>%2F2019%2F01%2F19%2FJVM%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[JVM垃圾收集算法各个平台的虚拟机操作内存的方法各不相同，因此我们只讨论几种算法的思想以及发展过程。 标记—清除算法 最基础的收集算法是“标记-清除”(Mark-Sweep)算法，如同它的名字一样，算法分为“标记”和“清除”两个阶段:首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象，它的标记过程就是引用计数算法。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。它的主要不足有两个:一个是效率问题，标记和清除两个过程的效率都不高;另一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作 复制算法 为了解决效率问题，一种称为“复制”(Copying)的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半，未免太高了一点。 注意：由于新生代的对象98%是”朝生夕死”的，所以我们并不需要按照1:1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中的一块Survivor。当回收时，将Eden和Survivor中还存活的对象一次性的复制到另一块Survivor的空间上，最后清理掉Eden和刚才用过的Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也就是每次新生代中可用内存空间是整个新生代容量的90%(80%+10%),只有10%的内存会被“浪费”。当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收只有不多余10%的对象存活，当Survivor空间不够用的时候，需要依赖其他内存(老年代)进行分配担保。 标记—整理算法 复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。根据老年代的特点，有人提出了另外一种“标记-整理”(Mark-Compact)算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存 分代收集算法分代收集并没有什么新的思想，只是根据对象存活周期不同将内存分为几块。一般Java堆分为新生代和老年代，这样就可以根据各个年代的特点来采用最合适的收集算法。在新生代中，每次垃圾收集时都会发现大批对象死去，只有少量存活，那就采用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外的空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来实现回收。 总结当我深入了解Java虚拟机的时候，才会知道原来我们平时Java虚拟机的GC垃圾回收原来是这么自动回收的，很震撼，也会为以后出现GC机制没有回收一些内存而造成内存溢出寻找原因打下基础]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm底层学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaWeb基础]]></title>
    <url>%2F2019%2F01%2F17%2FJavaWeb%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[JavaWeb基础JDBC技术JDBC操作数据库流程 Class.forName()加载数据库连接驱动 DriverManager.getConnection()获取数据库连接对象 根据SQL获取sql会话对象，有两种方式Statement、PreparedStatement 执行SQL处理结果集，执行SQL前如果有参数值就设置参数值 关闭结果集、关闭会话、关闭连接 关于使用PreparedStatement不使用Statement的原因 PreparedStatement继承自Statement，PreparedStatement实例包含已编译的SQL语句，因此执行速度快 PreparedStatement三个方法execute、executeQuery、executeUpdate已经更改为不再需要参数 PreparedStatement不需要不断的拼接，但是Statement需要 PreparedStatement传入的内容不会和sql语句发生任何的匹配关系，但Statement容易被SQL注入 关系数据库中连接池的机制是：前提：为数据库连接建立一个缓冲池 从连接池获取或者创建一个可用连接 使用完毕后，把连接返回给连接池 在系统关闭前，断开所有连接并释放连接占用的系统资源 能够处理无效连接，限制连接池中的连接总数不低于或者不超过某个限定值 注：数据库连接池数量一直保持一个最小连接数的数量，当数量不够时，数据库会创建一些连接，直到一个最大连接数，之后的数据库连接就会等待。 Http的长连接和短连接Http协议有HTTP/1.0版本和HTTP/1.1版本。HTTP/1.1默认保持长连接，数据传输完成完成了依然保持TCP连接不断开，等待同域名下继续使用这个通道传输数据。HTTP/1.0默认是短连接，浏览器和服务器每一次进行HTTP操作，就建立一次连接，任务结束就中断连接。 Cookie和SessionCookie和Session的区别：Cookie是web服务器发送给浏览器的一块信息，浏览器会在本地一个文件中给每个web服务器存储cookie。以后浏览器再给特定的web服务器发送请求时，同时会发送所有为该服务器存储的cookie。Session是存储在web服务器端的一块信息。session对象存储特定的用户会话所需的属性以及配置信息。当用户在应用程序的web页之间跳转时，存储在Session对象中的变量将不会丢失，而是在整个会话中一直存在下去。 Cookie和Session的不同点： 无论客户端做怎样的配置，session都能正常工作。当客户端禁用cookie时将无法使用cookie 存储方面，session可以存储任何的java对象，cookie只能存储String类型的对象 关于Session在集群和分布式中的共享问题我们可以使用服务器session复制共享，但是session广播通知其他session会造成网络流量瓶颈，同时session中的内容序列化也会消耗系统性能，所以最好使用接触redis实现session共享：原理： 当服务器发现session不在本机内存中，则会去redis中查找，如果redis查到，会复制到本机。这样就可以实现session同步和高可用！有时候我们可能担心redis宕机，所以我们要使用一主多备，由于redis宕机后不会自动切换master，所以需要结合keepalived来实现切换问题！ 单点登录原理后端生成一个session ID,然后设置到cookie，后面的所有请求 浏览器都会带上cookie，然后服务器端从cookie里面获取sessionID,再查找用户信息。所以，保持登录的关键不是cookie,而是通过cookie保存和传输的sessionID,其本质是能获取用户信息的数据。除了cookie,还通常使用HTTP请求头来传输。但是这个请求头浏览器不会像cookie一样自动携带，需要手工处理。 JSP技术Jsp本质上就是一个Servlet，它是Servlet的一种特殊形式，每个jsp页面都是一个Servlet实例。Servlet是由java提供用于开发web服务器应用程序的一个组件，运行在服务端，由servlet容器管理，用来生成动态内容。一个servlet实例是实现了特殊接口Servlet的Java类，所有自定义的servlet均必须实现Servlet接口。 jsp servlet对比：jsp是html页面中内嵌的Java代码，侧重页面显示Servlet是html代码和java代码分离，侧重逻辑控制，mvc设计思想中jsp位于视图层，servlet位于控制层 JVM只能识别java类，并不能识别jsp代码！web容器收到以.jsp为扩展名的url请求时，会将访问请求交给tomcat中jsp引擎处理，每个jsp页面第一次被访问时，jsp引擎将jsp代码解释为一个servlet源程序接着编译成servlet源程序生成.class文件，再由web容器servlet引擎去装载执行servlet程序，实现页面交互。 jsp域对象一个4个域对象 pageContext 指当前页面，在当前jsp页面有效，跳转到其他页面失效 request request域指的是在一次请求范围内有效，从http请求到服务器处理结束，返回响应的整个过程。 session session域指的是当前会话有效范围，浏览器从打开到关闭的过程中，转发、重定向均可以使用。 application context域指的是能在同一个web中使用，服务器未关闭或者重启，数据有效。 XML技术复习xml是一种可扩展性标记语言，支持自定义标签(使用前必须预定义)使用DTD和XML Schema标准化XML结构优点：用于配置文件，格式统一，符合标准；用于在互不兼容的系统间交互数据，共享数据方便。缺点：xml文件格式复杂，数据传输占流量，服务端和客户端解析xml文件占用大量资源且不易维护xml常用解析器有两种： DOM解析，xml文档以DOM树形结构加载入内存 SAX解析，采用事件模型]]></content>
      <categories>
        <category>JavaWeb</category>
      </categories>
      <tags>
        <tag>JavaWeb基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存]]></title>
    <url>%2F2019%2F01%2F16%2FJVM%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[JVM内存内存泄露:是指程序中己动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。 GC机制既然java有垃圾回收(GC)机制，理论上不应该有内存泄露的问题，然而总会有无用但可达的对象，这些对象不能被GC回收，因此也会导致内存泄露的发生。例如： hibernate的Session(一级缓存)中的对象属于持久态，垃圾回收器是不会回收这些对象的，然而这些对象可能存在无用的垃圾对象，如果不及时关闭或者清空一级缓存可能会导致内存泄露 注：栈的pop方法调用，即使栈的程序不再引用这些对象，因为栈内部维护着这些对象的过期引用，所以该不会被当做垃圾回收。这种内存泄露是隐蔽的，垃圾回收机制同时也不会回收内存泄露对象所引用的对象。因此会导致很多对象都排除在垃圾回收之外，从而对性能产生重大的影响 Java中为什么要有GC机制 安全性考虑 减少内存泄露 减少程序员的工作量 Java的GC需要回收那些缓存内存运行时，JVM会有一个运行时数据区来管理内存，包括: 程序计数器 虚拟机栈 本地方法栈 方法区 堆 程序计数器、虚拟机栈、本地方法栈都是每个线程私有的内存空间，随着线程而生，随线程而死。这三个区域的内存分配和回收都是确定的，无序考虑回收的问题，但是方法区和堆就不同了，一个接口的多个实现类需要的内存可能不一样。我们只有在程序运行期间才会知道会创建哪些对象，这部分内存的分配和回收都是动态的，GC主要关注的就是这部分内存 内存溢出的原因很多，简单举几个： 内存中加载的数据量过于庞大，如一次从数据库中取出过多数据 集合类中有对对象的引用，使用完没有情况，使JVM不能回收 代码中存在死循环或者代码中产生过多重复的对象实体]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm底层学习</tag>
        <tag>java底层知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程复习知识点总结]]></title>
    <url>%2F2019%2F01%2F16%2F%E7%BA%BF%E7%A8%8B%E5%A4%8D%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[线程复习知识点总结并行： 指的是多个线程同时运行(多核CPU)并发: 借助CPU的高速运转，只不过切换时间极短，用户察觉不到，这也是多线程运行的原因 JVM启动也是属于多线程的，在运行主线程的同时，与之切换运行的至少也有垃圾回收线程在JAVA实现多线程的两种方法 继承Thread: 由于子类重写了Thread类的run(),当调用start()时，直接去找子类的run()方法 实现Runnable: 构造函数中传入Runnable的引用，成员变量记住了它，start()调用run()方法内部判断成员变量Runable的引用是否为空，不为空编译时看的是Runnable的run(),运行时执行子类的run方法 Thread的方法： Thread.currentThread().getName();获取当前线程然后再获取到线程的名字join():当前线程停止，然后等待其他线程执行结束后，再恢复运行状态(应该抛出中断异常)yield: 让出cpu执行权给其他线程（Thread.yield()）setPriority(): 设置优先级，默认是5,值范围在0-10之间代码块加锁的时候，不能用匿名对象，否则synchronized不起作用非静态的同步方法的锁对象是this静态的同步锁对象是字节码对象 同步代码块嵌套会导致死锁StringBuffer适用于多线程下在字符缓冲区进行大量操作的情况,它是线程安全的StringBuilder适用于单线程下在字符缓冲区进行大量操作的情况，他是线程不安全的String是适用于少量的字符串操作的情况 单例设计模式（保证类在内存中只有一个对象） 线程的生命周期 新建、就绪、阻塞、运行、死亡]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>线程学习总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WEB安全学习总结]]></title>
    <url>%2F2019%2F01%2F16%2FWEB%E5%AE%89%E5%85%A8%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[WEB安全黑客攻击过去大部分都是直接对服务器进行溢出攻击的方式，或者是端口扫描WEB强大的四个原因： 数据库，编程语言，web容器，优秀的程序设计者 攻击者入侵服务器最有可能从以下这几点入手： 攻击者在渗透服务器时，直接对目标下手- -般有三种手段，当我们了解了攻击者的手段之后，防御也就变得简单了。 C段渗透:攻击者通过渗透同一网段内的一台主机对目标主机进行ARP等手段的渗透。 社会工程学:社会工程学是高端攻击者必须掌握的一 -个技能，渗透服务器有时不仅仅只靠技术。 Services:很多传统的攻击方式是直接针对服务进行溢出的，至今一些软件仍然存在溢出漏洞。像之前的MySQL就出现过缓冲区溢出漏洞。当然，对这类服务还有其他入侵方式，这些方式也经常用于内网的渗透中 Http响应码Http协议中的状态码有三个数字组成： 第一位数字定义了响应的类别，且只有以下5种。 1xx:信息提示，表示请求已被成功接收，继续处理。其范围为100~ 101。 2xx: 成功，服务器成功地处理了请求。其范围为200~ 206。 3xx:重定向，重定向状态码用于告诉浏览器客户端，它们访问的资源已被移动，并告诉客户端新的资源地址位置。这时，浏览器将重新对新资源发起请求。其范围为300~305。 4xx:客户端错误状态码，有时客户端会发送一些服务器无法处理的东西，比如格式错误的请求，或者最常见的是，请求一个不存在的URL。其范围为400~415。 5xx:有时候客户端发送了一.条有效请求，但Web服务器自身却出错了，可能是Web服务器运行出错了，或者网站都挂了。5XX就是用来描述服务器内部错误的，其范围为500~ 505。 常见的状态码描述如下200:客户端请求成功，是最常见的状态。302:重定向。 404:请求资源不存在，是最常见的状态。 400:客户端请求有语法错误，不能被服务器所理解。 401:请求未经授权。 403:服务器收到请求，但是拒绝提供服务。500:服务器内部错误，是最常见的状态。 503:服务器当前不能处理客户端的请求，一段时间后可能恢复正常 Https和Http HTTPS协议的全称为Hypetext Transfer Protocol over Secure Socket Layer,它是以安全为目标的HTTP通道，其实就是HTTP的“升级”版本，只是它比单纯的HTTP协议更加安全。 HTTPS的安全基础是SSL,即在HTTP下加入SSL层。也就是HTTPS通过安全传输机制进行传送数据，这种机制可保护网络传送的所有数据的隐秘性与完整性，可以降低非侵入性拦截攻击的可能性。 既然是在HTTP的基础上进行构建的HTTPS协议，所以，无论怎么样，HTTP 请求与响应都是以相同的方式进行工作的。 HTTP协议与HTTPS协议的主要区别如下。 HTTP是超文本传输办议，信息是明文传输，HTTPS则是具有安全性的SSL加密传输协议。 HTTP与HTTP协议使用的是完全不同的连接方式，HTTP采用80端口连接，而HTTP :则是443端口。 HTTPS协议需要到ca申请证书，一-般免费证书很少，需要交费,也有些Web容器提供，如TOMCAT。而HTTP协议却不需要。 HTTP 连接相对简单，是无状态的，而HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，相对来说，它要比HTTP协议更安全。 JS前台校验室不安全的，我们可以绕过Js校验，发现隐藏标签内容前端校验的存在只是为了规范用户的操作，而服务器端验证才是为防止恶意攻击！我们可以使用代理的方式修改HTTP请求，绕过Js校验，并向服务器端提交敏感数据，造成XSS跨站漏洞。 黑帽子SEO入侵黑帽SEO中一个提升排名的手段就是友情链接，与较大的网站做友情链接，那么自身的网站排名就有优势，一般黑客会对网站进行攻击，然后偷偷的挂上友情链接(黑链)，从而获得更好的排名 上面的那种攻击一般上都是利用HTTP协议搞的鬼。主要通过Referer和User-agent,黑帽子SEO就是通过这两个头来欺骗搜索引擎的！其中Referer告诉WEB服务器，用户是从哪个页面找过来的，而USER-AGENT告诉WEB服务器用户使用的浏览器和操作系统信息。当用户通过搜索引擎打开此网站时，一般会引出源页面（Referer头）]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>web安全学习总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM]]></title>
    <url>%2F2019%2F01%2F15%2FJVM%2F</url>
    <content type="text"><![CDATA[深入学习JVM学习总结按照java技术关注的重点业务领域来划分，java技术体系可以划分为4个平台 Java Card: 支持一些Java小程序( Applets) 运行在小内存设备(如智能卡)上的平台。 Java ME (Micro Edition): 支持Java程序运行在移动终端(手机、PDA). 上的平台，对Java API有所精简，并加入了针对移动终端的支持，这个版本以前称为J2ME。 JavaSE(StandardEdition):支持面向桌面级应用(如Windows下的应用程序)的Java平台，提供了完整的Java核心API,这个版本以前称为-J2SE。 Java EE ( Enferprise Edition) :支持使用多层架构的企业应用(如ERP、CRM应用)的Java平台，除了提供Java SE API外，还对其做了大量的扩充并提供了相关的部署支持，这个版本以前称为J2EE。 HotSpot VM是SunJDK和OPenJDK中所带的虚拟机，也是目前使用最广泛的虚拟机，看HotSpot名字就知道，具有基于计数器热点代码探测能力，通过执行计数器找出最具有编译价值的代码，然后通知JIT编辑器以方法为单位进行编译。 多核并行CPU硬件从当初的高频率到现在的多核心，软件也开始关注编程的并行.jdk1.5开始引入java.util.concurrent包实现一个粗粒度的并发框架。在jdk1.7加入了的java.util.concurrent.forkjoin包是对这个框架的一次重要扩充。Fork/Join模式是处理并发编程的一个景点方法，虽然不能解决所有的问题，但是在此模式的使用范围之内，能够轻松的利用多个cpu核心提供的计算资源来协作完成一个负责的计算任务。通过Fork/Join模式，我们能够更加顺畅的过渡到多核时代 OPenJDK的子项目Sumatra,目前显卡的计算运算、并行能力已经远远超过CPU。Sumatra项目就是为java提供使用GPU和APU运算能力的工具。在JDK外围，有专门满足计算需求的计算框架，如Apache的Hadoop Map/Reduce.这个是一个简单易懂的并行框架，能够运行在由上千个商用机器组成的大型集群上，并且能以一种可靠的容错方式并行处理TB级别的数据集 PV: 页面浏览量，通常是衡量一个网络新闻频道或者网站甚至一条网络新闻的主要指标Java堆区的内存大小设置还需要依赖于具体的操作系统平台导致系统瓶颈的计算资源明天继续学习总结…]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm底层学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深挖基础知识]]></title>
    <url>%2F2019%2F01%2F12%2F%E6%B7%B1%E6%8C%96%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[深挖基础知识动静态代理的区别，什么场景使用静态代理通常只代理一个类，动态代理是代理一个接口下的多个实现类静态代理事先知道代理的是什么，而动态代理不知道代理什么东西，只有运行的时候才知道。动态代理是实现JDK里的InvocationHandler接口的invoke方法。但注意的是代理的是接口，也就是你的业务类必须实现接口，通过Proxy里的newProxyInstance得到代理对象AOP是基于动态代理实现的，比如著名的Spring框架、Hibernate框架等待都是动态代理的使用例子 Java中单例设计模式分为懒汉式和饿汉式饿汉式指的是在使用前就提前创建好，懒汉式指的是先声明变量名，然后什么时候使用再创建。 JVM垃圾回收机制和常见算法GC在回收对象前必须发现那些无用的对象，那么如何发现呢？常用的搜索算法： 引用计数器算法(废弃)指的是在创建每个对象时设置一个计数器，当有地方使用时，加1，当引用失效后，计数器减1，当计数器为0的时候，JVM就认为对象不再被使用。但是即使计数器实现简单，效率高，但不能解决循环引用的问题，同时也会带来额外的开销，从jdk1.1之后这个算法就被丢弃了 根搜索算法根搜索算法是通过一些”GC Roots”对象作为起点，从这些节点开始搜索，搜索通过的路径成为引用链，当一个对象没有被GC Roots的引用链连接的时候，说明这个对象不可用 GC Roots对象包括： 虚拟机栈(栈帧中的本地变量表)中的引用对象 方法区域中的静态属性引用的对象 方法区域中常量引用的对象 本地方法栈中JNI中引用的对象 搜索到无用对象后，回收算法： 标记—清除算法(DVM使用的算法)： 效率不高，清除后有许多不连续的空间 复制算法：将内存分成两块，当垃圾回收的时候，把存活的对象复制到另一块，然后把这个内存整个清除掉。但是由于每次只能使用其中的一半，所以内存利用率不高，现在的JVM用复制方法收集新生代，由于新生代大部分对象都是朝生夕死的，所以两块的内存比例不再是一半一半了！ 标记—整理算法：适合收集存活时间比较久的对象，因为他是把存活的对象往内存的一端移动，然后回收边界以外的内存，从而提高了内存利用率。 分代收集： 根据对象的存活时间把内存分为新生代和老年代，每个代采用不同的垃圾回收算法。新生代使用复制算法，然后老年代采用标记整理算法。实现方式依赖于不同的虚拟机。 JVM内存结构 方法区： 静态分配，编译器将变量绑定到某个存储位置，而且绑定不会在运行时改变。常数池，源代码的命名常量、String常量和static变量保存在方法区 Java Stack(栈)： 一个栈的空间可能是连续的，也有可能不连续。栈中存储数据也是运行时确定的 堆分配： 以任意的顺序，在运行时进行存储空间分配和收回的内存管理模型。堆存储的数据通常是大小，数量和生命期在编译是不能确定的 JAVA内存分配 基本数据类型直接在栈空间分配 方法的形式参数，直接在栈空间分配，当方法调用完从栈空间回收 引用数据类型，需要通过new来创建，既在栈空间分配一个地址空间，又在堆空间分配对象的类变量 方法的引用参数，在栈空间分配一个地址空间，并指向堆空间的对象区，当方法调用结束之后从栈空间回收 局部变量通过new出来的，在栈空间和堆空间中分配空间，当局部变量生命周期结束后，栈空间立刻被回收，堆空间区域等待GC回收 方法调用时传入的实际参数，先在栈空间分配，在方法调用完成后从栈空间释放。 字符串常量在 DATA区域分配，this在堆空间分配 数组既在栈空间分配数组名称，又在堆空间分配数组实际的大小 Java强引用，垃圾回收器绝不会回收它，即使内存不够报错。Java引用分为四种级别： 强引用 软引用 弱引用 虚引用 1234String abc = new String("abc"); //强引用SoftReference&lt;String&gt; softRef = new SoftReference&lt;String&gt;(abc); //软引用WeakReference&lt;String&gt; weakRef = new WeakReference&lt;String&gt;(abc); //弱引用softRef.clear(); //虚引用 heap和stack区别 申请方式： stack是系统自动分配。系统自动在栈中开辟空间 heap是程序员自己申请并且指定大小，通过new的方式 申请后系统反应： stack: 只要是栈的剩余空间大于所申请的空间大小，系统将为程序提供内存，否则包异常提示栈溢出 heap: 操作系统有一个记录空间内存地址的链表，当系统收到程序申请时，会遍历链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从链表中删除，并把结点的空间分配程序。系统会将多余的那部分重新放入空闲链表中。 申请的大小限制: stack: 栈是向低地址扩展的数据结构，是一块连续的内存区域。栈顶地址和栈的最大容量是事先设定好的，栈的能获得空间很小 heap:堆是从向高地址扩展的数据结构，不是连续的内存区域。由于系统是用链表来储存空间内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址的。堆的大小受限于计算机系统的有效虚拟内存的大小。由此可见，堆获得的空间比较灵活，也比较大。 申请效率的比较: stack: 由系统自动分配，速度较快。程序员无法控制的 heap: 由new分配的内存，一般速度比较慢，容器产生内存碎片 Java的类加载器种类 根类加载器 扩展类加载器 系统(应用)类加载器 自定义加载器(必须继承ClassLoader) java类加载体系值ClassLoader双亲委托机制java是一种类型安全的语言，它有四类称为安全沙箱机制的安全机制来保证语言的安全性，这四种分别是： 类加载机制 .class文件检验器 内置于java虚拟机(及语言)的安全特性 安全管理器及java api java程序中的.java文件编译完成会生成.class文件，而.class文件就是通过类加载器的ClassLoader加载的，而ClassLoader在加载过程中会使用“双亲委派机制”来加载.class文件]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java底层知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的反射机制]]></title>
    <url>%2F2019%2F01%2F10%2FJava%E7%9A%84%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Java的反射机制什么是反射在运行状态中，对于任意一个类，都能获取这个类的属性和方法，对于任意一个对象，都能调用它的任意一个方法和属性(包含私有的属性和方法)。这种动态获取的信息以及动态调用对象的方法的功能就成为java语言的反射机制。通俗来讲，通过反射，该类对于我们来说是完全透明的，想要获取任何东西都可以。 想要使用反射机制，就必须先获取到该类的字节码文件对象(.class)，通过字节码文件对象，就能够通过该类中的方法获取到我们想要的所有信息(方法、属性、类名、父类名、实现所有的接口等)，每一个类对应着一个字节码文件，也就对应着一个class类型的对象，也就是字节码文件对象。 获取字节码的三种方式 1Class clazz1 = Class.forName("全限定类名"); //通过Class类中的静态方法forName，直接获取到一个类的字节码文件对象，此时该类还是源文件阶段，并没有变为字节码文件。 1Class clazz2 = Person.class; //当类被加载成.class文件时，此时Person类变成了.class，在获取该字节码文件对象，也就是获取自己， 该类处于字节码阶段 1Class clazz3 = p.getClass(); //通过类的实例获取该类的字节码文件对象，该类处于创建对象阶段 反射机制能够获取哪些信息通过字节码对象创建实例对象12Class clazz1 = Class.forName("cn.itcast.pojo.User");User user = (User)clazz1.newInstance(); // 我们就可以使用user获取我们想要的信息 获取指定更多构造器方法，有参构造123Class clazz1 = Class.forName("cn.itcast.pojo.User");clazz1.getConstructor(Integer.class,String.class);User user = (User)clazz1.newInstance(21,"李茂展"); // 通过构造器实例化对象，实际参数传入 获取成员变量并且使用Field对象 ###获取方法并使用Method 上面获取字节码的方式只展示了通过Class类的静态方法forName。其他方式同样可以完成上面的操作。这里就不一一演示了。我觉着，java反射机制理解概念最为重要。 注：上面的学习内容借鉴与此文章。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java反射机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo和SpringBoot]]></title>
    <url>%2F2019%2F01%2F07%2FDubbo%E5%92%8CSpringBoot%2F</url>
    <content type="text"><![CDATA[Dubbo和SpringBoot建议大家看看官方文档springboot对应dubbo版本关系 springboot整合Dubbo灰度发布：指的是新功能发布，部分用户尝试使用，一部分用户继续使用旧的功能，尝试稳定后，慢慢恢复！ 服务提供者pom.xml引入dubbo，由于我使用的是springboot2.1,所以 dubbo必须使用0.2.012345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.0&lt;/version&gt;&lt;/dependency&gt; 代替原先的provider.xml,同样的配置写在application.yml中之前我们对外暴露接口是xml配置，由于以后对外暴露接口太多，为了方便我们使用@Service (import com.alibaba.dubbo.config.annotation.Service);1234567891011dubbo: application: name: boot-service-provider registry: address: zookeeper:127.0.0.1:2181 protocol: name: dubbo port: 20880 # 通信规则# 连接监控中心 monitor: protocol: register 然后启动时，千万别忘了开启dubbo注解配置12345678910111213import com.alibaba.dubbo.config.spring.context.annotation.EnableDubbo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@EnableDubbo // 开启注解的dubbo功能@SpringBootApplicationpublic class BootServiceProvider &#123; public static void main(String[] args) &#123; SpringApplication.run(BootServiceProvider.class,args); &#125;&#125; 服务消费者pom.xml和服务提供者的相同然后使用application.yml替代原先的consumer.xml配置以前我们使用@Autowired,现在我们使用@Reference加载接口12345678dubbo: application: name: boot-service-consumer registry: address: 127.0.0.1 protocol: zookeeper monitor: protocol: register 然后启动时，千万别忘了开启dubbo注解配置123456789101112import com.alibaba.dubbo.config.spring.context.annotation.EnableDubbo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@EnableDubbo@SpringBootApplicationpublic class BootServiceConsumer &#123; public static void main(String[] args) &#123; SpringApplication.run(BootServiceConsumer.class,args); &#125;&#125; 然后运行成功！ Dubbo属性配置加载顺序规则：（方法级优先，接口级次之，全局配置再次之，如果级别一样，消费方优先，提供方次之）官网告诉我们有三种可以dubbo属性配置的方法，它们互补，优先级顺序为： Dubbo启动时检查很多时候，注册中心没有对应的服务的时候，消费者就已经启动了，往往会报错，原因:dubbo默认启动时检查我们可以在yml关闭启动时检查()123dubbo: reference: check: false 关闭所有服务的不检查123dubbo: consumer: check: false 在启动的时候，如果没有注册中心，会报错，但是我们可以关闭123dubbo: registry: check: false 消费者全局配置(dubbo.provider)123dubbo: provider: timeout: 2000 # 单位秒 timeout retries它们两个配合使用，timeout1234dubbo: consumer: timeout: 1000 # 单位毫秒，默认是1000 访问大于1秒就会报错 retries: 3 # 第一次尝试失败不算，总共尝试三次 dubbo多版本就是我们上面提到的灰度发布,我们使用 version版本来控制版本123dubbo: provider: version: 0.0.2 我们在消费者使用时使用*的方式,会随机切换 本地存根客户端一般只有接口，具体的实现都在服务器端，但是有时候我们想要做参数的提前校验，以及做缓存之类的这个时候我们只需要在客户端创建类实现远程调用接口，然后里面必须有一个构造函数12345678910111213141516171819202122232425import com.itcast.gmall.bean.UserAddress;import com.itcast.gmall.service.UserService;import org.springframework.util.StringUtils;import java.util.List;public class UserServiceStub implements UserService &#123; private final UserService userService; public UserServiceStub(UserService userService) &#123; this.userService = userService; &#125; // 构造函数传入真正的远程代理对象 public List&lt;UserAddress&gt; getUserAddressList(String userId) &#123; //如果参数不为空就返回 if(!StringUtils.isEmpty(userId))&#123; List&lt;UserAddress&gt; userAddressList = userService.getUserAddressList(userId); return userAddressList; &#125; return null; &#125;&#125; 然后我们需要在消费者端使用stub来设置1&lt;dubbo:reference interface="com.itcast.gmall.service.UserService" id="userService" stub="gmall.service.impl.UserServiceStub"&gt;&lt;/dubbo:reference&gt; 只有当我们的stub验证通过后，才会执行服务器端的代码(在开发中，我们通常把存根放在接口工程中) Dubbo和SpringBoot整合的三种方式 使用dubbo自动扫描 @Reference（引入服务）,@Service(暴露服务),记得使用@EnableDubbo 使用xml配置，那么我们使用@ImportResource配置xml文件，不需要使用@EnableDubbo 我们使用XXXConfig注册组件的方式，例如 &lt;dubbo:application&gt;&lt;/dubbo:application&gt;,记得使用@EnableDubbo 1234567891011121314import com.alibaba.dubbo.config.ApplicationConfig;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class MyConfig &#123; @Bean public ApplicationConfig applicationConfig()&#123; ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setName("boot-service-consumer"); return applicationConfig; &#125;&#125; 高可用Zookeeper宕机之后是消费者仍可以继续调用生产者的服务，因为他们仍能通过本地缓存通讯我们也可以使用@Reference(url=””)实现dubbo直连 Dubbo的负载均衡Random LoadBalance 基于权重的随机负载均衡机制 dubbo默认负载均衡机制RoundRobin LoadBalance 基于权重的轮询负载均衡机制LeastActive LoadBalance 基于最小活跃数负载均衡机制 我们自定义负载均衡机制12@Reference(loadbalance = "roundrobin")UserService userService; 服务降级我们可以在duubo控制台操作服务的屏蔽或者容错屏蔽：指的是消费者不向生产者发送请求，直接返回空容错：指的是消费者生产者发送请求失败后不报错，然后返回空 Dubbo容错机制dubbo默认的容错机制会切换另一台服务器，当然我们也可以借助springcloud的Hystrix来实现自定义容错机制 首先在服务提供者端引入依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.4.RELEASE&lt;/version&gt;&lt;/dependency&gt; 然后在方法上使用@HystrixCommand注解千万记住开启Hystrix注解模式，在启动类上加上 @EnableHystrix 同样的在消费端，我们也要引入相应的依赖，然后在调用方法上使用@HystrixCommand注解12345678910111213141516@HystrixCommand(fallbackMethod = "errorMethod") public List&lt;UserAddress&gt; initOrder(String userId) &#123; // TODO Auto-generated method stub System.out.println("用户id："+userId); //1、查询用户的收货地址 List&lt;UserAddress&gt; addressList = userService.getUserAddressList(userId); for (UserAddress userAddress : addressList) &#123; System.out.println(userAddress.getUserAddress()); &#125; return addressList; &#125; public List&lt;UserAddress&gt; errorMethod(String userId) &#123; return Arrays.asList(new UserAddress(1,"出错","出错","出错","出错","出错")); &#125; 然后我们需要在启动类上添加 @EnableHystrix dubbo底层原理我建议阅读官方文档]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo和SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo基础]]></title>
    <url>%2F2019%2F01%2F03%2FDubbo%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Dubbo基础现在的网站规模在不断的扩大，常规的垂直应用结构已经无法应对，分布式架构就应运而生 发展演变：dubbo官网的演变图 单一应用架构 所有功能写在一个工程，不利于维护，不能承受高流量访问压力 垂直应用架构 界面和业务逻辑没有实现分离，应用太过于独立，不利于之间交互 分布式服务架构 服务之间采用RPC调用，远程过程调用 流动计算架构 基于访问压力实时管理集群容量，提高集群的利用率 RPC框架： dubbo gRPC（google） Thrift （微软） HSF (阿里) JSF (京东) dubbo学习我们使用dubbo，首先我们进入官网，发现官网推荐我们使用zookeeper作为注册中心所以，我们下载zookeeper,然后我们先在本地调试，步骤如下 首先我们下载好zookeeper,解压到本地，进入config文件夹，修改zoo_sample.cfg为zoo.cfg 我们打开zoo.cfg,找到 dataDir，修改地址，前提是我们已经创建好一个用于存放data的文件夹，修改为 创建好的data文件夹地址 进入bin目录，然后分别先后点击 zkServer.cmd ，zkCli.cmd (注：我们是在window环境下的原因，才点击这两个)启动完成 在dubbo启动成功前提下，我们可以安装启动zookeeper的管理控制台 首先我们去github下载，然后加压 然后进入dubbo-admin\src\main\resources文件夹下，找到application.properties，查看dubbo.registry.address是否正确 然后进入cmd执行mvn-clean,打包得到jar包，java-jar jar包，默认端口7001，然后访问结果，默认用户名和密码都是root dubbo2.6版本以前我们需要zookeeper作为注册中心，我们需要引入zkclientdubbo2.6版本以后我们需要zookeeper作为注册中心，我们需要引入curator 代码基本入门首先我们引入依赖(服务提供者)12345678910111213141516171819202122232425262728293031&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;artifactId&gt;user-service-provider&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;artifactId&gt;gmall-interface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/dubbo --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.6.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.curator/curator-framework --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 服务的消费者提供服务的provider.xml123456789101112131415161718192021&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd"&gt; &lt;!--当前服务的名称--&gt; &lt;dubbo:application name="user-service-provider"&gt;&lt;/dubbo:application&gt; &lt;!--指定注册中心的位置--&gt; &lt;dubbo:registry address="zookeeper://127.0.0.1:2181"&gt;&lt;/dubbo:registry&gt; &lt;!--或者--&gt; &lt;!--&lt;dubbo:registry protocol="zookeeper" address="127.0.0.1:2181"&gt;&lt;/dubbo:registry&gt;--&gt; &lt;!--用dubbo协议在20880端口暴露服务--&gt; &lt;dubbo:protocol name="dubbo" port="20880"&gt;&lt;/dubbo:protocol&gt; &lt;!--声明需要暴露的服务接口--&gt; &lt;!--ref指向服务的真正的实现对象--&gt; &lt;dubbo:service interface="com.itcast.gmall.service.UserService" ref="userServiceImpl"&gt;&lt;/dubbo:service&gt; &lt;bean id="userServiceImpl" class="com.itcast.gmall.service.impl.UserServiceImpl"&gt;&lt;/bean&gt;&lt;/beans&gt; dubbo官方建议我们应该把公共类以及接口放在一个新的工程中 然后运行12345678910public class MainApplication &#123; public static void main(String[] args) throws IOException &#123; ClassPathXmlApplicationContext ioc = new ClassPathXmlApplicationContext("provider.xml"); ioc.start(); System.in.read(); &#125;&#125; 在dubbo管理中心展示 接下来我们完成服务消费者服务消费者的maven依赖和服务提供者的相同然后我们创建consumer.xml1234567891011121314&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;context:component-scan base-package="com.itcast.gmall.service.impl"&gt;&lt;/context:component-scan&gt; &lt;dubbo:application name="order-service-consumer"&gt;&lt;/dubbo:application&gt; &lt;dubbo:registry protocol="zookeeper" address="127.0.0.1:2181"&gt;&lt;/dubbo:registry&gt; &lt;!--声明需要调用的远程服务的接口；生成远程服务代理--&gt; &lt;dubbo:reference interface="com.itcast.gmall.service.UserService" id="userService"&gt;&lt;/dubbo:reference&gt;&lt;/beans&gt; 然后执行结束12345678910public class MainApplication &#123; public static void main(String[] args) throws IOException &#123; ClassPathXmlApplicationContext ioc = new ClassPathXmlApplicationContext("provider.xml"); ioc.start(); System.in.read(); &#125;&#125; 最终dubbo管理中心显示 构建简单的控制中心dubbo-monitor-simple首先我们使用mvn package构建Jar包，然后target中会有一个dubbo-monitor-simple-2.0.0-assembly.tar.gz，然后我们解压它，进入配置文件conf文件下，看看dubbo.properties中配置是否正确，然后进入assembly.bin文件夹后，点击start.sh启动启动后，那么怎么和服务关联在一起呢根据dubbo官网的描述，我们需要使用1&lt;dubbo:monitor protocol="registry"&gt;&lt;/dubbo:monitor&gt; 分别配置服务器端和消费端，然后分别重启，或在监控中心看到]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GIS音乐盒页面]]></title>
    <url>%2F2018%2F12%2F23%2FGIS%E9%9F%B3%E4%B9%90%E7%9B%92%E9%A1%B5%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[GIS音乐盒说明：这个音乐盒网站是我前一段时间做的前后端项目，结果在一个我自己清理文件的时候，不小心删除一个文件夹，下面所有的项目都被我给删除了，当我发现的时候，已经是第二天我准备上线的时候，回收站也已经被我清空了，我很是伤心。昨天我在查找资料的时候，看到了我之前做的前端静态文件，所以我打算拿出来给大家，什么时候用，拿走 注： 页面截屏一个页面截不全，你可以自己下载下来查看 以前测试阶段录的小视频我录了一个测试的小视频，然后转gif,展示出来推荐一个在线wav转gif的网站，很不错，点我去 首页 所有歌手的页面 歌曲详情页（含有评论的回复和再回复） 歌手的页面 所有歌曲的页面 专辑详情页 登录页(自己写了个模态框) 个人主页 总结： 写前端css最浪费时间，我这个页面写了差不多一个星期，包括设计页面的布局 这个后端我已经给删除了，你可以自己加后端功能，建议快速开发springboot 短信我当初使用的是阿里的短信 存储文件我使用的是七牛云，很好用]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端页面</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8——Stream流]]></title>
    <url>%2F2018%2F09%2F15%2FJava8%E2%80%94%E2%80%94Stream%E6%B5%81%2F</url>
    <content type="text"><![CDATA[Java8——Stream流我们先上手个小demo123456789101112import java.util.Arrays;public class DemoStream &#123; public static void main(String[] args) &#123; String[] strList = &#123;"李茂展","董浩","李沫熙","李哲","杨宁宁"&#125;; //接下来我们将使用stream流方式对strList进行操作，返回带 李 ，长度为3的 Arrays.stream(strList).filter((name)-&gt;name.contains("李")) .filter((name)-&gt;name.length()==3) .forEach(name-&gt; System.out.println(name)); &#125;&#125; Stream中集合的处理方案 这张图展示了过滤、映射、跳过、计数等多步操作，这是一个集合元素的处理方案，也就是一种函数模型中间执行过程中集合并不会真正的被处理，而是到最后count的时候才会被执行，这就是函数模型的操作，而之所以这样的得益于Lambda的延迟加载 Stream流获取Stream流获取有两种方式 Collection的有stream()方法获取stream流 1234567891011121314151617181920212223242526import java.util.*;import java.util.stream.Stream;public class DemoStream &#123; public static void main(String[] args) &#123; //list集合获取stream方式 ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); Stream&lt;String&gt; stream1 = list.stream(); //hash获取stream方式 HashSet&lt;String&gt; hashSet = new HashSet&lt;&gt;(); Stream&lt;String&gt; stream2 = hashSet.stream(); //map集合我们可以分别把键值对转换成流对象 HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;(); Set&lt;String&gt; keySet = map.keySet(); Stream&lt;String&gt; stream3 = keySet.stream(); Collection&lt;String&gt; values = map.values(); Stream&lt;String&gt; stream = values.stream(); &#125;&#125; 有一个Java.util.stream有一个静态方法of也可以获得stream流 123456public static void main(String[] args) &#123; //list集合获取stream方式 ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); Stream&lt;ArrayList&lt;String&gt;&gt; stream = Stream.of(list); &#125; Stream方法的学习总结首先分成两类 延迟方法 终结方法 foreach()方法 —— 终结方法遍历之后就不能使用stream流中的其他方法12345678import java.util.stream.Stream;public class ForStream &#123; public static void main(String[] args) &#123; Stream.of("李茂展","李沫熙","杨宁宁").forEach(name-&gt; System.out.println(name)); &#125;&#125; filter()方法 —— 延迟方法执行过滤之后，仍然可以使用stream的其他方法1Stream.of("李茂展","李沫熙","杨宁宁").filter(name-&gt;name.contains("李")).forEach(name-&gt; System.out.println(name)); 类名引用静态方法的使用我们使用Math.abs()来求绝对值首先我们创建一个函数式接口1234@FunctionalInterfacepublic interface AbsFunc &#123; public abstract int myAbs(int num);&#125; 然后我们可以使用lambda表达式来引用Math的静态方法12345678910111213public class DemoStream &#123; public static void getAbs(Integer num,AbsFunc absFunc)&#123; int myAbs = absFunc.myAbs(num); System.out.println(myAbs); &#125; public static void main(String[] args) &#123; getAbs(-10,Math::abs); &#125;&#125; 结构打印出来是 10 同样的使用super引用父类方法的时候，由于在子类中super是存在的，在lambda中我们可以使用super::show来完成调用 同样的使用this的时候，在lambda中我们可以使用this::show来完成调用 同样的使用new的时候，在lambda中我们可以使用Person::new来完成调用]]></content>
      <categories>
        <category>Java8</category>
      </categories>
      <tags>
        <tag>Stream流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8——Lambda表达式]]></title>
    <url>%2F2018%2F09%2F12%2FJava8%E2%80%94%E2%80%94Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Java8——Lambda表达式语法糖指的是使用更方便，但原理不变的代码语法 lambda表达式java8有一个词汇不得不提，就是 函数式接口函数式接口：有且只有一个抽象方法的接口，我们可以在接口上标注@FunctionalInterface，表示是一个函数式接口，主要作为参数或者返回值使用1234567package cn.itcast.helloworld.java8;@FunctionalInterfacepublic interface MyFunc &#123; public abstract void save();&#125; lambda表达式的重要特征: 可选类型声明：不需要声明参数类型，编译器可以统一识别参数值。 可选的参数圆括号：一个参数无需定义圆括号，但多个参数需要定义圆括号。 可选的大括号：如果主体包含了一个语句，就不需要使用大括号。 可选的返回关键字：如果主体只有一个表达式返回值则编译器会自动返回值，大括号需要指定明表达式返回了一个数值。 注：借鉴菜鸟教程，感觉总结特别好 接下来展示一个小demo12345678910111213141516171819202122public static void save(MyFunc myFunc)&#123; myFunc.save(); &#125; public static void main(String[] args) &#123; //传递接口的匿名内部类 save(new MyFunc() &#123; @Override public void save() &#123; System.out.println("执行完成"); &#125; &#125;); //由于方法的参数是一个函数式接口，所以可以使用lambda表达式 save(()-&gt;&#123; System.out.println("lambda表达式的使用"); &#125;); //由于函数式接口的方法没有参数，而且只有一条执行语句 save(()-&gt;System.out.println("lambda表达式的使用")); &#125; lambda表达式是延迟执行，可以对代码执行结果不急用用lambda语法，有助于提高性能lambda执行的前提是必须有函数式接口我们做了一个demo最适合解释lambda表达式的用法123456789101112131415161718192021/** 我们做了这么一个案例：* 当level的值为1的时候，打印日志,* 其他都不打印，为了防止我们苦费心思拿到日志之后，结果level不为 1，就损耗了性能* 所以我们使用有延迟加载作用的lambda** */public class Demo &#123; public static void save(int level,MyFunc myFunc)&#123; if(level == 1) myFunc.printLog(); &#125; //只有level的数字是1的时候，lambda表达式才会执行 public static void main(String[] args) &#123; save(1,()-&gt; System.out.println("这是日志")); &#125;&#125; Java中也给我们提供弄了很多函数式接口Comparator比较型接口在java中，Comparator接口是个函数式接口，内部只有一个抽象方法，所以按照lambda表达式规则，可以这样写12345678910111213141516171819202122public class MyCompare &#123; public static Comparator&lt;String&gt; myComparator()&#123; //匿名内部类// return new Comparator&lt;String&gt;() &#123;// @Override// public int compare(String o1, String o2) &#123;// return o2.length()-o1.length();// &#125;// &#125;; //采用Lambda表达式 return (o1,o2)-&gt;o2.length()-o1.length(); &#125; public static void main(String[] args) &#123; String[] arrList = &#123;"aaaaa","b","cccc","dddd"&#125;; System.out.println("原先顺序："+Arrays.toString(arrList)); Arrays.sort(arrList,myComparator()); System.out.println("现在顺序："+Arrays.toString(arrList)); &#125;&#125; 生产型接口指的是接口的泛型是什么类型，那么接口最后的返回值就是什么类型 Supplier生产型接口12345678910111213import java.util.function.Supplier;public class ProduceInterface &#123; public static String myPrint(Supplier&lt;String&gt; supplier)&#123; return supplier.get(); &#125; public static void main(String[] args) &#123; String str = myPrint(()-&gt;"李茂展"); System.out.println(str); &#125;&#125; Consumer消费型接口消费型接口，指的是泛型执行什么类型，就可以消费什么类型的数据12345678910111213141516import java.util.function.Consumer;public class ConsumerInterface &#123; public static void myConsumer(String name, Consumer&lt;String&gt; consumer)&#123; consumer.accept(name); &#125; public static void main(String[] args) &#123; //我们实现翻转输出 myConsumer("李茂展",(name)-&gt;&#123; String nameReverse = new StringBuffer(name).reverse().toString(); System.out.println(nameReverse); &#125;); &#125;&#125; Consumer中有一个默认方法andThen,我们可以这样使用123456789101112131415import java.util.function.Consumer;public class ConsumerInterface &#123; public static void myConsumer(String name, Consumer&lt;String&gt; consumer1, Consumer&lt;String&gt; consumer2)&#123; //谁写在前面谁先消费 consumer1.andThen(consumer2).accept(name); &#125; public static void main(String[] args) &#123; //我们实现先大写后小写输出 myConsumer("Tom",(name)-&gt; System.out.println(name.toUpperCase()),(name)-&gt; System.out.println(name.toLowerCase())); &#125;&#125; Predicate判断型接口predicate是用于判断的函数式接口，内部有一个test抽象方法，返回值是bool类型1234567891011121314import java.util.function.Predicate;public class PredicateInterface &#123; public static boolean myPredicate(String str, Predicate&lt;String&gt; predicate)&#123; return predicate.test(str); &#125; public static void main(String[] args) &#123; String str = "abcdefg"; boolean bool = myPredicate(str, (str1) -&gt; str1.length() &gt; 5); System.out.println(bool); &#125;&#125; predicate有三个默认方法： and: 表示条件同时满足 123456789101112131415import java.util.function.Predicate;public class PredicateInterface &#123; public static boolean myPredicate(String str, Predicate&lt;String&gt; predicate1,Predicate&lt;String&gt; predicate2)&#123; return predicate1.and(predicate2).test(str); &#125; public static void main(String[] args) &#123; String str = "abcdefg"; //判断长度大于5并且包含f字母，结果输出为true boolean bool = myPredicate(str, (str1) -&gt; str1.length() &gt; 5,(str1) -&gt; str1.contains("f")); System.out.println(bool); &#125;&#125; or: 表示条件只需要满足一个就可以返回true和上面的代码差不多相同，区别就是把上面的and替换成or,return predicate1.or(predicate2).test(str); negate： 表示取反 123456789101112131415import java.util.function.Predicate;public class PredicateInterface &#123; public static boolean myPredicate(String str, Predicate&lt;String&gt; predicate)&#123; return predicate.negate().test(str); &#125; public static void main(String[] args) &#123; String str = "abcdefg"; //判断长度大于5,然后结果应该是true，由于加上了negate,所以结果是false boolean bool = myPredicate(str, (str1) -&gt; str1.length() &gt; 5); System.out.println(bool); &#125;&#125; Function转换型接口Function中最主要的抽象方法是apply(T,t)，T表示转换前的类型，t表示转换后的类型123456789101112131415import java.util.function.Function;public class MyFunction &#123; public static void myFunc(String str, Function&lt;String,Integer&gt; function)&#123; Integer val = function.apply(str); System.out.println(val); &#125; public static void main(String[] args) &#123; //使用lambda表达式把字符串 "123"输出为数字 123 myFunc("123",(str)-&gt;Integer.parseInt(str)); &#125;&#125; Function有个默认方法andThen12345678910111213public class MyFunction &#123; public static void myFunc(String str, Function&lt;String,Integer&gt; function1,Function&lt;Integer,String&gt; function2)&#123; String str_val = function1.andThen(function2).apply(str); System.out.println(str_val); &#125; public static void main(String[] args) &#123; //使用lambda表达式把字符串转成数字然后再加上10再转换为字符串 myFunc("123",(str)-&gt;Integer.parseInt(str),(val)-&gt;String.valueOf(val +=10)); &#125;&#125;]]></content>
      <categories>
        <category>Java8</category>
      </categories>
      <tags>
        <tag>Lambda表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python flask做的二手交易商城]]></title>
    <url>%2F2018%2F08%2F09%2F%E4%BA%8C%E6%89%8B%E4%BA%A4%E6%98%93%E5%95%86%E5%9F%8E%2F</url>
    <content type="text"><![CDATA[看了几天python，想着做一个东西出来，就做出了一个小型二手 商城练练手1.解释以下的二手 商城展示，商品照片为了好看，从京东上爬下来的，有一些动态效果，我只制作了一张，在线转换成gif的话由于录制屏幕视频文件太大不太容易转格式 2.用户在没有登录的时候点击买东西，会弹出首先登录，同时也可以选择注册 3.卖东西的界面使用了可以拖拽的方式让用户上传商品更方便 4.用户添加商品到购物车的界面，由于二手商品数量每件比较少，所以限定用户在提交到购物车20分钟内完成结算，否则商品会从购物车内清除 5.加入购物车之后，用户可以去个人中心查看(顺便展示一下更换照片的界面) 6. 这个时候商品已经在你的购物车内，你在个人中心也可以看到购物车并且去结算 7. 去结算 8. 如果用户没有完成结算的话，会在订单中，同样也有时间限制，每件商品都有根据当初进入订单那个时间算起至三十分钟后自动从订单中取消 9. 商品列表页面 10. 在二手商城中难免有些买家觉着卖家定价不合适，会跟商家交谈，所以我也做了一个商品议价的模块，可以实现回复再回复的问题 11.我的总结： 上面只是简单的页面展示，具体代码在github上，这个项目中有很多的知识点 希望大家又遇到同样的功能不知道怎么实现的时候，我的代码能够帮到你 调bug是一件培养心态的一件事，做web也有二年左右了，感觉从代码中培养了好性格 12.github地址是:https://github.com/lmx110522/nyist_python_secondmall.git上面的页面可能不太好看，我是一个写后端代码的小码农却喜欢做前台页面，我去努力进步的！，希望你的支持，谢谢花费时间看我的博客，万分感谢！]]></content>
      <categories>
        <category>python flask</category>
      </categories>
      <tags>
        <tag>商城</tag>
        <tag>flask</tag>
        <tag>jQuery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Druid数据源]]></title>
    <url>%2F2018%2F06%2F01%2FDruid%E6%95%B0%E6%8D%AE%E6%BA%90%2F</url>
    <content type="text"><![CDATA[Druid 数据源Druid能够提供强大的监控和扩展功能。隶属于阿里巴巴旗下的连接池我们使用druid和SpingBoot结合 首先我们引入druid 的maven依赖 123456&lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt;&lt;/dependency&gt; yml配置如下1234567spring: datasource: username: root password: root url: jdbc:mysql://192.168.13.131:3306/springboot01 driver-class-name: com.mysql.jdbc.Driver type: com.alibaba.druid.pool.DruidDataSource 我们仍然可以使用druid其他的yml配置1234567891011121314151617# 数据源其他配置 initialSize: 5 minIdle: 5 maxActive: 20 maxWait: 60000 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: SELECT 1 FROM DUAL testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙# filters: stat,wall,log4j maxPoolPreparedStatementPerConnectionSize: 20 useGlobalDataSourceStat: true connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500 然后由于很多属性值druid无法映射，我们可以使用yml属性绑定的方式12345@ConfigurationProperties(prefix = "spring.datasource") @Bean public DataSource druid()&#123; return new DruidDataSource(); &#125; 然后我们需要配置druid的后台管理servlet以及监控的filter1234567891011121314151617181920212223//配置管理后台的servlet @Bean public ServletRegistrationBean statViewServlet()&#123; ServletRegistrationBean bean = new ServletRegistrationBean(new StatViewServlet(), "/druid/*"); Map&lt;String,String&gt; map = new HashMap&lt;&gt;(); map.put("loginUsername","admin"); map.put("loginPassword","admin"); map.put("allow","");//默认允许所有访问 map.put("deny","192.168.13.132");//禁止192.168.13.132访问 bean.setInitParameters(map);//初始化参数 return bean; &#125; //配置一个web监控的filter @Bean public FilterRegistrationBean webStatFilter()&#123; FilterRegistrationBean&lt;Filter&gt; bean = new FilterRegistrationBean&lt;&gt;(); bean.setFilter(new WebStatFilter()); Map&lt;String,String&gt; map = new HashMap&lt;&gt;(); map.put("exclusions","*.js,*.css,/druid/*"); //不拦截这些 bean.setInitParameters(map); //初始化参数 bean.setUrlPatterns(Arrays.asList("/*")); //表示拦截所有请求 return bean; &#125; 然后输入localhost/druid就可运行成功]]></content>
      <categories>
        <category>Druid</category>
      </categories>
      <tags>
        <tag>SpringBoot druid数据源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot的难点总结]]></title>
    <url>%2F2018%2F05%2F14%2FSpringBoot%E7%9A%84%E9%9A%BE%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[SpringBoot的难点总结WebJars:以jar包的方式引入例如jquery,我们可以这样引入12345&lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;jquery&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt;&lt;/dependency&gt; 然后在目录结构是： html中引入 /webjars/jquery/3.0.0/jquery.js就可以加载到 分析 WebMvcAutoConfiguration“/**”访问当前项目的任何资源(静态资源文件夹)12345"classpath:/META‐INF/resources/","classpath:/resources/","classpath:/static/","classpath:/public/""/"：当前项目的根路径 欢迎页； 静态资源文件夹下的所有index.html页面；被”/**”映射访问 localhost/ 会首先找Index.html 所有的 **/favicon.ico 都是在静态资源文件下找；SpringBoot自定义web配置文件以及拦截器springboot1.x版本的时候我们会继承WebMvcConfigurerAdapter,但是在2.x版本以后被标注@Deprecated，表示这个方法再慢慢被其他用法给替代所以我们使用实现WebMvcConfigurer,然后重写其方法12345678@Configurationpublic class MyConfig implements WebMvcConfigurer&#123; public void addViewControllers(ViewControllerRegistry registry) &#123; //主要处理一些不需要直接操作，只需要映射地址的 registry.addViewController("/index").setViewName("index"); &#125;&#125; 当然我们也可以这样使用123456789101112@Configurationpublic class MyConfig implements WebMvcConfigurer&#123; public WebMvcConfigurer webMvcConfigurer()&#123; return new WebMvcConfigurer() &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController("/test").setViewName("test"); &#125; &#125;; &#125;&#125; SpringBoot的拦截器我们往往在操作前要校验权限，所以拦截器有必要使用创建一个类，实现HandlerInterceptor接口123456789101112131415161718@Componentpublic class LoginInterceptor implements HandlerInterceptor &#123; public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; String username = (String) request.getSession().getAttribute("username"); if(StringUtils.isEmpty(username))&#123; username = request.getParameter("username"); if(!StringUtils.isEmpty(username))&#123; request.getSession().setAttribute("username",username); &#125; //没有输入username并且没有登录转发给登录页面 request.getRequestDispatcher("/index").forward(request,response); return false; &#125; return true; &#125;&#125; 我使用的是把拦截器注册到ioc容器中，这样防止以后我在拦截器中注入其他组件不能使用的问题12345678910111213141516171819202122232425262728@Configurationpublic class MyConfig implements WebMvcConfigurer&#123; @Autowired private LoginInterceptor loginInterceptor; public void addViewControllers(ViewControllerRegistry registry) &#123; //主要处理一些不需要直接操作，只需要映射地址的 registry.addViewController("/index").setViewName("index"); &#125; public WebMvcConfigurer webMvcConfigurer()&#123; return new WebMvcConfigurer() &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController("/test").setViewName("test"); &#125; // 按住ctrl+O // springboot 1.x版本静态资源默认不拦截，但是2.x以后会拦截静态资源 @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(loginInterceptor).addPathPatterns("/**"). excludePathPatterns("/index","/login","/"); &#125; &#125;; &#125;&#125; 我使用的12@Autowired private LoginInterceptor loginInterceptor; 注意： 加载ioc容器中的拦截组件，然后registry.addInterceptor(loginInterceptor)加载，而不是使用 registry.addInterceptor(new loginInterceptor())方式，这种情况时，自定义的interceptor中不能注入其他内容，比 如redis或者其他service，如果要注入，必须使用上面这种方法 SpringBoot错误处理机制查看源码 ErrorMvcAutoConfiguration类的使用当访问后出现4XX或者5XX的错误的时候，会转发/error请求，然后查看静态文件夹有没有error文件夹，如果没有，根据请求的设备不同，会有不同的处理结果(默认错误页面)检查设备是PC会返回html,其他设备返回json格式的数据 如何定制错误呢 有模板引擎的情况下；error/状态码; 【将错误页面命名为 错误状态码.html 放在模板引擎文件夹里面的error文件夹下】，发生此状态码的错误就会来到 对应的页面；我们可以使用4xx和5xx作为错误页面的文件名来匹配这种类型的所有错误，精确优先（优先寻找精确的状态码.html）； 页面能获取的信息； timestamp：时间戳 status：状态码 error：错误提示 exception：异常对象 message：异常消息 errors：JSR303数据校验的错误都在这里 没有模板引擎（模板引擎找不到这个错误页面），静态资源文件夹下找； 以上都没有错误页面，就是默认来到SpringBoot默认的错误提示页面； 定义错误页面1234567891011121314//出现异常会进入这个类中的方法@ControllerAdvicepublic class MyException &#123; @ExceptionHandler(CustomException.class) public String handleException(Exception e)&#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put("code","500"); map.put("message",e.getMessage()); return "forward:/error"; &#125;&#125; 但是上面这一种不具有适配性，所以我们可以这样做123456789public class MyErrorAttributes extends DefaultErrorAttributes &#123; @Override public Map&lt;String, Object&gt; getErrorAttributes(WebRequest webRequest, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; map = super.getErrorAttributes(webRequest, includeStackTrace); map.put("company","nyist"); return map; &#125;&#125; SpringBoot嵌入式Servlet容器优点： 简单、便携缺点： 默认不支持JSP，优化定制比较复杂我们可以外置的Servlet容器，然后我们可以这样做 创建成一个war项目 将嵌入式的tomcat设置成provided 必须编写一个类 12345678public class ServletInitializer extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; return application.sources(TomcatDemoApplication.class); &#125;&#125; 启动就可以使用了 我们也要配置静态资源的访问12spring.mvc.view.prefix=/WEB-INF/spring.mvc.view.suffix=.jsp]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>SpringBoot难点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[南阳理工下载中心]]></title>
    <url>%2F2018%2F04%2F09%2F%E5%8D%97%E9%98%B3%E7%90%86%E5%B7%A5%E4%B8%8B%E8%BD%BD%E4%B8%AD%E5%BF%83%2F</url>
    <content type="text"><![CDATA[springboot实现使用ftp实现下载由于前后台都是我本人写的，加上就四五天的时间，所以，有点瑕疵！给我评论哟springboot特点有以下 1、使编码变得简单2、使配置变得简单3、使部署变得简单4、使监控变得简单由于时间比较紧张，有些功能或许不太完善，后期回去完善，谢谢您的查看! 里面大致功能 阿里验证码 springboot框架下的RabbitMq解决同时注册削锋的问题 springboot使用redis以及session实现避免多用户造成给数据库压力 网站多处使用ajax异步技术实现异步加载数据 sppringdatajpa的使用，多条件共同作用下的查询结果异显示在页面 本站本来要使用socket实现管理员消息推送，但是这个功能和上个spingboot模拟QQ相似，所以就没写 希望它对您有帮助 先上截图 1 首页 2 全部下载，这个有点含金量，多条件同时传递筛选，然后异步显示 3 登录，使用了阿里的手机验证码登录，以及jquery实现的滑块验证 4. 上传页面，实现了图片在线预览，以及自动识别格式 5. 更换头像少不了的功能 6.下载项详细页，里面包含评论，还有同类型精准匹配推荐 7. 下载须知，这个样式有必要展示一下，挺好看的 8. 管理员后台登录 9. 管理员主界面， 10. 审核界面不一一介绍了，希望你如果真的想了解这些功能，下载下来，看看具体功能实现步骤，上面的网站照片主要是让你了解一下网站的大致功能 以及如何显示，具体代码请查看github网站，如果喜欢，给个小星星 ！ github地址： https://github.com/lmx110522/download-nyist.git **]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>jQuery</tag>
        <tag>FTP</tag>
        <tag>redis</tag>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker学习]]></title>
    <url>%2F2018%2F03%2F22%2FDocker%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Docker学习docker是一个开源的应用容器引擎，基于GO语言并遵循Apache2.0协议开源Docker支持将软件编译成一个镜像，然后在镜像中做好各个软件的配置，将镜像发布出去，其他使用者就可以直接使用这个镜像docker安装需要centos内核高于3.10（uname -r 查看内核版本） 核心概念docker主机： 安装了docker程序的机器docker客户端(Client)：连接docker主机进行操作；docker仓库(Registry)：用来保存各种打包好的软件镜像；docker镜像(Images)：软件打包好的镜像；放在docker仓库中；docker容器(Container)：镜像启动后的实例称为一个容器；容器是独立运行的一个或一组应用 使用docker的步骤： 安装好docker程序 yum install docker 启动docker程序 systemctl start docker 去docker容器查找你所需要的镜像 docker search 镜像 下载对应的镜像 docker pull 镜像::版本 查看下载好的镜像 docker images 安装对应的镜像 docker run 查看安装好的镜像 docker ps -a 命令补充: 查看在运行的镜像: docker ps 删除容器: docker rm 容器id 关闭容器: docker stop 容器id 查看启动日志: docker logs 容器id 删除镜像： dokcer rmi 容器id MYSQL安装案例 mysql docker run --name mysql -e MYSQL_ROOT_PASSWORD=123456 -p 3306:3306 -d mysql]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker基础知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot实现模拟QQ的实现(超具体)]]></title>
    <url>%2F2018%2F02%2F08%2Fspringboot%E5%AE%9E%E7%8E%B0%E6%A8%A1%E6%8B%9FQQ%E7%9A%84%E5%AE%9E%E7%8E%B0(%E8%B6%85%E5%85%B7%E4%BD%93)%2F</url>
    <content type="text"><![CDATA[springboot实现QQ在线聊天，大部分功能已经实现！ 如果需要的话，去我的github空间download,有不足，希望大家指出~ 1.登录页面 2.先来看看主界面是什么样子 3.然后我们再看看聊天界面是什么样的 4.添加好友的时候什么样子呢! 5.对方加你好友的时候，你的接受好友申请的界面 6.你点击同意之后，你可以选择好友在哪个好友分组，当然你也可以添加分组 7.基本的功能都已经实现主要难点有以下 数据库如何保存聊天信息，如果频繁操作数据库，会让网页每次访问压力很大，不利于体验效果 作为一个后端人员，做网页效果难度很大，还好我闲暇时间都会去看看前端，这个前后端完全来自我一个人四天的努力，所以难免有点地方不足，请大家给我留言 逻辑比较清楚，但是实现起来比较麻烦！变量传来传去，丢参数很正常，但是，现在程序一切运行正常，大家可以从下载下来，在idea运行，有一个问题，在chrome内核的浏览器上支持度比较好，在其他浏览器的滚动条有点问题！ 注册功能我没有写，我下一条博客准备发我的用python框架flask写的小型商城，那个里面有邮箱注册，到时候大家可以从哪里瞅瞅 希望你的小星星点赞我的github，谢谢 我的github站点：https://github.com/lmx110522/nyist_chat_project.git 谢谢大家花时间看我的博客，万分感谢~~~]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>jQuery</tag>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot的配置]]></title>
    <url>%2F2018%2F01%2F15%2FSpringBoot%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[配置文件加载位置springboot 启动会扫描以下位置的application.properties或者application.yml文件作为Spring boot的默认配置文件 file:./config/ file:./ classpath:/config/ classpath:/ 加载规则如下： 优先级由高到底，高优先级的配置会覆盖低优先级的配置； SpringBoot会从这四个位置全部加载主配置文件；互补配置； 我们还可以通过spring.config.location来改变默认的配置文件位置 java -jar test.jar –spring.config.location=D:/application.yml 项目打包好以后，我们可以使用命令行参数的形式，启动项目的时候来指定配置文件的新位置；指定配置文件和默认加载的这些配置文件共同起作用形成互补配置； 外部配置加载顺序SpringBoot也可以从以下位置加载配置； 优先级从高到低；高优先级的配置覆盖低优先级的配置，所有的配置会形成互补配置1.命令行参数所有的配置都可以在命令行上进行指定java -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar –server.port=8087 –server.context-path=/abc多个配置用空格分开； 配置项=值2.来自java:comp/env的JNDI属性3.Java系统属性（System.getProperties()）4.操作系统环境变量5.RandomValuePropertySource配置的random.*属性值由jar包外向jar包内进行寻找；优先加载带profile6.jar包外部的application-{profile}.properties或application.yml(带spring.profile)配置文件7.jar包内部的application-{profile}.properties或application.yml(带spring.profile)配置文件再来加载不带profile8.jar包外部的application.properties或application.yml(不带spring.profile)配置文件9.jar包内部的application.properties或application.yml(不带spring.profile)配置文件10.@Configuration注解类上的@PropertySource11.通过SpringApplication.setDefaultProperties指定的默认属性]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>springboot知识点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring琐碎知识汇总]]></title>
    <url>%2F2018%2F01%2F10%2FSpring%E7%90%90%E7%A2%8E%E7%9F%A5%E8%AF%86%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[SpringBoot学习总结SpringBoot简化spring开发，约定大于配置 优点： 快速创建独立运行的Spring项目以及与主流框架集成 使用嵌入式的Servlet容器,应用无需打成WAR包 starters自动依赖与版本控制 大量的自动配置,简化开发,也可修改默认值 无需配置XML ,无代码生成,开箱即用 准生产环境的运行时应用监控 与云计算的天然集成 使用springboot也跟目前大时代背景有关，现在企业级应用如此庞大，集群，微服务，SOA词汇渐渐进入我们的视野提到了微服务，我们就要看看马丁大叔的个人主页,马丁大叔14年提到了微服务，提倡服务之间应使用restful风格，后来我们将要学习的springcloud采用的就是基于restful风格的架构方案 开发springboot最好用的是IDEA，这是我的百度网盘链接，拿去用吧IDEA工具下载 配置文件SpringBoot使用一个全局的配置文件，配置文件名是固定的 application.yml application.properties YAML是”YAML Ain’t a Markup Language”（YAML不是一种置标语言）的递归缩写yml是一种标记语言，yml以数据为中心，相比于xml,xml花费太多的时间在标签上，效率不高 yml语法：1、基本语法k:(空格)v：表示一对键值对（空格必须有）； 以空格的缩进来控制层级关系；只要是左对齐的一列数据，都是同一个层级的123server: port: 80 path: /test 2、值的写法字面量 字符串默认不用加上单引号或者双引号 双引号不会转义特殊字符，例如：”spring \n boot” 输出则是 “spring”换行“boot” 单引号会转义特殊字符，例如：”spring \n boot” 输出则是 “spring \n boot” 对象 通常下面写法：123dog: name: 阿黄 age: 12 也可以下面这种行内写法1dog: &#123;name: 阿黄,age: 12&#125; 数组1234pets: - dog - cat - pig 它也有一个行内写法1pets: [dog,cat,pig] yml语法还支持占位符 随机数 age: ${random.uuid} 使用上面定义好的 1234dog: name: 阿黄 age: $&#123;random.uuid&#125; nickname: 小$&#123;dog.name:狗狗&#125; 狗狗表示是如果加载不到dog.name，狗狗就是就是默认值 注：在yml中，last-name和lastName是表示的一样 从yml得到数据绑定给pojoyml数据123person: username: 旺财 password: 123 @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定，prefix=”person”配置文件中哪个下面的所有属性进行一一映射12345678910111213141516171819202122232425262728293031323334353637383940@Component @ConfigurationProperties(prefix = "person") public class Person &#123; private String username; private String password; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125;&#125; 然后我们使用springboot的测试功能```java@RunWith(SpringRunner.class)@SpringBootTestpublic class HelloworldApplicationTests &#123; @Autowired private Person person; @Test public void contextLoads() &#123; System.out.println(person.getUsername()); &#125;&#125; 成功打印出： 旺财，成功绑定 这个用法是springboot中很多底层源码都会用的到,源码摘取： redis属性和yml数据绑定，就是用的这个方法 ConfigurationProperties和Value的对比 @ConfigurationPropertie @Value 功能 批量注入配置文件中的属性 一个个指定 松散绑定（松散语法） 支持 不支持 SpEL 不支持 支持 JSR303数据校验 支持 不支持 复杂类型封 支持 不支持 在注解ConfigurationProperties的情况下在类上添加@Validated实现JSR303校验 @PropertySource和@ImportSource区别由于我们使用ConfigurationProperties默认会从application.properties/yml中获取数据，所以，如果我们自己写了一个properties，我们则需要@PropertySource1234567891011121314151617181920212223242526272829303132333435package cn.itcast.helloworld.pojo;import org.hibernate.validator.constraints.Length;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.PropertySource;import org.springframework.stereotype.Component;import org.springframework.validation.annotation.Validated;@Component@PropertySource(value = &#123;"classpath:person.properties"&#125;)@ConfigurationProperties(prefix = "person")@Validatedpublic class Person &#123; @Length(min = 8,max = 16) private String username; private String password; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125;&#125; @ImportSource：导入spring的配置文件，让配置文件生效1@ImportResource(locations = &#123;"classpath:beans.xml"&#125;) profile环境配置，在spring注解的时候有@Profile,和在学习注解版的时候作用是相同的，有两种方法可以根据环境不同来实现配置文件不同 application-dev.properties、application-prod.properties的方式 分区文档快，yml文件可以分区，如下，注意看红线 重要的知识点来了 如何激活环境 运行时配置环境 –spring.profiles.active=dev 项目打包好，我们在命令行可以使用 java jar test.jar –spring.profiles.active=dev 虚拟机参数 -Dspring.profiles.active=dev]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>yml</tag>
        <tag>springboot入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring注解驱动开发（二）]]></title>
    <url>%2F2017%2F12%2F18%2Fspring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[spring注解驱动开发（二）@Import的使用目前我们知道的往ioc容器中注册组件的方式有两种 在类上标注@component、@Service、@Controller、@Repository，然后通过@ComponentScan的方式扫描到ioc容器中 在配置类中需要注册到ioc容器的组件使用@Bean主机的方式出了上面的方法，那么我们再介绍几种方法 @Import可以实现快速注册组件的目的@Import({MyImportSelector.class})然而在ioc中的id是该类的全类名 FactoryBean接口可以实现注册组件的目的我们可以创建一个类实现FactoryBean接口1234567891011121314151617181920public class PersonFactoryBean implements FactoryBean&lt;Person&gt;&#123; //返回对象会加载到ioc容器中 public Person getObject() throws Exception &#123; // TODO Auto-generated method stub System.out.println("成功调用"); return new Person(); &#125; //指定类型 public Class&lt;?&gt; getObjectType() &#123; // TODO Auto-generated method stub return Person.class; &#125; //指定是否是单例模式 public boolean isSingleton() &#123; // TODO Auto-generated method stub return true; &#125;&#125; 然后我们可以测试12345AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MyConfig.class); Object bean = context.getBean("personFactoryBean"); System.out.println(bean.getClass());//打印出来的是class cn.itcast.pojo.Person Object bean1 = context.getBean("&amp;personFactoryBean"); System.out.println(bean1.getClass());//打印出来的是class cn.itcast.config.PersonFactoryBean 注：上面在获取bean的时候，有一个符号&amp;，通过加上这个符号可以获得注册组件自己 ImportSelector接口可以实现注册组件的目的我们把要注册到ioc容器中组件的全类名放在返回的数组中1234567public class MyImportSelector implements ImportSelector&#123; public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123; return new String[] &#123;"cn.itcast.pojo.Role","cn.itcast.pojo.Dog"&#125;; &#125;&#125; 记得把MyImportSelector注册到ioc容器中，这里我们采用快速注入的方式@Import({MyImportSelector.class})我们可以一次注册多个组件到容器中 ImportBeanDefinitionRegistrar接口可以实现注册组件的目的123456789101112131415public class MyImportBeanDefinitionRegister implements ImportBeanDefinitionRegistrar&#123; public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; //首先判断ioc中是否有role这个组件，如果有的话，就注册bean boolean flag = registry.containsBeanDefinition("cn.itcast.pojo.Role"); if(flag) &#123; //注册person组件 RootBeanDefinition beanDefinition = new RootBeanDefinition(Person.class); registry.registerBeanDefinition("person",beanDefinition); &#125; &#125;&#125; @Bean中的initMethod、destroyMethod原先我们使用xml配置的方式表示为:1234567891011121314151617181920public class Role &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public void init() &#123; System.out.println("容器初始化"); &#125; public void destory() &#123; System.out.println("容器被销毁"); &#125;&#125; 123&lt;bean id="role" class="cn.itcast.pojo.Role" init-method="init" destroy-method="destory"&gt; &lt;property name="name" value="bean生命周期"&gt;&lt;/property&gt;&lt;/bean&gt; 在@Bean中有两个属性1234@Bean(initMethod="init",destroyMethod="destory") public Role role() &#123; return new Role(); &#125; 注：在销毁的时候，单实例容器会销毁，但是多实例，容器不负责销毁，所以在多实例下销毁方法不调用 在初始化的时候，单实例容器运行时，会调用初始化（init）方法，多实例在调用对象的时候创建(执行init的方法) @Value、@PropertySource的使用以前我们使用下面方式给组件赋值123&lt;bean id="dog" class="cn.itcast.pojo.Dog"&gt; &lt;property name="name" value="旺财"&gt;&lt;/property&gt; &lt;/bean&gt; 在注解版中我们可以使用1234@Value("旺财")private String name;@Value("#&#123;2*3&#125;")private String nickName; 当然这种硬编码不太好，所以我们可以加载配置文件中的值，那么引入@PropertySource实现引入配置文件然后使用属性占位符的方式得到12@Value("$&#123;dog.name&#125;")private String name; 当然你也可以使用SPEL表达式得到。12 @Value("#&#123;systemProperties['dog.name']&#125;")private String name; @Autowired、@Qualifier、@Primary注解的使用@Autowired用作组件的自动装配，装配的规则是 首先按照组件的类型从ioc容器中查找，查找到装配完成 如果遇到多个同类型的组件，那么会使用属性名作为查找ioc容器组件的id 如果没有查到到，会报错！但是我们又不想让它报错，那么我们可以使用@Autowired(required=false)当然我们也可以自己指定需要查找组件的id,用@Qualifier(&quot;indexService1&quot;),这样我们就可以去ioc容器中查找id是indexService1的组件同时呢，spring也给我们提供了@Primary，意思是要找此类型的组件，首选此组件12345@Primary @Bean public IndexService indexService1() &#123; return new IndexService(); &#125; 注：@Primary注解使用的时候，就不要使用@Qualifier注解了 spring也支持@Resource(JSR250)和@Inject(JSR330),这些都是java规范@Resource默认按照属性的名称作为组件的id去ioc容器查找，当然我们也可以使用@Resource（name=’indexDao1’）设置@Inject需要导入javax.inject的包，在使用上和@Autowired一样@Autowired可以使用在构造器，方法，属性上面、参数位置，如果组件只有一个有参构造器，参数位置的@Autowired可以省略，还有@Bean中的参数，也不用写@Autowired，都可以从容器中自动装配 @Profile注解的使用Spring为我们提供的可以根据当前环境，动态的激活和切换一系列组件的功能默认的profile是default我们在某个组件上面加上@Profile(&#39;test&#39;),一旦加上之后，就是当环境激活的时候，对应的bean才可以注册到容器中那么如何激活呢 在运行到时候，设置命令行参数的方式 -Dspring.profiles.active=test 可以借助applicationContext方式激活环境，例如：1234567AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext();//设置需要激活的环境context.getEnvironment().setActiveProfiles("test","dev");//注册主配置类context.register(MyConfig.class);//启动刷新容器context.refresh();]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring注解驱动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring注解驱动开发（一）]]></title>
    <url>%2F2017%2F12%2F15%2Fspring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[spring注解驱动开发（一）初步介绍 spring注解驱动开发随着springboot这个简洁化开发，约定大于配置的大环境下，spring注解版知识点使用的也开始越来越多，所以我已经学习了基础springboot之后果断停止，开始学习spring注解驱动开发,下面是我总结的一些注解知识,这个页面会一直更新，用于以后的查阅 1、@Configurable注解以及@Bean的使用Configurable表示这个一个配置类，代替原先xml配置之前我们用xml做DI(依赖注入)，现在我们可以通过class的方式来声明一个配置类 xml配置1234567891011&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.0.xsd"&gt; &lt;bean id="person" class="cn.itcast.pojo.Person"&gt; &lt;property name="username" value="lmx"&gt;&lt;/property&gt; &lt;property name="password" value="123"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; 现在可以使用123456789101112131415package cn.itcast.config;import org.springframework.beans.factory.annotation.Configurable;import org.springframework.context.annotation.Bean;import cn.itcast.pojo.Person;@Configurablepublic class MyConfig &#123; @Bean(name="lmx") public Person person() &#123; return new Person("lmz","456"); &#125;&#125; 上面的bean代替旧的即&lt;bean/&gt;可以实现向容器注册组件，其中bean的name属性指的是注册组件在容器中的ID，默认是方法名作为组件的ID 然后通过下面的测试，果然简单有效，赞！1234567891011121314151617181920212223242526package cn.itcast.test;import org.springframework.context.annotation.AnnotationConfigApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import cn.itcast.config.MyConfig;import cn.itcast.pojo.Person;public class MainTest &#123; public static void main(String[] args) &#123;// ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext("beans.xml");// Person person = (Person)applicationContext.getBean("person");// System.out.println("姓名："+person.getUsername());// System.out.println("密码："+person.getPassword()); AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MyConfig.class); Person bean = context.getBean(Person.class); System.out.println("姓名："+bean.getUsername()); System.out.println("密码："+bean.getPassword()); String[] beanNamesForType = context.getBeanNamesForType(Person.class); for (String string : beanNamesForType) &#123; System.out.println(string); &#125; &#125;&#125; 2、@ComponentScan包扫描注解context:component-scan主要用于扫描对应包下面的注解到容器中，一般有以下注解 @Controller @Service @Repository @Component 对应的xml配置 &lt;context:component-scan base-package=&quot;cn.itcast&quot;/&gt;’ 用class类文件的方式，把下面配置配在config文件的上面，这样可以实现包扫描 @ComponentScan(basePackages= {“cn.itcast”})’ @excludeFilters可以除去不想扫描进容器的注解1234@ComponentScan(basePackages= &#123;"cn.itcast"&#125;,excludeFilters= &#123; @Filter(type=FilterType.ANNOTATION,classes=Controller.class), @Filter(type=FilterType.ANNOTATION,classes=Service.class)&#125;) use-default-filters这个语句主要是关闭默认扫描对应包下面的所有注解 @includeFilters中要把use-default-filters设置成false xml中这样写 &lt;context:component-scan base-package=&quot;cn.itcast&quot; use-default-filters=&quot;false&quot; /&gt; 使用class文件这样写就ok了1234@ComponentScan(basePackages = &#123;"cn.itcast"&#125;,includeFilters = &#123;@Filter(type=FilterType.ANNOTATION,classes=Controller.class),@Filter(type=FilterType.ANNOTATION,classes=Service.class)&#125;,useDefaultFilters = false) 由于java8以上才有@Repeatable这个注解，表示可以注解重复，但是java8以下不支持，所以我们要做兼容性有一个注解@ComponentScans，可以包含多个@ComponentScan 3、 @Scope注解扫描到容器的默认是单实例的我们可以通过scope改变默认值xml中我们是这样来表示scope的1234&lt;bean id="person" class="cn.itcast.pojo.Person" scope="prototype"&gt; &lt;property name="username" value="lmx"&gt;&lt;/property&gt; &lt;property name="password" value="123"&gt;&lt;/property&gt; &lt;/bean&gt; class类方式在@Bean注解上添加@Scope 注： 单实例是ioc容器启动的时候就就把对象创建放进容器了，但多实例是什么时候调用就什么时候创建 例如：@Scope(&#39;prototype&#39;)这个表明扫描进容器的组件是多实例的，当然我们也可以使用@Scope(&#39;singleton&#39;)或者不写，可以实现单实例12345@Scope(value="SCOPE_PROTOTYPE") @Bean(name="lmx") public Person person() &#123; return new Person("lmz","456"); &#125; 4、 @Lazy懒加载的使用把这个注解放在@Bean的上面表示懒加载，即IOC容器启动的时候创建，什么时候使用什么时候创建 注:这个属性主要针对的是单实例的 5、 @Conditional条件注解的使用这个注解在springboot的底层源码用的最多，所以有必要好好深挖一下我写了一个demo1234567891011@Conditional(WindowsCondition.class) @Bean(name="bill") public Person person01() &#123; return new Person("Bill Gates","123"); &#125; @Conditional(LinuxCondition.class) @Bean(name="linus") public Person person02() &#123; return new Person("linus","456"); &#125; 分别创建WindowsCondition、LinuxCondition，都要实现Condition接口12345678910111213141516171819202122232425262728public class LinuxCondition implements Condition&#123; //参数 context 上下文环境 // 参数 metadata 当前注释此注解的信息 public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; // //获得ioc使用的beanfactory// ConfigurableListableBeanFactory beanFactory = context.getBeanFactory();// // //获取类加载器// ClassLoader classLoader = context.getClassLoader();// // //获取bean定义的注册类// BeanDefinitionRegistry registry = context.getRegistry(); // //判断对应的bean是不是在ioc容器中已经存在// boolean isExist = registry.containsBeanDefinition("lmx");// //获取当前系统环境信息 Environment environment = context.getEnvironment(); //获取操作系统属性 String property = environment.getProperty("os.name"); if(property.contains("Linux")) return true; return false; &#125;&#125; 123456789101112public class WindowsCondition implements Condition&#123; public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; // TODO Auto-generated method stub Environment environment = context.getEnvironment(); String property = environment.getProperty("os.name"); if(property.contains("Windows")) return true; return false; &#125;&#125; 然后做测试12345AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MyConfig.class); String[] strings = context.getBeanNamesForType(Person.class); for (String string : strings) &#123; System.out.println(string); &#125; 结果：由于我的系统是Windows，所以ioc容器中注册的组件id是 bill 下一篇还有spring注解驱动开发（二）]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring注解驱动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx]]></title>
    <url>%2F2017%2F11%2F25%2FNginx%2F</url>
    <content type="text"><![CDATA[Nginxnginx安装nginx安装手册，这个讲解的特别详细，nginx安装手册安装成功之后你在本地输入之后会看到，如果访问不到，请检查防火墙问题 nginx主要的功能 Nginx是一个轻量级、高性能、稳定性高、并发性好的HTTP和反向代理服务器 主要功能 反向代理正向代理：某些情况下，代理我们用户去访问服务器，需要用户手动的设置代理服务器的ip和端口号。反向代理：是用来代理服务器的，代理我们要访问的目标服务器。代理服务器接受请求，然后将请求转发给内部网络的服务器(集群化)，并将从服务器上得到的结果返回给客户端，此时代理服务器对外就表现为一个服务器。 反向代理的优点： 1、充当防火墙 2、可以使负载均衡 Nginx在反向代理上，提供灵活的功能，可以根据不同的正则采用不同的转发策略 负载均衡多在高并发情况下需要使用。其原理就是将数据流量分摊到多个服务器执行，减轻每台服务器的压力，多台服务器(集群)共同完成工作任务从而提高了数据的吞吐量Nginx可使用的负载均衡策略有：轮询（默认）、权重、ip_hash（对负载均衡有破坏） nginx模块我们要好好研究一下Nginx的配置文件nginx.conf daemondaemon on| off:是否已进程的方式守护nginx默认情况下是守护的，所以我们不用修改它 master_processmaster_process on| off:默认一个master进程管理多个worker进程的，关闭之后nginx不会fork出子进程来处理请求，默认是可以的，不用修改它 nginx pidnginx进程的pid nginx反向代理123456789101112131415server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; deny 192.168.13.130; # 禁止192.168.13.130域名访问 allow 192.168.13.0/131; # 表示允许192.168.13.0到192.168.13.131之间的域名访问 deny all; # 表示除了上面允许的ip能够访问意外，其他都不允许访问 root /home/ynn; index index.html index.htm; &#125; 上面的listen表示监听的端口是80,server_name，对应的域名是localhost,location后面有一个 /表示访问localhost/会去服务器/home/ynn下去查找我一般用nginx作为反向代理，使用ftp提高文件给服务器，然后使用反向代理的方式去访问服务器中的内部资源 nginx的负载均衡配置1234567891011121314151617upstream nyist_mall &#123; server 192.168.13.131:8081 weight = 5 max_fails=3 fail_timeout=30s; server 192.168.13.131:8082 weight = 3; server 192.168.13.131:8083 weight = 2; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; proxy_pass http://nyist_mall; &#125; max_fails:表示请求连续失败三次就认定此服务器已经宕机，不再去请求该服务器fail_timeout: 表示请求时长超过30s没有响应，表示请求失败 当我发送localhost访问服务器的时候，nginx负载均衡机制会把我的访问分发给三台服务器，这样可以实现将数据流量分摊给多台服务器执行，减轻每台服务器压力，多台服务器协作，增加数据的吞吐量 Nginx+Tomcat集群和上面我配置的负载均衡相同，只需要把你的tomcat访问地址放在upstrea下面的server中皆可以了，然后设置自己的负责均衡策略这样一个tomcat集群就设置完成了 keepalived + Nginx 实现nginx高可用关于配置，我觉着这个博客写的就很好了，Keepalived+nginx高可用配置我的理解:首先我们必须要设置一个虚拟IP,然后我们使用keepalived绑定虚拟IP,nginx要和keepalived绑定在一起，当nginx宕机的时候，keepalived会检测到，然后停掉nginx,接着关闭自己，然后备用keepalived发送响应给主keepalived,然后在规定时间内没有发送成功，keepalived认定对应的服务已经挂掉，然后自己从备用转成主用。重启后，再次回到原先的主备状态]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>nginx的重点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息中间件]]></title>
    <url>%2F2017%2F10%2F17%2F%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[消息中间件 常用的消息中间件1. ActiveMQ Apache出品的，开发常用2. RabbitMQ 完全支持JMS1.1和J2EE 1.4规范3. kafka Kafka的目的是通过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群来提供实时的消息。 消息中间件可以提高系统性能 JMSJMS 是一套消息中间件的技术规范，定义了一系列的接口规范。JMS 定义了五种不同的消息正文格式，以及调用的消息类型，允许你发送并接收以一些不同形式的数据，提供现有消息格式的一些级别的兼容性。 TextMessage–一个字符串对象 MapMessage–一套名称-值对 ObjectMessage–一个序列化的 Java 对象 BytesMessage–一个字节的数据流 StreamMessage – Java 原始值的数据流 对于消息的传递有两种类型： 一种是点对点的，即一个生产者和一个消费者一一对应； 另一种是发布、订阅模式，即一个生产者产生消息并进行发送后，可以由多个消费者进行接收。 消息中间件用的比较多的还是activeMQ点对点模式消息生产者生产消息（点对点模式）1234567891011121314151617181920212223242526272829303132333435363738import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;public class QueueProducer &#123; public static void main(String[] args) throws JMSException &#123; //创建连接工厂 ActiveMQConnectionFactory activeMQConnectionFactory = new ActiveMQConnectionFactory("tcp://192.168.13.131:61616"); //创建连接 Connection connection = activeMQConnectionFactory.createConnection(); //启动连接 connection.start(); //获取session（会话对象） 参数1:是否启动事物 参数2:消息确认方式 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //创建队列对象 Queue queue = session.createQueue("sms"); //创建消息生产者对象 MessageProducer producer = session.createProducer(queue); //创建消息(文本对象) TextMessage textMessage = session.createTextMessage("你好，jms"); //发送消息 producer.send(textMessage); //关闭连接 producer.close(); session.close(); connection.close(); &#125;&#125; 消费者消费消息（点对点模式）1234567891011121314151617181920212223242526272829303132333435363738394041424344import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;public class QueueConsumer &#123; public static void main(String[] args) throws JMSException &#123; //创建连接工厂 ActiveMQConnectionFactory activeMQConnectionFactory = new ActiveMQConnectionFactory("tcp://192.168.13.131:61616"); //创建连接 Connection connection = activeMQConnectionFactory.createConnection(); //启动连接 connection.start(); //获取session（会话对象） 参数1:是否启动事物 参数2:消息确认方式 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //创建队列对象 Queue queue = session.createQueue("sms"); //创建消息消费者对象 MessageConsumer consumer = session.createConsumer(queue); //设置监听 consumer.setMessageListener(new MessageListener() &#123; public void onMessage(Message message) &#123; TextMessage textMessage = (TextMessage) message; try &#123; String messageText = textMessage.getText(); System.out.println("接收到的消息是："+messageText); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); consumer.close(); session.close(); connection.close(); &#125;&#125; 发布订阅模式消息生产者生产消息（发布订阅模式）123456789101112131415161718192021222324252627282930313233343536373839import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;public class QueueProducer &#123; public static void main(String[] args) throws JMSException &#123; //创建连接工厂 ActiveMQConnectionFactory activeMQConnectionFactory = new ActiveMQConnectionFactory("tcp://192.168.13.131:61616"); //创建连接 Connection connection = activeMQConnectionFactory.createConnection(); //启动连接 connection.start(); //获取session（会话对象） 参数1:是否启动事物 参数2:消息确认方式 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //创建主题对象 Topic topic = session.createTopic("sms2"); //创建消息生产者对象 MessageProducer producer = session.createProducer(topic); //创建消息(文本对象) TextMessage textMessage = session.createTextMessage("你好，jms2"); //发送消息 producer.send(textMessage); //关闭连接 producer.close(); session.close(); connection.close(); &#125;&#125; 消费者消费消息（发布订阅模式）1234567891011121314151617181920212223242526272829303132333435363738394041424344import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;public class QueueConsumer &#123; public static void main(String[] args) throws JMSException &#123; //创建连接工厂 ActiveMQConnectionFactory activeMQConnectionFactory = new ActiveMQConnectionFactory("tcp://192.168.13.131:61616"); //创建连接 Connection connection = activeMQConnectionFactory.createConnection(); //启动连接 connection.start(); //获取session（会话对象） 参数1:是否启动事物 参数2:消息确认方式 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //创建主题对象 Topic topic = session.createTopic("sms2"); //创建消息消费者对象 MessageConsumer consumer = session.createConsumer(topic); //设置监听 consumer.setMessageListener(new MessageListener() &#123; public void onMessage(Message message) &#123; TextMessage textMessage = (TextMessage) message; try &#123; String messageText = textMessage.getText(); System.out.println("接收到的消息是："+messageText); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); consumer.close(); session.close(); connection.close(); &#125;&#125; 注意点 发布订阅模式下，生产者发布消息，消费者必须在开启的情况下才可以接受到，否则消息就浪费掉，就消失了。 Spring整合Jms Spring生产者xml文件配置（点对点） 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:amq="http://activemq.apache.org/schema/core" xmlns:jms="http://www.springframework.org/schema/jms" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;context:component-scan base-package="cn.itcast.demo"&gt;&lt;/context:component-scan&gt; &lt;!-- 真正可以产生Connection的ConnectionFactory，由对应的 JMS服务厂商提供--&gt; &lt;bean id="targetConnectionFactory" class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;property name="brokerURL" value="tcp://192.168.13.131:61616"/&gt; &lt;/bean&gt; &lt;!-- Spring用于管理真正的ConnectionFactory的ConnectionFactory --&gt; &lt;bean id="connectionFactory" class="org.springframework.jms.connection.SingleConnectionFactory"&gt; &lt;!-- 目标ConnectionFactory对应真实的可以产生JMS Connection的ConnectionFactory --&gt; &lt;property name="targetConnectionFactory" ref="targetConnectionFactory"/&gt; &lt;/bean&gt; &lt;!-- Spring提供的JMS工具类，它可以进行消息发送、接收等 --&gt; &lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;!-- 这个connectionFactory对应的是我们定义的Spring提供的那个ConnectionFactory对象 --&gt; &lt;property name="connectionFactory" ref="connectionFactory"/&gt; &lt;/bean&gt; &lt;!--这个是队列目的地，点对点的 文本信息--&gt; &lt;bean id="queueTextDestination" class="org.apache.activemq.command.ActiveMQQueue"&gt; &lt;constructor-arg value="queue_text"/&gt; &lt;/bean&gt; &lt;!--这个是订阅模式 文本信息--&gt; &lt;bean id="topicTextDestination" class="org.apache.activemq.command.ActiveMQTopic"&gt; &lt;constructor-arg value="topic_text"/&gt; &lt;/bean&gt; &lt;/beans&gt; Spring生产者生产消息（点对点）1234567891011121314151617181920import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jms.core.JmsTemplate;import org.springframework.stereotype.Component;import javax.jms.Destination;@Componentpublic class SpringQueueProducer &#123; @Autowired private JmsTemplate jmsTemplate; @Autowired private Destination queueTextDestination; //发送消息 public void sendTextMessage(final String text)&#123; jmsTemplate.convertAndSend(text); &#125;&#125; 123456789101112@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations="classpath:applicationContext-jms-producer.xml")public class TestQueue &#123; @Autowired private QueueProducer queueProducer; @Test public void testSend()&#123; queueProducer.sendTextMessage("SpringJms-点对点"); &#125; &#125; Spring消费者接收消息（点对点）Spring消费者接收xml配置12345678910111213141516171819202122232425262728293031323334&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:amq="http://activemq.apache.org/schema/core" xmlns:jms="http://www.springframework.org/schema/jms" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;!-- 真正可以产生Connection的ConnectionFactory，由对应的 JMS服务厂商提供--&gt; &lt;bean id="targetConnectionFactory" class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;property name="brokerURL" value="tcp://192.168.25.131:61616"/&gt; &lt;/bean&gt; &lt;!-- Spring用于管理真正的ConnectionFactory的ConnectionFactory --&gt; &lt;bean id="connectionFactory" class="org.springframework.jms.connection.SingleConnectionFactory"&gt; &lt;!-- 目标ConnectionFactory对应真实的可以产生JMS Connection的ConnectionFactory --&gt; &lt;property name="targetConnectionFactory" ref="targetConnectionFactory"/&gt; &lt;/bean&gt; &lt;!--这个是队列目的地，点对点的 文本信息--&gt; &lt;bean id="queueTextDestination" class="org.apache.activemq.command.ActiveMQQueue"&gt; &lt;constructor-arg value="queue_text"/&gt; &lt;/bean&gt; &lt;!-- 监听类 --&gt; &lt;bean id="myMessageListener" class="cn.itcast.demo.MyMessageListener"&gt;&lt;/bean&gt; &lt;!-- 消息监听容器 --&gt; &lt;bean class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="destination" ref="queueTextDestination" /&gt; &lt;property name="messageListener" ref="myMessageListener" /&gt; &lt;/bean&gt; &lt;/beans&gt; Spring消费者消费消息（点对点）1234567891011121314package cn.itcast.demo;import javax.jms.Message;import javax.jms.MessageListener;import javax.jms.TextMessage;public class MyMessageListener implements MessageListener &#123; public void onMessage(Message message) &#123; TextMessage textMessage = (TextMessage) message; System.out.println("接受到的消息为："+textMessage); &#125;&#125; 123456789101112@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations="classpath:applicationContext-jms-consumer-queue.xml")public class TestQueue &#123; @Test public void testQueue()&#123; try &#123; System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; spring整合jms，对于订阅广播模式，xml配置和点对点一样，我被对应配置已经放在里面了然后只有执行语句不一样 Spring生产者生产消息（发布订阅模式）1234567891011121314151617181920@Componentpublic class TopicProducer &#123; @Autowired private JmsTemplate jmsTemplate; @Autowired private Destination topicTextDestination; /** * 发送文本消息 * @param text */ public void sendTextMessage(final String text)&#123; jmsTemplate.send(topicTextDestination, new MessageCreator() &#123; public Message createMessage(Session session) throws JMSException &#123; return session.createTextMessage(text); &#125; &#125;); &#125;&#125; 12345678910111213141516import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import cn.itcast.demo.TopicProducer;@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations="classpath:applicationContext-activemq-producer.xml")public class TestTopic &#123; @Autowired private TopicProducer topicProducer; @Test public void sendTextQueue()&#123; topicProducer.sendTextMessage(); &#125; &#125; Spring消费者消费消息（发布订阅模式）123456789101112@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations="classpath:applicationContext-jms-consumer-topic.xml")public class TestTopic &#123; @Test public void testTopic()&#123; try &#123; System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 上面的代码 1System.in.read(); 是防止程序启动结束就会关闭，所以让窗口一直等待输入 学习总结花了一两天来了解jms以及和spring的整合，用处很大！有以下两点 可以用来在发送短信的功能中，把短信验证码发送到队列中，然后点对点方式让用户接受到，起到了一定程度的削锋 发布订阅模式可以用在集群环境下，由于集群环境下，同一个页面在不同的服务器上存在多份，可以使用发布订阅模式完成同时渲染多个服务器上的相同的页面]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>消息中间件</tag>
        <tag>JMS</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis的学习总结]]></title>
    <url>%2F2017%2F04%2F17%2Fredis%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[redis的学习总结总结不已，好好珍惜 关系型数据库 特点：数据和数据之间，表和字段之间，表和表之间是存在关系的 优点： 数据之间有关系，进行数据的增删改查时非常方便的。 关系型数据库 有事务操作。 保证数据的完整性 缺点： 数据和数据之间的关系，是有底层算法保证的，大量算法会拉低系统运行速度 海量数据的增删改查时会显得无能为力，很可能宕机 海量数据环境下对数据表进行维护/扩展，也会变得无能为 非关系型数据库（NOSQL）：为了处理海量数据，需要将关系型数据库的关系 去掉。优点： 海量数据的增删改查，非常轻松应对 海量数据的维护非常轻松。 缺点： 数据和数据之间没有关系，所以不能一目了然 非关系型数据库，没有关系，没有强大的事务保证数据的 完整和安全 海量数据的操作redis使用最多，新浪网Redis的使用地方： 作为关系型数据库的缓存 可以做任务队列 大量数据运算 排行榜（类似于微博热搜榜） 字符串在Redis中是二进制安全的便意味着该类型存入和获取的数据相同。在Redis中字符串类型的Value最多可以容纳的数据长度是512M 什么是二进制安全的？关系型数据库是二进制不安全的，关系型数据库需要频繁的编辑码，很可能导致码表不同造成乱码redis是二进制安全的，在服务器端不进行编码，只起到传递数据的目的，解码编码只发生在客户端 Redis的安装（Centos） redis是C语言开发，安装redis需要先将官网下载的源码进行编译，编译依赖gcc环境。如果没有gcc环境，需要安装gcc:（环境已经导入完成） 解压文件tar –zxvf redis-3.0.0.tar.gz 编译redis (编译，将.c文件编译为.o文件)进入解压文件夹，cd redis-3.0.0执行make 安装make PREFIX=/usr/local/redis install copy文件redis启动需要一个配置文件，可以修改端口号等信息。cp redis.conf /usr/local/redis 注：如果没有配置文件redis也可以启动，不过将启用默认配置，这样不方便我们修改端口号等信息 Redis启动 Redis启动-后端模式 修改redis.conf配置文件， daemonize yes 以后端模式启动。vim /usr/local/redis/redis.conf 启动时，指定配置文件cd /usr/local/redis/ ./bin/redis-server ./redis.conf 查看是否启动 ps -ef | grep -i redis redis的关闭 查询到PID,kill -9 pid 【断电，非正常关闭，一般不用，否则造成数据丢失】 正常关闭 【正常关闭，数据保存】./bin/redis-cli shutdown Redis数据类型redis使用的键值对的方式保存数据 Redis——String类型的操作Key: 必须是字符串Value: String,hash,list,set,zset(有序的set集合) 赋值： set key value：设定key持有指定的字符串value，如果该key存在则进行覆盖操作。总是返回”OK” 如果赋予相同的key，新的value会覆盖老的value取值： get key：获取key的value。如果与该key关联的value不是String类型，redis将返回错误信息，因为get命令只能用于获取String value；如果该key不存在，返回(nil)。删除：del key：删除指定key,返回值是数字类型，表示删了几条数据getset：先去除第一个值然后设置给第二个incr key：原子性递增decr key：原子性递减Incr和decr 只能对字符串是数字的操作append key value: 拼凑字符串。如果该key存在，则在原有的value后追加该值；如果该key不存在，则重新创建一个key/value Redis——Hash类型的操作hash存储的特点：占用磁盘空间极少flushall,flushdb 删除所有的键值对，第一个表示删除所有db下的键值对，第二个表示删除当前db下的所有键值对设置hset: hset hash1 username zhangsan 设置key为hash1，username=zhangsanhmset: hmset hash2 username uname zhangsan age 18取出hget: 获取key中的多个filed的值 hget hash1 usernamehmget: ： 获取key中的多个filed的值 hget hash2 uname agehgetall: ： 获取key中的所有filed-vaule hgetall hash2删除hdel hash1 uname 删除hash1中的uname属性keys： 查询所有的key(各个类型都可以这样查找使用)hincrby: hincrby hash2 age 20 增加20hexists hexists hash1 uname 判断是uname字段是否存在hlens hlens hash2 得到hash2中字段个数hkeys hkeys hash2 获取所有的keyhvals hvals hash2 获取所有的值 Redis——list类型的操作（类似于java中的链表list）lpush key 参数1….：加入参数到list集合，例如 1,2,3 插入结果是:3,2,1rpush key 参数1….：加入参数到list集合lrange key start end： 获取从左往右数起从start到end的元素,其中end可为-1表示导入第一个元素lpop key： list集合从左侧弹出keyrpop key： list集合从右侧演出keyllen key：list集合的长度lrem key a：从左侧查找删除所有的alrem key count value：从左侧查找删除所有的key然后删除count个value值 Redis——set类型的操作set无序，不重复，适用于两个大集合的运算add key values[value1、value2…]：向set中添加数据，如果该key的值已有则不会重复添加srem key members[member1、member2…]：删除set中指定的成员smembers key：获取set中所有的成员sismember key member：判断参数中指定的成员是否在该set中，1表示存在，0表示不存在或者该key本身就不存在。（无论集合中有多少元素都可以极速的返回结果 集合运算sdiff key1 key2…：返回key1与key2中相差的成员，而且与key的顺序有关。即返回差集。表示属于key1不属于key2,有顺序的sinter key1 key2…：返回交集。即属于key1,属于key2，无顺序sunion key1 key2 …：返回并集，返回key1,key2 上面的方法都可以加上store,例如sdiff为sdiffstore key3 key1 key2:把key1、key2的交集存放在key3上 其他延伸scard key1:返回key1的长度 Redis——zset(有序set集合)类型的操作zset: 有序不重复这个功能很适合用作 排行榜之所以是有序，就是因为每个元素我们都要赋予一个分数 zadd key score member score2 member2 … ：将所有成员以及该成员的分数存放到sorted-set中。如果该元素已经存在则会用新的分数替换原有的分数zscore key member：返回指定成员的分数zcard key1:返回key1的长度zrem key member[member…]：移除集合中指定的成员，可以指定多个成员zrange key start end [withscores]：获取集合中脚标为start-end的成员，[withscores]参数表明返回的成员包含其分数。（分数由小到大排列）zrevrange key start end [withscores]：获取集合中脚标为start-end的成员，[withscores]参数表明返回的成员包含其分数（分数由大到小排列） 通用命令keys* ：表示查找所有的keydel key1 ：表示删除key1exists key：表示key是否存在rename key newkey：表示给key重名为newkeytype key：表示得到key的类型expire key time：表示给key设置生存时间为time秒ttl key：表示得到key的剩余生存时间 subscribe,publish 频道的订阅与发布subscribe test表示订阅test频道publish test key 表示在test频道发布内容key,然后订阅频道的会接收到key内容 Redis的数据库默认redis创建好了数据量,总共16个数据库，分别0,1…15；数据库和数据库之间，不能共享键值对。切换数据库：select 数据库名; 把某个键值对进行数据库移植：move newkey 1：将当前库的key移植到1号库中 Redis的事务MySQL-事务： 目的为了保证数据完整性，安全。Redis-事务： 目的为了进行redis语句的批量化执行 multi：开启事务用于标记事务的开始，其后执行的命令都将被存入命令队列，直到执行EXEC时，这些命令才会被原子的执行，类似与关系型数据库中的：begin transactionexec：提交事务，类似与关系型数据库中的：commit 执行批量化discard：事务回滚，类似与关系型数据库中的：rollback 不执行批量化操作 Redis的其他命令dbsize： 返回当前数据库中key 的数目info 查看redis数据 Redis的持久化redis所有的增删改，都在内存中操作，断电之后内存中的数据是不存在的，由于redis部分内容存在硬盘上，所以是部分丢失数据 redis有两种持久化策略 RDB:是redis的默认持久化机制,相当于 照快照，保存的是一种状态 优点： 快照保存数据速度极快，还原数据速度较快 适用于灾难备份 缺点： RDB机制符合要求就会照快照(随时随地启动)，会占用一部分系统资源，小机器不适合使用 RDB何时进行照快照： ①服务器正常关闭时，会照一次快照 ./bin/redis-cli shutdown ②key满足一定条件，会照一次快照 AOF: AOF: 使用日志功能保存数据操作。 默认AOF机制关闭的。 每秒同步（默认）：每秒进行一次AOF保存数据。 安全性低，比较节省系统资源 每修改同步：只要有key变化语句，就进行AOF保存数据。比较安全，但是极为浪费效率 不同步：不进行任何持久化操作 不安全 AOF操作：只会保存导致key变化的语句 AOF配置： always #每次有数据修改发生时都会写入AOF文件 everysec #每秒钟同步一次，该策略为AOF的缺省策略 no #从不同步。高效但是数据不会被持久化 优点：①持续性占用极少量的内存资源 缺点：①日志文件会特别大，不适用于灾难恢复 ②恢复效率远远低于RDB 适用于：内存比较小的计算机]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis缓存的使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络知识自我总结]]></title>
    <url>%2F2017%2F03%2F05%2F%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E8%87%AA%E6%88%91%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[网络知识自我总结两种软件架构： b/s c/s 无论哪一种，都需要网络 网络通信协议它对数据的传输格式，传输速率，传输步骤等做了统一规定，通信双方必须同时遵守才能完成数据交换 TCP/IP协议:是internet最基本的协议通常我们会把七层结构简化为四层结构，每一层都要告诉它的下一层所提供的协议来完成自己的需求 网络层是TCP/IP的核心，用于将传输的数据进行分组，将分组的数据传输到目标计算机或者网络 两种通信协议的介绍UDP:数据报协议UDP是无连接通信协议，即在数据传输时，数据的接受端和发送端不建立逻辑连接。由于使用UDP协议消耗资源小，通信效率高，所以通常被使用为视频音频，因为偶尔丢失一两个数据包，也不会对接受结果产生太大的影响由于UDP面向无连接性，不能保证数据的完整性，因此在传输重要数据时候不建议使用UDP协议特点：数据限制在64KB以内 TCP:面向连接三次握手，保证数据的安全，用于文件传输，浏览网页等 在tcp中，首先是先启动服务器端，等待着客户端来连接，然后客户端发送请求给服务器端，服务器端响应请求给客户端，然后客户端再次向服务器端发送请求确认连接，三次握手结束。成功建立连接。 网上有一个比较形象的图 网络编程三要素 协议：计算机网络通信必须要遵守的规则 IP地址：互联网协议地址 端口：有两个字节组成，取值范围0-65535之间，0-1024我们不能使用，已经被系统分配给已知软件了]]></content>
      <categories>
        <category>网络知识</category>
      </categories>
      <tags>
        <tag>TCP协议</tag>
        <tag>UDP协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux的chmod赋权限语句]]></title>
    <url>%2F2017%2F02%2F19%2Flinux%E7%9A%84chmod%E8%B5%8B%E6%9D%83%E9%99%90%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[linux下chmod 755的解释很多时候在Linux系统下给安装好的软件赋权限的时候回用的755、555,那么数字表示什么呢？ 普及一下chmod的数字 chmod是Linux下设置文件权限的命令，后面的数字表示不同用户或用户组的权限。 一般是三个数字： 第一个数字表示文件所有者的权限 第二个数字表示与文件所有者同属一个用户组的其他用户的权限 第三个数字表示其它用户组的权限。 权限分为三种：读（r=4），写（w=2），执行（x=1） 。 综合起来还有可读可执行（rx=5=4+1）、可读可写（rw=6=4+2）、可读可写可执行(rwx=7=4+2+1)。 举个例子 1234chmod 755 设置用户的权限为： 1.文件所有者可读可写可执行 --7 2.与文件所有者同属一个用户组的其他用户可读可执行 --5 3.其它用户组可读可执行]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>命令</tag>
      </tags>
  </entry>
</search>
